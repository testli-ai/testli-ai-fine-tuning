{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "87aaec3e95994cd2ba627b36eac640e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b496d957025420b81cfd0a7a69b4688",
              "IPY_MODEL_6d16dbdda5074a97a23ca3fbb3d338fc",
              "IPY_MODEL_5c9616b79e844b92b2e32dd9d6b2ba73"
            ],
            "layout": "IPY_MODEL_2ad00772a72d4ff39d78ee9a7867cca7"
          }
        },
        "9b496d957025420b81cfd0a7a69b4688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0565f22b822a48efa46682fcf2129d51",
            "placeholder": "​",
            "style": "IPY_MODEL_b5f244dce30e4816b21258182f091e92",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6d16dbdda5074a97a23ca3fbb3d338fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c35d12adc3394343aa7ea35f28979487",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2624865902a4afbb282a9e4d29d0b90",
            "value": 3
          }
        },
        "5c9616b79e844b92b2e32dd9d6b2ba73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08f05af0a2124925929e38bf0cf846ce",
            "placeholder": "​",
            "style": "IPY_MODEL_0d261ae08588473ebe6d88ea96b87e52",
            "value": " 3/3 [00:08&lt;00:00,  3.03s/it]"
          }
        },
        "2ad00772a72d4ff39d78ee9a7867cca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0565f22b822a48efa46682fcf2129d51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5f244dce30e4816b21258182f091e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c35d12adc3394343aa7ea35f28979487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2624865902a4afbb282a9e4d29d0b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "08f05af0a2124925929e38bf0cf846ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d261ae08588473ebe6d88ea96b87e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32a3956c5fc14a04ae8ab7a8d1717e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd573ad96f0b463c8901fe9062ba2fb8",
              "IPY_MODEL_0d654113e14248c9ad20ebd877fced6b",
              "IPY_MODEL_e0a0996fb9044069b46536b64705245e"
            ],
            "layout": "IPY_MODEL_f1153fae60744e679dc407938cb37a0d"
          }
        },
        "dd573ad96f0b463c8901fe9062ba2fb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02dd604a804d4b50a91f552534883349",
            "placeholder": "​",
            "style": "IPY_MODEL_5e24c19eaefe4ddf8a5abcb6bbb3bdf1",
            "value": "unsloth.Q4_K_M.gguf: 100%"
          }
        },
        "0d654113e14248c9ad20ebd877fced6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64bdfc6b2eae42a6b5af341693a38a16",
            "max": 4372815648,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fd0ef1558d74872935aa32860cf1198",
            "value": 4372815648
          }
        },
        "e0a0996fb9044069b46536b64705245e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8a125fdf48f40668c0a94a18ea8bced",
            "placeholder": "​",
            "style": "IPY_MODEL_16d5fb05ea4141e48533c1e9faf17e3a",
            "value": " 4.37G/4.37G [01:28&lt;00:00, 45.4MB/s]"
          }
        },
        "f1153fae60744e679dc407938cb37a0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02dd604a804d4b50a91f552534883349": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e24c19eaefe4ddf8a5abcb6bbb3bdf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64bdfc6b2eae42a6b5af341693a38a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd0ef1558d74872935aa32860cf1198": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8a125fdf48f40668c0a94a18ea8bced": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d5fb05ea4141e48533c1e9faf17e3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28f2a659e97e49ddb6edfe847713eed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff6585a18c1b4b58bd12f5bd385ebc69",
              "IPY_MODEL_8083b69fbd174da7af962468f95ed313",
              "IPY_MODEL_c93dd51d13274435800bcb4ed25afcea"
            ],
            "layout": "IPY_MODEL_249be5d2d07a432d934b4355a554f2c3"
          }
        },
        "ff6585a18c1b4b58bd12f5bd385ebc69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_075a1f675ece455cab62fedb8efbdbaa",
            "placeholder": "​",
            "style": "IPY_MODEL_e64c91bcdac74a1eaa68a9d28ff85a00",
            "value": "adapter_config.json: 100%"
          }
        },
        "8083b69fbd174da7af962468f95ed313": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca0d7510c9a9482a924856ac3e018f3a",
            "max": 794,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f36f806c9d8e495a89f21c06d24fa48e",
            "value": 794
          }
        },
        "c93dd51d13274435800bcb4ed25afcea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23d2dbc2fbbc470e9c89e10da8c7161f",
            "placeholder": "​",
            "style": "IPY_MODEL_958cdb21628c4e8aab36d6003fa53ec4",
            "value": " 794/794 [00:00&lt;00:00, 75.0kB/s]"
          }
        },
        "249be5d2d07a432d934b4355a554f2c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "075a1f675ece455cab62fedb8efbdbaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e64c91bcdac74a1eaa68a9d28ff85a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0d7510c9a9482a924856ac3e018f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f36f806c9d8e495a89f21c06d24fa48e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "23d2dbc2fbbc470e9c89e10da8c7161f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958cdb21628c4e8aab36d6003fa53ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b634502073d4f53b6ab2edc706fde02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_678e0e424fb444f18ab27595321509bb",
              "IPY_MODEL_567d42e3d40a4ba4b0739692bf7aa25c",
              "IPY_MODEL_743a567f04c4444e9cfc8a6a8b731c37"
            ],
            "layout": "IPY_MODEL_0daf2cd0636c4391bd680de8bfebea64"
          }
        },
        "678e0e424fb444f18ab27595321509bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_577f23d1d31141bc8e50472829c0d76f",
            "placeholder": "​",
            "style": "IPY_MODEL_bfda717fde97420a8aefd9314dd1c4f4",
            "value": "config.json: 100%"
          }
        },
        "567d42e3d40a4ba4b0739692bf7aa25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5d59e813524752a4ea20efc74831c9",
            "max": 715,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0286c62f6ec44f988ede926b5a3e87c0",
            "value": 715
          }
        },
        "743a567f04c4444e9cfc8a6a8b731c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c31055d547364a9fb03c6732696a61a1",
            "placeholder": "​",
            "style": "IPY_MODEL_48d86f7b5759475d9326007cb1c7618d",
            "value": " 715/715 [00:00&lt;00:00, 68.6kB/s]"
          }
        },
        "0daf2cd0636c4391bd680de8bfebea64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577f23d1d31141bc8e50472829c0d76f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfda717fde97420a8aefd9314dd1c4f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a5d59e813524752a4ea20efc74831c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0286c62f6ec44f988ede926b5a3e87c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c31055d547364a9fb03c6732696a61a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d86f7b5759475d9326007cb1c7618d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97300d374b9648088f8ec2c878f29feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1586e9601b02430b84ae0056e6f48a0d",
              "IPY_MODEL_c29615c9556c408a9a6e8a75c92145ee",
              "IPY_MODEL_ff5372ea1ddb49e0871f162162dbee5d"
            ],
            "layout": "IPY_MODEL_be7d050ceaac4df89e5aedea5b0d298b"
          }
        },
        "1586e9601b02430b84ae0056e6f48a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_199cce7ed30e4e50a643f9a94e69717f",
            "placeholder": "​",
            "style": "IPY_MODEL_da2059a534bb4b379dd7429315d47476",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "c29615c9556c408a9a6e8a75c92145ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a1e4e7d8614502bba82f81fb7aec34",
            "max": 23950,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_529ee8af4dad4bb187a876909768a4d3",
            "value": 23950
          }
        },
        "ff5372ea1ddb49e0871f162162dbee5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_454992edcc29408c8021bc041ef409b4",
            "placeholder": "​",
            "style": "IPY_MODEL_127a297b94514d38bf447cec377ead5d",
            "value": " 23.9k/23.9k [00:00&lt;00:00, 1.97MB/s]"
          }
        },
        "be7d050ceaac4df89e5aedea5b0d298b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "199cce7ed30e4e50a643f9a94e69717f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "da2059a534bb4b379dd7429315d47476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7a1e4e7d8614502bba82f81fb7aec34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529ee8af4dad4bb187a876909768a4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "454992edcc29408c8021bc041ef409b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127a297b94514d38bf447cec377ead5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5101485e43345668b4a29490608e8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9958b8b784148b6b7e20db8bb47599c",
              "IPY_MODEL_495ca8537b5c4eb688780ab2eb7a18fd",
              "IPY_MODEL_d479180a38ce4964baeccc385bbb69cf"
            ],
            "layout": "IPY_MODEL_4536d938d8944049b99814b630820d5f"
          }
        },
        "d9958b8b784148b6b7e20db8bb47599c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f164fbd7b6664cb892403022d2e76463",
            "placeholder": "​",
            "style": "IPY_MODEL_3359db84ad3940cfb5ffdf2150be32cc",
            "value": "Downloading shards: 100%"
          }
        },
        "495ca8537b5c4eb688780ab2eb7a18fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9d3c0dfe1ca4417bf8a074fd40db0ed",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b060c80508c441fd9e2d75e227e9357d",
            "value": 3
          }
        },
        "d479180a38ce4964baeccc385bbb69cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5396b2d979b0495885503ede511543f5",
            "placeholder": "​",
            "style": "IPY_MODEL_bdde41687e3240418f16df8861c11adb",
            "value": " 3/3 [02:41&lt;00:00, 48.75s/it]"
          }
        },
        "4536d938d8944049b99814b630820d5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f164fbd7b6664cb892403022d2e76463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3359db84ad3940cfb5ffdf2150be32cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9d3c0dfe1ca4417bf8a074fd40db0ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b060c80508c441fd9e2d75e227e9357d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5396b2d979b0495885503ede511543f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdde41687e3240418f16df8861c11adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06d9dcdb34e94d7581374c5e38fd9383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f31cc78b1e9445dba57bea4b91e420d",
              "IPY_MODEL_d0be6c3f2fe9421e81d649f251b6c045",
              "IPY_MODEL_93e306e0836f4a6c8bde5d347e233cfe"
            ],
            "layout": "IPY_MODEL_0655911851524af3bf3ce38cee294a22"
          }
        },
        "5f31cc78b1e9445dba57bea4b91e420d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0069c48378fe490999a8779e39913f66",
            "placeholder": "​",
            "style": "IPY_MODEL_fe42b07715484da780f1e1b614024577",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "d0be6c3f2fe9421e81d649f251b6c045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d07ef3c66fb4cb1a0c3a71b3074b45f",
            "max": 4949453792,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57dc30558e304eaabb9ba9bfee76de88",
            "value": 4949453792
          }
        },
        "93e306e0836f4a6c8bde5d347e233cfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24da8fb1f4f64abdb2b272245bcbf727",
            "placeholder": "​",
            "style": "IPY_MODEL_26faee4d02fb49c28d7ca86e72f3b157",
            "value": " 4.95G/4.95G [01:15&lt;00:00, 62.4MB/s]"
          }
        },
        "0655911851524af3bf3ce38cee294a22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0069c48378fe490999a8779e39913f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe42b07715484da780f1e1b614024577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d07ef3c66fb4cb1a0c3a71b3074b45f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57dc30558e304eaabb9ba9bfee76de88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24da8fb1f4f64abdb2b272245bcbf727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26faee4d02fb49c28d7ca86e72f3b157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8d972458968458d8599efbfa56215d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b890e0ca046c4c41b63bfc69d1682a6f",
              "IPY_MODEL_f341816be48c46fbb3effeb2806b2706",
              "IPY_MODEL_c2226d730e8b4ebda2bc35cba89a56ff"
            ],
            "layout": "IPY_MODEL_ab969a60454a456bbefc5da75dde7487"
          }
        },
        "b890e0ca046c4c41b63bfc69d1682a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1147c7569d8843728c3ed288538fb580",
            "placeholder": "​",
            "style": "IPY_MODEL_e006feb706b940b0ba2b99cc0bb74427",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "f341816be48c46fbb3effeb2806b2706": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0633cb22c174c27b326ad37d23c3668",
            "max": 4999819336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21f5e76cd088458c97827e1cca7b0961",
            "value": 4999819336
          }
        },
        "c2226d730e8b4ebda2bc35cba89a56ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7bfa93af3b4809a73c3aa1d6c5e326",
            "placeholder": "​",
            "style": "IPY_MODEL_9d2b820175f541829aa05c0b047055ad",
            "value": " 5.00G/5.00G [00:55&lt;00:00, 58.2MB/s]"
          }
        },
        "ab969a60454a456bbefc5da75dde7487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1147c7569d8843728c3ed288538fb580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e006feb706b940b0ba2b99cc0bb74427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0633cb22c174c27b326ad37d23c3668": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21f5e76cd088458c97827e1cca7b0961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b7bfa93af3b4809a73c3aa1d6c5e326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2b820175f541829aa05c0b047055ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac5a6a08f9d64e44804f5f93553fd91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78eb13a1047f45b4b67af071b2e7b630",
              "IPY_MODEL_3f89df2e3ae74098a0c2c159546baf96",
              "IPY_MODEL_60a2b75f4447445887d7010a79bc6cc2"
            ],
            "layout": "IPY_MODEL_2f840e0d2a5740a5a32ccf4a30f999b1"
          }
        },
        "78eb13a1047f45b4b67af071b2e7b630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c871e4114e34c6f86753754f8713d10",
            "placeholder": "​",
            "style": "IPY_MODEL_a2b68b3ee6d943f2aa85b923bf1970d2",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "3f89df2e3ae74098a0c2c159546baf96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_765355e83bac422e90a01b2357a15893",
            "max": 4546807800,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57025e14a53f41588a1ff37d36a1e575",
            "value": 4546807800
          }
        },
        "60a2b75f4447445887d7010a79bc6cc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5601746326824b209a49e0a77ab75580",
            "placeholder": "​",
            "style": "IPY_MODEL_dfab269861ff4380b33482566216e0c5",
            "value": " 4.55G/4.55G [00:30&lt;00:00, 169MB/s]"
          }
        },
        "2f840e0d2a5740a5a32ccf4a30f999b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c871e4114e34c6f86753754f8713d10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2b68b3ee6d943f2aa85b923bf1970d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "765355e83bac422e90a01b2357a15893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57025e14a53f41588a1ff37d36a1e575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5601746326824b209a49e0a77ab75580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfab269861ff4380b33482566216e0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7582d941a6343aaa68df274ad31f5f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e4b181bbeff40ce9f1c6ef572a2b802",
              "IPY_MODEL_ae31a3318f774728a9af4ee151f1deb0",
              "IPY_MODEL_2815c3463a694f13956256f5af6f5feb"
            ],
            "layout": "IPY_MODEL_2c324ba5efc442939e5c972295ea08c3"
          }
        },
        "4e4b181bbeff40ce9f1c6ef572a2b802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4966b8308d44fd867dcd019848cde2",
            "placeholder": "​",
            "style": "IPY_MODEL_af16740f87544b609d06ac6165897d84",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ae31a3318f774728a9af4ee151f1deb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5211ecd466de4669af236c62d33f85af",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb2c1afbeb3443969fcb9ad9bebeba82",
            "value": 3
          }
        },
        "2815c3463a694f13956256f5af6f5feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95d6e5fe680e4a189bd778364a7b4fda",
            "placeholder": "​",
            "style": "IPY_MODEL_61c330b18ba942e3b33f259d4fe39234",
            "value": " 3/3 [00:09&lt;00:00,  3.01s/it]"
          }
        },
        "2c324ba5efc442939e5c972295ea08c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4966b8308d44fd867dcd019848cde2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af16740f87544b609d06ac6165897d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5211ecd466de4669af236c62d33f85af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb2c1afbeb3443969fcb9ad9bebeba82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "95d6e5fe680e4a189bd778364a7b4fda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61c330b18ba942e3b33f259d4fe39234": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "80227a8e1010419ea07d99ad16037483": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e265164287d484598e5bfb5d8a5ef15",
              "IPY_MODEL_7be4ff2b96b64258892143e28257deff",
              "IPY_MODEL_6d844df5b9df46cfa1b696a32a8884cd"
            ],
            "layout": "IPY_MODEL_0601f569a8944d9b97065c266cf54d5d"
          }
        },
        "3e265164287d484598e5bfb5d8a5ef15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_589c3744b91c4134b597faf960112971",
            "placeholder": "​",
            "style": "IPY_MODEL_9b3de80b599643248119300c2db882d1",
            "value": "generation_config.json: 100%"
          }
        },
        "7be4ff2b96b64258892143e28257deff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de6f87f198cf4e42853bb99955035790",
            "max": 157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7fd431860e9b4309ada1b11e9e48bcda",
            "value": 157
          }
        },
        "6d844df5b9df46cfa1b696a32a8884cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eecb6bfed3ce45a2becb3179f2dba472",
            "placeholder": "​",
            "style": "IPY_MODEL_b480fc75fae34829bcb30efe3a123460",
            "value": " 157/157 [00:00&lt;00:00, 15.6kB/s]"
          }
        },
        "0601f569a8944d9b97065c266cf54d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "589c3744b91c4134b597faf960112971": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b3de80b599643248119300c2db882d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de6f87f198cf4e42853bb99955035790": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fd431860e9b4309ada1b11e9e48bcda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eecb6bfed3ce45a2becb3179f2dba472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b480fc75fae34829bcb30efe3a123460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae2862dd0d9647f597a86d5e0df5bbe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_425f2c2c50a042f88486b400f4df71e8",
              "IPY_MODEL_a49a432626734ea6a6b6ed3a53f24010",
              "IPY_MODEL_f05dd230c8e848368b25b49a97f2ac88"
            ],
            "layout": "IPY_MODEL_8e47e9ba83d94bad8c5c94f5331c6200"
          }
        },
        "425f2c2c50a042f88486b400f4df71e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c72da06d12c946a6843c0f7f68b7ddd0",
            "placeholder": "​",
            "style": "IPY_MODEL_9197c0bc590841539c17d6acc15e6887",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "a49a432626734ea6a6b6ed3a53f24010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7433d4f8cfe493eb4043a53106e4228",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91632bbce65c45f1b10a4bee290585f9",
            "value": 167832240
          }
        },
        "f05dd230c8e848368b25b49a97f2ac88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c8b8c90ada499faf4545bd01a5e18a",
            "placeholder": "​",
            "style": "IPY_MODEL_33e40acb5a50459996f872b4ff0d51c0",
            "value": " 168M/168M [00:00&lt;00:00, 194MB/s]"
          }
        },
        "8e47e9ba83d94bad8c5c94f5331c6200": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c72da06d12c946a6843c0f7f68b7ddd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9197c0bc590841539c17d6acc15e6887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7433d4f8cfe493eb4043a53106e4228": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91632bbce65c45f1b10a4bee290585f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35c8b8c90ada499faf4545bd01a5e18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33e40acb5a50459996f872b4ff0d51c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfef43f1260f492f8d07847918caa4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e1c7d15ac43540ab86292db176d9ac96",
              "IPY_MODEL_7afea7fcd9444ecdbe7e0ef343d1ed21",
              "IPY_MODEL_50187a6047f04c57b253b6ed3904347d"
            ],
            "layout": "IPY_MODEL_ac2e752c4ebe4521b5574ccc07e79609"
          }
        },
        "e1c7d15ac43540ab86292db176d9ac96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec2aabe0fa940cd97b1247fe13db19d",
            "placeholder": "​",
            "style": "IPY_MODEL_80d87d679282444e9f1d0bf2e922d582",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7afea7fcd9444ecdbe7e0ef343d1ed21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cc20096d3df4ab489f917435a14d0f4",
            "max": 136730,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8497dda45ef44a85899c829bdd96fe48",
            "value": 136730
          }
        },
        "50187a6047f04c57b253b6ed3904347d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30e07bb8c52c4f6abd9e21551e019b90",
            "placeholder": "​",
            "style": "IPY_MODEL_6c0ed2810b394886b5405bf346e0fd37",
            "value": " 137k/137k [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "ac2e752c4ebe4521b5574ccc07e79609": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eec2aabe0fa940cd97b1247fe13db19d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d87d679282444e9f1d0bf2e922d582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cc20096d3df4ab489f917435a14d0f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8497dda45ef44a85899c829bdd96fe48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30e07bb8c52c4f6abd9e21551e019b90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c0ed2810b394886b5405bf346e0fd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9dc3ed0f73f4f67a2df8d53fa1e2e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8efa2f00446b4194b84134868458a25f",
              "IPY_MODEL_0755ea4b3b3d4b2fb935de0777b08db1",
              "IPY_MODEL_7adddacd821e4f7c9fe1ce0c45d674ea"
            ],
            "layout": "IPY_MODEL_18b96e11f1bd40e7b1f5b7881f8321ce"
          }
        },
        "8efa2f00446b4194b84134868458a25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b508a2020ec24e119a302a0e9125be6e",
            "placeholder": "​",
            "style": "IPY_MODEL_9077ee91e4734b65ad287750d17ee6b7",
            "value": "tokenizer.model: 100%"
          }
        },
        "0755ea4b3b3d4b2fb935de0777b08db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1770560d061d4447a86b9d5b1afc6fe4",
            "max": 587404,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4104f0ba150047a69f9bd7e9fd05987c",
            "value": 587404
          }
        },
        "7adddacd821e4f7c9fe1ce0c45d674ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b6fe1474bb146a6b7123446217f1d1e",
            "placeholder": "​",
            "style": "IPY_MODEL_bea6724a83c440669402cb1495db67bc",
            "value": " 587k/587k [00:00&lt;00:00, 44.4MB/s]"
          }
        },
        "18b96e11f1bd40e7b1f5b7881f8321ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b508a2020ec24e119a302a0e9125be6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9077ee91e4734b65ad287750d17ee6b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1770560d061d4447a86b9d5b1afc6fe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4104f0ba150047a69f9bd7e9fd05987c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b6fe1474bb146a6b7123446217f1d1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bea6724a83c440669402cb1495db67bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b2f685fb174b57a24598221d7b93b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_918cddc51d6c43dfbc5ba4bd1c0d474f",
              "IPY_MODEL_b76e83b62e5545d8b10092487dbba985",
              "IPY_MODEL_f4a41efe83d84044be4c2bc488ce8deb"
            ],
            "layout": "IPY_MODEL_633704e717774f74a04f496dd95df975"
          }
        },
        "918cddc51d6c43dfbc5ba4bd1c0d474f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8049362bc29248d8a647ebe58034633f",
            "placeholder": "​",
            "style": "IPY_MODEL_ce9584bd4eab4b86bad5a07bb5d31c37",
            "value": "tokenizer.json: 100%"
          }
        },
        "b76e83b62e5545d8b10092487dbba985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55d8a3c4ebd34382bd2e4741cd090428",
            "max": 3671968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_65d433ebe8f24754a69704c9cae7edf8",
            "value": 3671968
          }
        },
        "f4a41efe83d84044be4c2bc488ce8deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1169d59d33476fbeb1484f0718af9b",
            "placeholder": "​",
            "style": "IPY_MODEL_a9c5ebb252aa485f86c977989315176e",
            "value": " 3.67M/3.67M [00:00&lt;00:00, 28.2MB/s]"
          }
        },
        "633704e717774f74a04f496dd95df975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8049362bc29248d8a647ebe58034633f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce9584bd4eab4b86bad5a07bb5d31c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55d8a3c4ebd34382bd2e4741cd090428": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65d433ebe8f24754a69704c9cae7edf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba1169d59d33476fbeb1484f0718af9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9c5ebb252aa485f86c977989315176e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fa66044c77d488bad05ca2b498ab302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c13d4d2033f5413084a050dd6b7d7ae4",
              "IPY_MODEL_947dfffd02a841489079f3b939e18648",
              "IPY_MODEL_94008ecf00d645059aed28240c29193a"
            ],
            "layout": "IPY_MODEL_4ff07f6dfc1e4195b78b7ba0ae37eb88"
          }
        },
        "c13d4d2033f5413084a050dd6b7d7ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d43dc9855e4840799ec528210f42f019",
            "placeholder": "​",
            "style": "IPY_MODEL_cdeb9175cb6346748a46761c6a1c6e69",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "947dfffd02a841489079f3b939e18648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726afbc5dc8e4fd6966bcd626f7904b4",
            "max": 437,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb8297d00a4143209b5350dcd4c805d1",
            "value": 437
          }
        },
        "94008ecf00d645059aed28240c29193a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d74992fd0224ce18a9ee3ac2e72d616",
            "placeholder": "​",
            "style": "IPY_MODEL_3e85287610e3434285bc863b8c8f702e",
            "value": " 437/437 [00:00&lt;00:00, 44.8kB/s]"
          }
        },
        "4ff07f6dfc1e4195b78b7ba0ae37eb88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d43dc9855e4840799ec528210f42f019": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdeb9175cb6346748a46761c6a1c6e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726afbc5dc8e4fd6966bcd626f7904b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb8297d00a4143209b5350dcd4c805d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d74992fd0224ce18a9ee3ac2e72d616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e85287610e3434285bc863b8c8f702e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/testli-ai/testli-ai-fine-tuning/blob/main/testliai_generate_exam_mistral_7b_instruct_v0_3_bnb_4bit_GGUF_q4_k_m_v0_0_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# next model name: testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m-v0.0.2"
      ],
      "metadata": {
        "id": "oiKDd_fxjS9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AKpt62lrDVgm",
        "outputId": "60d446eb-6ddd-41a5-8b64-fa42ef5be41f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.47.1\n",
            "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets==3.2.0\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch==2.5.1+cu124 in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision==0.20.1+cu124 in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.47.1) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.2.0)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (2.2.2)\n",
            "Collecting xxhash (from datasets==3.2.0)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.2.0)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.2.0)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==3.2.0) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.1+cu124) (1.13.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.20.1+cu124) (11.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.1+cu124) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==3.2.0) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.47.1) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.1+cu124) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==3.2.0) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==3.2.0) (1.17.0)\n",
            "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, transformers, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 transformers-4.47.1 xxhash-3.5.0\n",
            "Requirement already satisfied: tokenizers==0.21.0 in /usr/local/lib/python3.11/dist-packages (0.21.0)\n",
            "Collecting bitsandbytes==0.45.1\n",
            "  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting accelerate==1.2.1\n",
            "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers==0.21.0) (0.28.1)\n",
            "Requirement already satisfied: torch~=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.45.1) (2.5.1+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes==0.45.1) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (6.0.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (4.47.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft==0.14.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch~=2.0->bitsandbytes==0.45.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes==0.45.1) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft==0.14.0) (2024.11.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch~=2.0->bitsandbytes==0.45.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.0) (2025.1.31)\n",
            "Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.4/336.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.3.0\n",
            "    Uninstalling accelerate-1.3.0:\n",
            "      Successfully uninstalled accelerate-1.3.0\n",
            "Successfully installed accelerate-1.2.1 bitsandbytes-0.45.1\n",
            "Collecting trl==0.12.0\n",
            "  Downloading trl-0.12.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.2.15-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipykernel==5.5.6\n",
            "  Downloading ipykernel-5.5.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.12.0) (1.2.1)\n",
            "Requirement already satisfied: datasets>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.12.0) (3.2.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl==0.12.0) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl==0.12.0) (4.47.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel==5.5.6) (6.4.2)\n",
            "Collecting unsloth_zoo>=2025.2.7 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.2.7-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.5.1+cu124)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (24.2)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.16-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.26.4)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.14.0)\n",
            "Collecting protobuf<4.0.0 (from unsloth)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.28.1)\n",
            "Collecting hf_transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.32.2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl==0.12.0) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.21.0->trl==0.12.0) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.21.0->trl==0.12.0) (3.11.13)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (75.1.0)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel==5.5.6)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.0.0->ipykernel==5.5.6) (4.9.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl==0.12.0) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl==0.12.0) (0.21.0)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.2.7->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.2.7->unsloth) (11.1.0)\n",
            "Collecting torch>=2.4.0 (from unsloth)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.6.1)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel==5.5.6) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel==5.5.6) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client->ipykernel==5.5.6) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl==0.12.0) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.21.0->trl==0.12.0) (1.18.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel==5.5.6) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel==5.5.6) (4.3.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.12.0) (0.1.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel==5.5.6) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel==5.5.6) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel==5.5.6) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=2.21.0->trl==0.12.0) (2025.1.31)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers->unsloth) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.0) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=2.21.0->trl==0.12.0) (2025.1)\n",
            "Downloading trl-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.2/310.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-5.5.6-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.0/121.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth-2025.2.15-py3-none-any.whl (188 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.8/188.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.2.7-py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.1/107.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m120.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.16-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: triton, nvidia-cusparselt-cu12, shtab, protobuf, jedi, hf_transfer, tyro, torch, ipykernel, xformers, torchvision, cut_cross_entropy, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 6.17.1\n",
            "    Uninstalling ipykernel-6.17.1:\n",
            "      Successfully uninstalled ipykernel-6.17.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 5.5.6 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 hf_transfer-0.1.9 ipykernel-5.5.6 jedi-0.19.2 nvidia-cusparselt-cu12-0.6.2 protobuf-3.20.3 shtab-1.7.1 torch-2.6.0 torchvision-0.21.0 triton-3.2.0 trl-0.12.0 tyro-0.9.16 unsloth-2025.2.15 unsloth_zoo-2025.2.7 xformers-0.0.29.post3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "ipykernel"
                ]
              },
              "id": "8a4ba4205b6b478b862ddf2b3fdbeaf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting outlines\n",
            "  Downloading outlines-0.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting interegular (from outlines)\n",
            "  Downloading interegular-0.3.3-py37-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from outlines) (3.1.5)\n",
            "Collecting lark (from outlines)\n",
            "  Downloading lark-1.2.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from outlines) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from outlines) (3.1.1)\n",
            "Collecting diskcache (from outlines)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from outlines) (2.10.6)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines) (4.23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outlines) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from outlines) (4.67.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from outlines) (4.12.2)\n",
            "Collecting iso3166 (from outlines)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting airportsdata (from outlines)\n",
            "  Downloading airportsdata-20250224-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from outlines) (2.6.0)\n",
            "Collecting outlines_core==0.1.26 (from outlines)\n",
            "  Downloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting genson (from outlines)\n",
            "  Downloading genson-1.3.0-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting pre-commit>=4.0.1 (from outlines)\n",
            "  Downloading pre_commit-4.1.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=4.0.1->outlines)\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=4.0.1->outlines)\n",
            "  Downloading identify-2.6.8-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=4.0.1->outlines)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=4.0.1->outlines) (6.0.2)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=4.0.1->outlines)\n",
            "  Downloading virtualenv-20.29.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->outlines) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->outlines) (2.27.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->outlines) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (0.23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outlines) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (3.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->outlines) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->outlines) (1.3.0)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (4.3.6)\n",
            "Downloading outlines-0.2.1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outlines_core-0.1.26-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.3/343.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.1.0-py2.py3-none-any.whl (220 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.6/220.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading airportsdata-20250224-py3-none-any.whl (913 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m913.7/913.7 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading genson-1.3.0-py3-none-any.whl (21 kB)\n",
            "Downloading interegular-0.3.3-py37-none-any.whl (23 kB)\n",
            "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.8-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading virtualenv-20.29.2-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: genson, distlib, virtualenv, nodeenv, lark, iso3166, interegular, identify, diskcache, cfgv, airportsdata, pre-commit, outlines_core, outlines\n",
            "Successfully installed airportsdata-20250224 cfgv-3.4.0 diskcache-5.6.3 distlib-0.3.9 genson-1.3.0 identify-2.6.8 interegular-0.3.3 iso3166-2.1.1 lark-1.2.2 nodeenv-1.9.1 outlines-0.2.1 outlines_core-0.1.26 pre-commit-4.1.0 virtualenv-20.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers==4.47.1 datasets==3.2.0 torch==2.5.1+cu124 torchvision==0.20.1+cu124\n",
        "!pip install tokenizers==0.21.0 bitsandbytes==0.45.1 peft==0.14.0 accelerate==1.2.1\n",
        "!pip install trl==0.12.0 unsloth ipykernel==5.5.6\n",
        "!pip install outlines"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tokenize import tokenize\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from google.colab import userdata\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,TrainingArguments, logging, pipeline\n",
        "from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n",
        "import torch\n",
        "from trl import SFTTrainer\n",
        "from google.colab import userdata\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from unsloth import FastLanguageModel\n",
        "\n"
      ],
      "metadata": {
        "id": "zEr6NZ0BDaQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ea097c-13c9-4a44-df77-ca1cb01e81c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset = load_dataset('json', data_files='converted_exam.json')\n",
        "# dataset['train']"
      ],
      "metadata": {
        "id": "NitS8QklDdoY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lSHi-MHC57WN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get(\"thongtestli\")\n",
        "\n",
        "# Khởi tạo tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    token=hf_token,\n",
        ")\n"
      ],
      "metadata": {
        "id": "D02VG9oGDjcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from datasets import Dataset, DatasetDict\n",
        "\n",
        "# # Hàm lấy Top K đề thi dựa trên số lượng token\n",
        "# def get_top_k_exams(dataset, token_counts, k):\n",
        "#     k = min(k, len(token_counts))  # Đảm bảo k không vượt quá số lượng dữ liệu thực tế\n",
        "#     top_k_indices = [int(i) for i in np.argsort(token_counts)[-k:][::-1]]  # Chuyển numpy.int64 thành int\n",
        "\n",
        "#     # Trích xuất dữ liệu theo chỉ số đã sắp xếp\n",
        "#     top_k_data = {\n",
        "#         \"exam_id\": [],\n",
        "#         \"sections\": []\n",
        "#     }\n",
        "\n",
        "#     for i in top_k_indices:\n",
        "#         if \"output\" in dataset[i] and isinstance(dataset[i][\"output\"], list):  # Kiểm tra output có tồn tại và là danh sách\n",
        "#             exam_sections = []\n",
        "#             for output_item in dataset[i][\"output\"]:\n",
        "#                 if isinstance(output_item, dict) and \"sections\" in output_item:  # Kiểm tra output_item là dict có \"sections\"\n",
        "#                     for section in output_item[\"sections\"]:\n",
        "#                         if all(key in section for key in [\"section_name\", \"section\", \"passage_text\", \"questions\"]):\n",
        "#                             exam_sections.append({\n",
        "#                                 \"section_name\": section[\"section_name\"],\n",
        "#                                 \"section\": section[\"section\"],\n",
        "#                                 \"passage_text\": section[\"passage_text\"],\n",
        "#                                 \"questions\": section[\"questions\"]\n",
        "#                             })\n",
        "\n",
        "#             if exam_sections:  # Chỉ thêm vào danh sách nếu có dữ liệu\n",
        "#                 top_k_data[\"exam_id\"].append(i)  # Lưu ID của đề thi\n",
        "#                 top_k_data[\"sections\"].append(exam_sections)  # Lưu danh sách sections\n",
        "\n",
        "#     return Dataset.from_dict(top_k_data)\n",
        "\n",
        "# # Giá trị k (số lượng đề thi muốn giữ lại)\n",
        "# k = 200\n",
        "\n",
        "# # Tạo DatasetDict mới để lưu trữ kết quả\n",
        "# filtered_datasets = {}\n",
        "\n",
        "# # Áp dụng cho tất cả các tập dữ liệu trong DatasetDict\n",
        "# for split in dataset.keys():  # Duyệt qua các tập dữ liệu như \"train\", \"validation\", \"test\"\n",
        "#     # Tính tổng số lượng token trong tất cả các đoạn passage_text của từng đề thi\n",
        "#     combined_token_counts = []\n",
        "\n",
        "#     for item in dataset[split]:\n",
        "#         total_tokens = 0\n",
        "#         if \"output\" in item and isinstance(item[\"output\"], list):  # Đảm bảo output là danh sách\n",
        "#             for output_item in item[\"output\"]:\n",
        "#                 if isinstance(output_item, dict) and \"sections\" in output_item:  # Kiểm tra output_item là dict có \"sections\"\n",
        "#                     total_tokens += sum(len(section[\"passage_text\"].split()) for section in output_item[\"sections\"] if \"passage_text\" in section)\n",
        "\n",
        "#         combined_token_counts.append(total_tokens)\n",
        "\n",
        "#     # Lọc Top K đề thi dựa trên số token\n",
        "#     top_k_dataset = get_top_k_exams(dataset[split], combined_token_counts, k)\n",
        "\n",
        "#     # Lưu vào DatasetDict mới\n",
        "#     filtered_datasets[split] = top_k_dataset\n",
        "\n",
        "# # Chuyển thành DatasetDict hoàn chỉnh\n",
        "# filtered_dataset = DatasetDict(filtered_datasets)\n",
        "\n",
        "# # In kết quả\n",
        "# print(f\"Tập dữ liệu sau khi lọc Top {k} đề thi: {filtered_dataset}\")\n"
      ],
      "metadata": {
        "id": "O9D0q54vDqOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hf_token = userdata.get('thongtestli')\n",
        "# dataset['train'].to_pandas()\n",
        "# dataset['train'].push_to_hub(\"English_exam03.03\", token=hf_token)"
      ],
      "metadata": {
        "id": "YxvokkK0Ds52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "dataset_name = \"testliai-main/English_exam03.03\"\n",
        "new_model = \"testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m\""
      ],
      "metadata": {
        "id": "XpQPS9OSNWAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(dataset_name)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7g27m1oaEspI",
        "outputId": "9b8e3881-cf6c-4e36-fba3-f63001eba1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output'],\n",
              "        num_rows: 176\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def formatting_prompts_func(examples):\n",
        "    prompts = []\n",
        "\n",
        "    for exam in examples:  # Duyệt qua từng đề thi trong danh sách output\n",
        "        if isinstance(exam, dict):  # Kiểm tra xem exam có phải là dict không\n",
        "            level = exam.get(\"input\", {}).get(\"level\", \"unspecified\")  # Lấy mức độ khó của đề (Easy, Intermediate, Advanced)\n",
        "        else:\n",
        "            continue  # Bỏ qua nếu exam không phải là dict\n",
        "\n",
        "        # Bắt đầu prompt với hướng dẫn rõ ràng\n",
        "        prompt = f\"### English Exam Generator ###\\n\\n\"\n",
        "        prompt += f\"Generate a brand-new English exam at the {level} level.\\n\"\n",
        "        prompt += f\"Follow the same format as learned.\\n\\n\"\n",
        "        prompt += f\"### English Exam ###\\n\\n\"\n",
        "\n",
        "        for section in exam.get(\"sections\", []):  # Duyệt qua từng phần của đề thi\n",
        "            prompt += f\"**Section: {section.get('section_name', 'Unnamed Section')}**\\n\"\n",
        "\n",
        "            passage_text = section.get(\"passage_text\", \"\").strip()\n",
        "            if passage_text:  # Nếu có đoạn văn thì thêm vào prompt\n",
        "                prompt += f\"Passage:\\n{passage_text}\\n\\n\"\n",
        "\n",
        "            prompt += \"Questions:\\n\"\n",
        "            for question in section.get(\"questions\", []):\n",
        "                prompt += f\"- {question.get('question_text', 'No question text available')}\\n\"\n",
        "                for idx, option in enumerate(question.get(\"options\", [])):\n",
        "                    prompt += f\"  {idx}. {option}\\n\"\n",
        "                prompt += \"\\n\"\n",
        "\n",
        "        prompt += f\"{EOS_TOKEN}\\n\"  # Thêm token kết thúc để mô hình nhận diện\n",
        "        prompts.append(prompt)\n",
        "\n",
        "    return {\"prompt\": prompts}\n",
        "\n",
        "# Đảm bảo rằng EOS_TOKEN được định nghĩa\n",
        "EOS_TOKEN = \"<|endoftext|>\"  # Nếu tokenizer.eos_token không khả dụng, có thể sử dụng chuỗi này\n",
        "\n",
        "# Tạo dataset mới với định dạng prompt\n",
        "if \"dataset\" in globals():\n",
        "    dataset = dataset.map(formatting_prompts_func)\n"
      ],
      "metadata": {
        "id": "i2__PzkIDv79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T02P4N-EG_rW",
        "outputId": "e2e37e82-6340-44f6-baa4-936b2c837d05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar  3 13:13:03 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   29C    P0             41W /  400W |       5MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNskHj78StOs",
        "outputId": "5bdf65c7-9fdb-455a-88b2-88eae99b3eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output', 'prompt'],\n",
              "        num_rows: 176\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hf_token = userdata.get('thongtestli')\n",
        "max_seq_length = 6144\n",
        "dtype=torch.float16\n",
        "load_in_4bit = False\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=base_model,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        "    token=hf_token,\n",
        ")\n",
        "\n",
        "# Configure tokenizer\n",
        "tokenizer.padding_side = 'right'\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.add_special_tokens({'eos_token': tokenizer.eos_token, 'bos_token': tokenizer.bos_token})\n",
        "\n",
        "# Configure the model with LoRA\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,  # Suggested values: 8, 16, 32, 64, 128\n",
        "    target_modules=[\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "    ],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,  # Optimized when set to 0\n",
        "    bias=\"none\",     # Optimized with \"none\"\n",
        "    use_gradient_checkpointing=True,  # Set \"True\" or a specific method supported\n",
        "    random_state=3407,\n",
        "    use_rslora=False,   # Optional: Rank-stabilized LoRA\n",
        "    loftq_config=None,  # Optional: LoFT Quantization config\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "87aaec3e95994cd2ba627b36eac640e3",
            "9b496d957025420b81cfd0a7a69b4688",
            "6d16dbdda5074a97a23ca3fbb3d338fc",
            "5c9616b79e844b92b2e32dd9d6b2ba73",
            "2ad00772a72d4ff39d78ee9a7867cca7",
            "0565f22b822a48efa46682fcf2129d51",
            "b5f244dce30e4816b21258182f091e92",
            "c35d12adc3394343aa7ea35f28979487",
            "f2624865902a4afbb282a9e4d29d0b90",
            "08f05af0a2124925929e38bf0cf846ce",
            "0d261ae08588473ebe6d88ea96b87e52"
          ]
        },
        "id": "gFMKE2icE0yO",
        "outputId": "163ddd99-16b9-4b5c-cfe0-a6b752d80b35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.2.15: Fast Mistral patching. Transformers: 4.47.1.\n",
            "   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87aaec3e95994cd2ba627b36eac640e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_output_text(example):\n",
        "    \"\"\"Extract text from the 'output' field into a usable format.\"\"\"\n",
        "    sections_text = []\n",
        "\n",
        "    for output in example.get(\"output\", []):\n",
        "        for section in output.get(\"sections\", []):\n",
        "            text = f\"Section: {section.get('section_name', 'Unnamed Section')}\\n\"\n",
        "            if section.get(\"passage_text\"):\n",
        "                text += f\"Passage:\\n{section['passage_text']}\\n\\n\"\n",
        "            text += \"Questions:\\n\"\n",
        "            for q in section.get(\"questions\", []):\n",
        "                text += f\"- {q.get('question_text', '')}\\n\"\n",
        "                for idx, option in enumerate(q.get(\"options\", [])):\n",
        "                    text += f\"  {idx}. {option}\\n\"\n",
        "            sections_text.append(text)\n",
        "\n",
        "    return {\"formatted_output\": \"\\n\".join(sections_text)}\n",
        "\n",
        "# Apply transformation\n",
        "dataset = dataset.map(format_output_text)\n",
        "\n",
        "# Now use \"formatted_output\" for training\n",
        "dataset_text_field=\"formatted_output\"\n"
      ],
      "metadata": {
        "id": "WvskYrm9VJqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(dataset['train'][i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TNy9czBUZCu",
        "outputId": "2ac7ac6a-74f2-48b5-ac75-fc57082e7a7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': {'level': 'easy', 'prompt': 'Generate a new English exam'}, 'output': [{'exam_number': 1, 'sections': [{'passage_text': 'Water is very important for life. It has many special ____ (1)____. It freezes and becomes ice which is____ (2)____ than water that stays liquid. Unlike many liquids, water ____(3)_____ when it becomes ice. Ice is essential _ _(4)_ _ for most natural creatures to survive in colder months. Because water is a solvent, it can ____ (5)_____ many different substances. Also, it takes quite a long time for its _____ (6)____ to change.', 'questions': [{'correct_option': 1, 'options': ['things', 'properties', 'materials', 'shapes'], 'question_text': 'What should be put in the blank (number 1)?'}, {'correct_option': 3, 'options': ['cooler', 'smaller', 'hotter', 'larger'], 'question_text': 'What is number (2)?'}, {'correct_option': 1, 'options': ['melts', 'expands', 'freezes', 'shrinks'], 'question_text': 'Choose only one option to fill the blank labeled (3)?'}, {'correct_option': 1, 'options': ['help', 'helps', 'helping', 'is helping'], 'question_text': 'What is the correct helping verb for the phrase in Question 4, labeled 4?'}, {'correct_option': 0, 'options': ['dissolve', 'add', 'mix', 'change'], 'question_text': 'Which verb should be put into this blank (the fifth part)?'}, {'correct_option': 0, 'options': ['temperature', 'color', 'size', 'weight'], 'question_text': 'Which word should be placed in the blank at the end of the passage?'}], 'section': 1, 'section_name': 'Cloze Grammar Vocabulary'}, {'passage_text': 'My dream home is a cozy cottage. I imagine it by a (1)_____, where I can ________(2)_____ the view all day. It would be surrounded by a beautiful, colorful and _______(3)_______ garden. Inside the house, I envision a ______ (4) ________ with sunlight streaming on my favorite novels, with lots of ______(5)__________ from which I love drinking tea. Furthermore, my bed in a comfy bedroom has a _________ (6)______ comforter.', 'questions': [{'correct_option': 2, 'options': ['river', 'garden', 'lake', 'house'], 'question_text': 'Which place name is a common feature of gardens?'}, {'correct_option': 1, 'options': ['eat', 'enjoy', 'purchase', 'borrow'], 'question_text': 'Select a suitable verb relating to appreciation of the view.'}, {'correct_option': 2, 'options': ['sad', 'dull', 'beautiful', 'expensive'], 'question_text': 'What adjective best describes an attractive feature in home decoration?'}, {'correct_option': 1, 'options': ['kitchen', 'reading room', 'outside', 'restaurant'], 'question_text': 'Choose the option describing where personal items are kept.'}, {'correct_option': 2, 'options': ['chairs', 'pillows', 'cups', 'sofas'], 'question_text': 'This word refers to a cozy feature and is generally associated with what?'}, {'correct_option': 3, 'options': ['hard', 'beautiful', 'colourful', 'pillows'], 'question_text': 'Which common and cozy object is normally included in bedding?'}], 'section': 2, 'section_name': 'Cloze Contextual Vocabulary'}, {'passage_text': '', 'questions': [{'correct_option': 1, 'options': [\"This is only a part of evolution! It won't make people lazy! I want to give examples.\", 'Robots will just become partners: humans must be better!.', \"Is that very clear now? If you are afraid of Robots, change, and progress?, it reflects too much a pessimist mindset. What's up?\", 'Better partners for sure!; but is the quality higher?'], 'question_text': 'Choose the best way for giving an additional supportive argument at level A2 on the possible positive impacts of AI. Order options to achieve a coherent short utterance supporting this idea.'}, {'correct_option': 2, 'options': ['1. \"Can robots be creative?\" 2. \"I think so. Some robots can write music.\" 3. \"Oh, really? What do you mean?\" 4. \"Wow, is that true?\"', '1. \"What are your feelings about AI?\" 2. \"This is my own feeling: I fear automation.\" 3. \"Me too! Can we trust new Technologies and AI? I\\'m doubtful.\" 4. \"Really unbelievable is what I\\'m thinking!\"', '1. \"I\\'m worried that AI will replace many people at work.\" 2. \"Yes, it\\'s one more side of automation; Robots and Machines increase every day.\" 3. \"We have more time without too hard jobs, right? We do less work! Amazing! I like this idea.\"', '1. Will robots have too much influence on artistic creative activities? 2. Robots and AI in literature and film will greatly increase the quality of creative contents. They work harder than many Writers and Creators! 3. Some aspects for sure. People and Art will still be here without robotic replacement I think, no? 4. \"That makes some sense! Good! Absolutely!\"'], 'question_text': \"Arrange these utterances to make a logical conversation showing people's concerns about AI and creativity in simple sentences appropriate for Level A2.\"}, {'correct_option': 0, 'options': ['A. I adore my elder protective brother! His experience really matters. That’s awesome 1! B. And then my parents. Their amazing and understanding always helps us when we struggle. This is too good to let away! Yeah! C. This means I really hope my dream never dies 1! my family’s best. A happy home indeed!', 'A. Our house creates all this! That’s my dream home. Then, this harmonious lovely friendly warm house brings so many joy times moments which makes B. A huge plus Everyone contributes to the lovely joyful environment That, of course, really help members C. Then, my little caring lovely sister…,This brings fun daily in most periods.', \"...Then also having my parents …That´s really quite something!, ...this would not actually become if this does exist now…,B These family units..My dog and my dad.. It's difficult this to maintain balance and stay cool in many daily situations., A. And because there is lovely warm care together. This makes an actual family ideal at it!. C. We, are a harmonious lovely wonderful strong bunch; so many dreams in its ideal world.\", 'A. Then the dog makes us smile more. Also a special thing My father cooks too sometimes.; I truly really am very lucky! , The main persons then , are my parents…. B…. Our life has made everyone special in one way!…that adds to more harmony, and… happy feeling of being together like all the members ! Then again…. Then our little lovely pet makes that better… My C. sister truly cheers up my life!... This all really does indeed make every each days happy!'], 'question_text': 'What choice would show the text arranged more suitably naturally and meaningfully which details our small/happy family’s joyful environment and home? ( The question about 7 sentences in given alternatives 0,1,2 và 3 but only some sentences contain one same main point; each is from A->C)'}, {'correct_option': 3, 'options': ['I live with my family members happily together, then this small cozy environment we like also includes a nice dog and other beloved pets. 2. Members of Family, that is one major thing. 3. Although… My family and my home also provides a nice place so you probably will really feel secure.', 'This makes an even bigger family than often imaginable initially, So our harmony in this quite big big home provides our family with unique harmony in an unbelievably quiet moment. Every time each family gets along very well; 1. Family home. One group of Members: a big, happy clan, and. 3.', 'We love playing games and having BBQ together because most members like it that means having barbecue together in weekends, we play badminton most weekends or watch football matches together when there free times, and 2. Members in the ideal family will feel lucky; A secure home offers ideal time to meet as usual this is the most time to see everybody 3. this happy friendly feeling also fills their lovely family with many best wishes .', '1. Our family home, is not really big you see, However, although..., 2. The most wonderful moments of life that will always support, and 3. Being all members with our own style does give our life a special taste, you would remember a special type with an impression making one family with positive points unique values at it.'], 'question_text': 'Which would the best order be that will tell about one’s family happily based provided texts?'}, {'correct_option': 1, 'options': ['1. Then, there is my kind younger sister, she and I spend a fun time. 2. My nice lovely father is both funny and strict on us 3. My mother’s patience has always touched most members since we really admire it. Our family includes.', '1. My Family includes my lovely brother Peter; he is my friend. 2. We celebrate big days warmly in my unique, unforgettable family members. 3. Then we also have my mum, a very clever one who always makes everything much smoother. Next...', '1.This member actually makes us comfortable and happy, we’re often supported when together like all friends, 2. This is the harmony I like most at my home’s family and would show you in reality 3.Our mother shows what kind of a friendly mother with so nice style that often make things smooth whenever everything is confused. I always have my friend...', '1.They add so harmonious atmosphere whenever everyone gathers at big events to feel as friend. Especially… They support and cover one another 2. Then, there’s my very clever and wise brother, Nick 3. We always have much good times. Our lovely mother This family group has…. \"'], 'question_text': 'Choose a good example following the order that allows talking something about a harmonious family reasonably and naturally, 4 text fragments are available, decide this based on text information:'}], 'section': 3, 'section_name': 'Best Arrangement of Utterances'}, {'passage_text': \"Our bodies are like tiny universes! Many tiny living things, called microbes, live inside us. These are too small to see without a special tool called a microscope. Some microbes help us digest food. Others protect us from illness. These helpful microbes are called 'good' bacteria. But some microbes can make us sick; these are called 'bad' germs.\", 'questions': [{'correct_option': 1, 'options': ['viruses', 'microbes', 'atoms', 'cells'], 'question_text': 'What are the tiny living helpers and bad germs called combined?'}, {'correct_option': 1, 'options': ['a telescope', 'a microscope', 'a magnifying glass', 'binoculars'], 'question_text': 'What special tool do we use to see microbes which cannot be seen without?'}, {'correct_option': 2, 'options': ['water', 'air', 'food', 'sunlight'], 'question_text': 'Good microbes (bacteria) help what?'}, {'correct_option': 0, 'options': ['germs', 'microbes', 'bacteria', 'bugs'], 'question_text': 'Which word helps identify only the disease-causing types among these (but overall all includes microbes)?'}, {'correct_option': 1, 'options': ['helpful', 'harmful', 'small', 'all'], 'question_text': 'What kind of microbes such as (bacteria, microbes) can both protect against being sick and/or could make what is wrong occur within our internal organism or system?'}], 'section': 4, 'section_name': 'Cloze Informational Comprehension'}, {'passage_text': 'Protecting our environment is very important. We can help by reducing waste. Try to reuse bags and bottles. Recycling paper, plastic, and glass helps a lot. Planting trees and cleaning litter also play a part. Together, everyone makes a big impact on the environment.', 'questions': [{'correct_option': 1, 'options': ['Burning more garbage', 'Reusing bags and bottles', 'Increasing transportation use', 'Cutting more trees'], 'question_text': 'What is one good initiative which helps protect our precious environment and contributes toward waste alleviation?'}, {'correct_option': 0, 'options': ['Planting trees lowers carbon levels', 'We increase carbon when watering our home gardens', 'Cleaning plastic is never environmentally positive', 'Recycling makes our Earth look nicer, improving appearances'], 'question_text': 'Choose the most useful contribution in an effort focused on protecting our environment amongst these points highlighted for the purpose of creating environmentally favorable approaches that serve us now and tomorrow and further sustainability.'}, {'correct_option': 1, 'options': ['Making more rubbish every day', 'Using less energy', 'Driving a gasoline fueled car all alone instead of using mass transit and cycling to cut back on carbon impact, for an improvement upon environment, toward better world conservation, in an interest toward long-term impacts for conservation', 'Using more oil'], 'question_text': \"Of the following selections presented, which initiative best aligns successfully with efforts dedicated towards securing Earth's long term positive preservation of habitats with a goal in a good way successfully achieving our environmental protection tasks at the peak achievable highest efforts involved, to successfully work to obtain the conservation objective required?\"}, {'correct_option': 0, 'options': ['Reducing waste', 'Cutting more paper', 'Driving a petrol fueled vehicles around constantly', 'Producing more garbage on a daily and routine occurring scale basis highly impacting surrounding natural regions'], 'question_text': \"Which among the below described possibilities successfully contribute with no exceptions to minimizing pollution on Earth's already burdened environmental and natural ecological assets negatively affected impacted by continuous pollutant emissions?\"}, {'correct_option': 2, 'options': ['Burning plastic every time this gets disposed of within our homes on our personal living location´s area regularly as habitual procedure', 'Only littering if at all only doing such minimal amounts environmentally insignificant', 'Reducing, reusing and recycling are effective ways of helping improve and help environmentally to increase protective initiatives for better sustainability and maintaining environmentally good preservation approaches', 'Cutting down all new, young saplings on newly established developing farms for re-planting'], 'question_text': 'Which of the following measures is considered most beneficial related specifically geared toward positive environmental enhancement activities specifically working, successfully towards maintaining successful preservation success with effective actions in practice for the long-range environmentally valuable impactful protection of natural habitat successfully being carried-forth to obtain the success desired in good time in our effort maintaining biodiversity effectively with actions having the best possible output impacts in environmental betterment actively pursuing better protective methods of habitat maintenance'}, {'correct_option': 2, 'options': ['We should increase the number of motor vehicles', 'Never switch and make good use our older gadgets at present being functional still working appropriately', 'Recycling is helpful', 'More cutting of the trees from environmentally precious woodlands'], 'question_text': 'What are among the most effective in the protection our land effectively against pollution related damage caused specifically as relates to human interventions that impact environmentally with negative outputs from environmentally adverse outputs of impacts produced directly from detrimental human activity interfering adversely impacting in adverse manner´resulting damage ecologically harmful, which ones can be considered contributing mostly favorably positively improving conservation strategies effectively?'}, {'correct_option': 2, 'options': ['Collecting empty plastic bags for disposing by means incineration', 'Continue buying water only from plastic, rather only doing purchasing in individual bottle-size packs.', 'Planting new seedling trees of many varying types of tree saplings whenever and wherever possible to carry out continuous and continual new planting and replenishing projects to create and cultivate future growth projects in which we grow trees continuously and often so forestation may constantly go-ahead', 'Produce far more quantity of refuse as opposed less to before doing prior previously to implementation'], 'question_text': 'What method works suitably towards conservation effort actively engaged positively advancing environmentally improving sustainable ways actively functioning so working positively benefiting efforts, helping positively impacting environments actively helping actively engage protecting various valuable and precious environmentally valuable natural preservation effective initiatives in achieving environmental protective betterment goals.'}, {'correct_option': 0, 'options': ['Using public transportation methods, or riding a cycling whenever possible reducing or omitting when able using individual usage of motor automotive transportation', 'Continuously producing consistently increased outputs environmentally harmful negatively impacting output by volume continually without fail', 'Making very sizable volumes highly increased and massively expanded garbage output quantity. More', 'Dispensing completely without fail always immediately after utilization every instance consistently without delaying doing so any amount that occurs immediately after making new items immediately'], 'question_text': 'What should be done best working toward our actively making efforts toward effective better actively involved approaches contributing to making our actions focused protecting toward ensuring better environmentally healthy outputs obtained, most particularly having sustainable positive impact for our positive long-term results environmentally effectively resulting successful achievements environmentally beneficial effective outputs aimed improving Earth long-term conservation effectively helping sustainability'}, {'correct_option': 3, 'options': ['Producing as much garbage we can every possible time frequently', 'Using and implementing regularly continually frequently repeatedly high usage quantities utilizing energy levels extremely elevated exceedingly large scale output energy consumption greatly heightened levels', 'Polluting as many sites we frequent to make impact whenever feasible possible with whatever time convenient consistently making high impacts on the most number total areas and impacting many possible locations environmentally very much', 'Planting more and more of greater quantities constantly maintaining consistently as highly much number possible many more various sorts and types assorted tree tree seedling of sorts various widely differing saplings from those we already maintain'], 'question_text': 'The best manner forward towards successfully increasing Earth maintenance toward better effectively environmentally protected Earth sustainably managing positively securing long- term positively achieving great improving results on effective outcomes for successfully achieving positive great environmental effects from actions that will assist working toward improvements to better maintenance securing healthy planet Earth making greatly impact improvements for the highest achieving improved impact resulting good healthy sustainably maintained better earth outcome result success resulting sustainable great improvement positive lasting great successfully maintained and preserved health of Earth successful result of such initiatives positive output environmentally greatly enhanced and successful'}], 'section': 5, 'section_name': 'Reading Comprehension'}, {'passage_text': \"Long ago, in a village nestled beside a whispering forest, lived a young girl named Mai. Mai found a mysterious map tucked inside an old book. The map depicted a winding path leading to a glistening tree said to grant wishes. Intrigued, Mai set off with her mischievous cat, Bin, acting as her guide. Their journey began amidst vibrant flowers and birds chirping melodies. Yet, along a river bank shaded by willows where mysterious spirits lurked, a puzzling riddle stopped her: 'What never asks yet replies faithfully, always says yes, but can seldom stay upright?' Bin looked as perplexed. The tree was near, but Mai knew that she was being tested; not mere navigation but her wit. Further on was an old wooden bridge spanning over a ravine, showing early stages of rottenness. To a concerned traveler, this tested Mai's quick and agile ability which passed fairly safely; Mai and Bin felt relief knowing they overcame the hurdle. Finally seeing the glistening magical tree, Mai expressed her greatest true wish: A world filled with more joy, love, and kindness. The mighty shimmering beams enveloped both her and her true guide friend Bin.\", 'questions': [{'correct_option': 2, 'options': ['The map showed the way to a nearby town.', 'The map was in a book describing old maps and legends of magical creatures.', 'The map guided Mai to a tree which grants wishes.', 'The map led to a deep dark jungle and many hidden treasures.'], 'question_text': 'First, what did the magical map show specifically?'}, {'correct_option': 3, 'options': ['Birds sang pleasantly, flowers were absent.', 'Mai journeyed solely.', 'A river-banks filled with shady lush-green trees, however, animals were present.', 'Obstacles presented before Mai, testing her ability.'], 'question_text': 'What was unique about the second part of Mai’s mysterious early magical journey?'}, {'correct_option': 3, 'options': ['A person.', 'A mountain.', 'The sky or star.', 'An echo.'], 'question_text': 'What did the riddle likely suggest based on hints?'}, {'correct_option': 1, 'options': ['She ignored it and took shortcuts.', 'She passed, the decaying appearance indicating a need for skill and caution to negotiate.', 'The obstacles simply presented the easy route path to get quicker there in front of all dangers.', 'There is another similar bridge close by.'], 'question_text': \"How did Mai deal with the bridge's fragility (poor nature)?\"}, {'correct_option': 2, 'options': ['More toys', 'The disappearance of Bin instantly', 'Peace and happiness spreading throughout the whole of entire.', 'Finding a hidden cave nearby river.'], 'question_text': 'Mai’s wish implied that she what sincerely yearned deepest?'}, {'correct_option': 3, 'options': ['Magical power of the river,', 'Magical strength coming to both Mai and her special friend.', 'The will she possesses, the ability of magic', 'Mutual love with companion showing mutual support despite struggles that challenges showed during tough journey helping overcame all those trials that the journey presented.'], 'question_text': 'What finally successfully passed the entire journey showing?'}, {'correct_option': 3, 'options': ['A journey without challenges.', 'A long adventure that ultimately led up ending sadly which never produced positive impacts.', 'Journey ending perfectly, having happily ever after.', 'A long, complicated, confusing yet successful journey to overcome her final greatest wish ending as happy unexpectedly even despite being filled all obstacles from earlier stages during those perilous journey throughout dangerous situations. She is gifted something unexpectedly more fulfilling after successfully passing hard hurdles during those risky times encountered.'], 'question_text': 'What kind of journey did Mai overall experience ultimately end what?'}, {'correct_option': 1, 'options': ['Mai showed fear easily throughout those challenging path she passed those tough moments.', 'Bin, a crucial aid and support throughout perilous paths, helped Mai all trials.', 'Mai always faced obstacles single-handedly.', \"Mai didn't require any assistance at her challenges passing the route.\"], 'question_text': 'The tale highlighted who specifically was support helpful for Mai for all that crucial obstacles moments she passed during this?'}, {'correct_option': 2, 'options': ['She used a map to get what she really desperately truly needed for long.', 'The story is ultimately meant that some things exist solely within those places not readily capable experiencing for any travelers simply wishing on places easily reached.', 'The journey shows Mai discovering true magical experience, inner happiness with supporting friend which brought meaningful ending. That experience ultimately led to greatest unexpected rewards greater what she has never thought possible earlier simply by believing journey worth having even facing challenges which were ultimately what brought ultimate greatest discoveries for such meaningful happy life-lasting moments journey made.', 'The conclusion implied some form of disappointment as what had occurred throughout final moments she truly cherished despite any efforts towards greatest expectations having initially envisioned as starting initial path undertaken showing that sometimes initial path initially imagined is the best choice always afterall.'], 'question_text': 'By analyzing the full extent storyline with its context ultimately suggests truly message the story suggests ultimately means is?'}], 'section': 6, 'section_name': 'Reading Comprehension Advanced'}]}], 'prompt': [], 'formatted_output': 'Section: Cloze Grammar Vocabulary\\nPassage:\\nWater is very important for life. It has many special ____ (1)____. It freezes and becomes ice which is____ (2)____ than water that stays liquid. Unlike many liquids, water ____(3)_____ when it becomes ice. Ice is essential _ _(4)_ _ for most natural creatures to survive in colder months. Because water is a solvent, it can ____ (5)_____ many different substances. Also, it takes quite a long time for its _____ (6)____ to change.\\n\\nQuestions:\\n- What should be put in the blank (number 1)?\\n  0. things\\n  1. properties\\n  2. materials\\n  3. shapes\\n- What is number (2)?\\n  0. cooler\\n  1. smaller\\n  2. hotter\\n  3. larger\\n- Choose only one option to fill the blank labeled (3)?\\n  0. melts\\n  1. expands\\n  2. freezes\\n  3. shrinks\\n- What is the correct helping verb for the phrase in Question 4, labeled 4?\\n  0. help\\n  1. helps\\n  2. helping\\n  3. is helping\\n- Which verb should be put into this blank (the fifth part)?\\n  0. dissolve\\n  1. add\\n  2. mix\\n  3. change\\n- Which word should be placed in the blank at the end of the passage?\\n  0. temperature\\n  1. color\\n  2. size\\n  3. weight\\n\\nSection: Cloze Contextual Vocabulary\\nPassage:\\nMy dream home is a cozy cottage. I imagine it by a (1)_____, where I can ________(2)_____ the view all day. It would be surrounded by a beautiful, colorful and _______(3)_______ garden. Inside the house, I envision a ______ (4) ________ with sunlight streaming on my favorite novels, with lots of ______(5)__________ from which I love drinking tea. Furthermore, my bed in a comfy bedroom has a _________ (6)______ comforter.\\n\\nQuestions:\\n- Which place name is a common feature of gardens?\\n  0. river\\n  1. garden\\n  2. lake\\n  3. house\\n- Select a suitable verb relating to appreciation of the view.\\n  0. eat\\n  1. enjoy\\n  2. purchase\\n  3. borrow\\n- What adjective best describes an attractive feature in home decoration?\\n  0. sad\\n  1. dull\\n  2. beautiful\\n  3. expensive\\n- Choose the option describing where personal items are kept.\\n  0. kitchen\\n  1. reading room\\n  2. outside\\n  3. restaurant\\n- This word refers to a cozy feature and is generally associated with what?\\n  0. chairs\\n  1. pillows\\n  2. cups\\n  3. sofas\\n- Which common and cozy object is normally included in bedding?\\n  0. hard\\n  1. beautiful\\n  2. colourful\\n  3. pillows\\n\\nSection: Best Arrangement of Utterances\\nQuestions:\\n- Choose the best way for giving an additional supportive argument at level A2 on the possible positive impacts of AI. Order options to achieve a coherent short utterance supporting this idea.\\n  0. This is only a part of evolution! It won\\'t make people lazy! I want to give examples.\\n  1. Robots will just become partners: humans must be better!.\\n  2. Is that very clear now? If you are afraid of Robots, change, and progress?, it reflects too much a pessimist mindset. What\\'s up?\\n  3. Better partners for sure!; but is the quality higher?\\n- Arrange these utterances to make a logical conversation showing people\\'s concerns about AI and creativity in simple sentences appropriate for Level A2.\\n  0. 1. \"Can robots be creative?\" 2. \"I think so. Some robots can write music.\" 3. \"Oh, really? What do you mean?\" 4. \"Wow, is that true?\"\\n  1. 1. \"What are your feelings about AI?\" 2. \"This is my own feeling: I fear automation.\" 3. \"Me too! Can we trust new Technologies and AI? I\\'m doubtful.\" 4. \"Really unbelievable is what I\\'m thinking!\"\\n  2. 1. \"I\\'m worried that AI will replace many people at work.\" 2. \"Yes, it\\'s one more side of automation; Robots and Machines increase every day.\" 3. \"We have more time without too hard jobs, right? We do less work! Amazing! I like this idea.\"\\n  3. 1. Will robots have too much influence on artistic creative activities? 2. Robots and AI in literature and film will greatly increase the quality of creative contents. They work harder than many Writers and Creators! 3. Some aspects for sure. People and Art will still be here without robotic replacement I think, no? 4. \"That makes some sense! Good! Absolutely!\"\\n- What choice would show the text arranged more suitably naturally and meaningfully which details our small/happy family’s joyful environment and home? ( The question about 7 sentences in given alternatives 0,1,2 và 3 but only some sentences contain one same main point; each is from A->C)\\n  0. A. I adore my elder protective brother! His experience really matters. That’s awesome 1! B. And then my parents. Their amazing and understanding always helps us when we struggle. This is too good to let away! Yeah! C. This means I really hope my dream never dies 1! my family’s best. A happy home indeed!\\n  1. A. Our house creates all this! That’s my dream home. Then, this harmonious lovely friendly warm house brings so many joy times moments which makes B. A huge plus Everyone contributes to the lovely joyful environment That, of course, really help members C. Then, my little caring lovely sister…,This brings fun daily in most periods.\\n  2. ...Then also having my parents …That´s really quite something!, ...this would not actually become if this does exist now…,B These family units..My dog and my dad.. It\\'s difficult this to maintain balance and stay cool in many daily situations., A. And because there is lovely warm care together. This makes an actual family ideal at it!. C. We, are a harmonious lovely wonderful strong bunch; so many dreams in its ideal world.\\n  3. A. Then the dog makes us smile more. Also a special thing My father cooks too sometimes.; I truly really am very lucky! , The main persons then , are my parents…. B…. Our life has made everyone special in one way!…that adds to more harmony, and… happy feeling of being together like all the members ! Then again…. Then our little lovely pet makes that better… My C. sister truly cheers up my life!... This all really does indeed make every each days happy!\\n- Which would the best order be that will tell about one’s family happily based provided texts?\\n  0. I live with my family members happily together, then this small cozy environment we like also includes a nice dog and other beloved pets. 2. Members of Family, that is one major thing. 3. Although… My family and my home also provides a nice place so you probably will really feel secure.\\n  1. This makes an even bigger family than often imaginable initially, So our harmony in this quite big big home provides our family with unique harmony in an unbelievably quiet moment. Every time each family gets along very well; 1. Family home. One group of Members: a big, happy clan, and. 3.\\n  2. We love playing games and having BBQ together because most members like it that means having barbecue together in weekends, we play badminton most weekends or watch football matches together when there free times, and 2. Members in the ideal family will feel lucky; A secure home offers ideal time to meet as usual this is the most time to see everybody 3. this happy friendly feeling also fills their lovely family with many best wishes .\\n  3. 1. Our family home, is not really big you see, However, although..., 2. The most wonderful moments of life that will always support, and 3. Being all members with our own style does give our life a special taste, you would remember a special type with an impression making one family with positive points unique values at it.\\n- Choose a good example following the order that allows talking something about a harmonious family reasonably and naturally, 4 text fragments are available, decide this based on text information:\\n  0. 1. Then, there is my kind younger sister, she and I spend a fun time. 2. My nice lovely father is both funny and strict on us 3. My mother’s patience has always touched most members since we really admire it. Our family includes.\\n  1. 1. My Family includes my lovely brother Peter; he is my friend. 2. We celebrate big days warmly in my unique, unforgettable family members. 3. Then we also have my mum, a very clever one who always makes everything much smoother. Next...\\n  2. 1.This member actually makes us comfortable and happy, we’re often supported when together like all friends, 2. This is the harmony I like most at my home’s family and would show you in reality 3.Our mother shows what kind of a friendly mother with so nice style that often make things smooth whenever everything is confused. I always have my friend...\\n  3. 1.They add so harmonious atmosphere whenever everyone gathers at big events to feel as friend. Especially… They support and cover one another 2. Then, there’s my very clever and wise brother, Nick 3. We always have much good times. Our lovely mother This family group has…. \"\\n\\nSection: Cloze Informational Comprehension\\nPassage:\\nOur bodies are like tiny universes! Many tiny living things, called microbes, live inside us. These are too small to see without a special tool called a microscope. Some microbes help us digest food. Others protect us from illness. These helpful microbes are called \\'good\\' bacteria. But some microbes can make us sick; these are called \\'bad\\' germs.\\n\\nQuestions:\\n- What are the tiny living helpers and bad germs called combined?\\n  0. viruses\\n  1. microbes\\n  2. atoms\\n  3. cells\\n- What special tool do we use to see microbes which cannot be seen without?\\n  0. a telescope\\n  1. a microscope\\n  2. a magnifying glass\\n  3. binoculars\\n- Good microbes (bacteria) help what?\\n  0. water\\n  1. air\\n  2. food\\n  3. sunlight\\n- Which word helps identify only the disease-causing types among these (but overall all includes microbes)?\\n  0. germs\\n  1. microbes\\n  2. bacteria\\n  3. bugs\\n- What kind of microbes such as (bacteria, microbes) can both protect against being sick and/or could make what is wrong occur within our internal organism or system?\\n  0. helpful\\n  1. harmful\\n  2. small\\n  3. all\\n\\nSection: Reading Comprehension\\nPassage:\\nProtecting our environment is very important. We can help by reducing waste. Try to reuse bags and bottles. Recycling paper, plastic, and glass helps a lot. Planting trees and cleaning litter also play a part. Together, everyone makes a big impact on the environment.\\n\\nQuestions:\\n- What is one good initiative which helps protect our precious environment and contributes toward waste alleviation?\\n  0. Burning more garbage\\n  1. Reusing bags and bottles\\n  2. Increasing transportation use\\n  3. Cutting more trees\\n- Choose the most useful contribution in an effort focused on protecting our environment amongst these points highlighted for the purpose of creating environmentally favorable approaches that serve us now and tomorrow and further sustainability.\\n  0. Planting trees lowers carbon levels\\n  1. We increase carbon when watering our home gardens\\n  2. Cleaning plastic is never environmentally positive\\n  3. Recycling makes our Earth look nicer, improving appearances\\n- Of the following selections presented, which initiative best aligns successfully with efforts dedicated towards securing Earth\\'s long term positive preservation of habitats with a goal in a good way successfully achieving our environmental protection tasks at the peak achievable highest efforts involved, to successfully work to obtain the conservation objective required?\\n  0. Making more rubbish every day\\n  1. Using less energy\\n  2. Driving a gasoline fueled car all alone instead of using mass transit and cycling to cut back on carbon impact, for an improvement upon environment, toward better world conservation, in an interest toward long-term impacts for conservation\\n  3. Using more oil\\n- Which among the below described possibilities successfully contribute with no exceptions to minimizing pollution on Earth\\'s already burdened environmental and natural ecological assets negatively affected impacted by continuous pollutant emissions?\\n  0. Reducing waste\\n  1. Cutting more paper\\n  2. Driving a petrol fueled vehicles around constantly\\n  3. Producing more garbage on a daily and routine occurring scale basis highly impacting surrounding natural regions\\n- Which of the following measures is considered most beneficial related specifically geared toward positive environmental enhancement activities specifically working, successfully towards maintaining successful preservation success with effective actions in practice for the long-range environmentally valuable impactful protection of natural habitat successfully being carried-forth to obtain the success desired in good time in our effort maintaining biodiversity effectively with actions having the best possible output impacts in environmental betterment actively pursuing better protective methods of habitat maintenance\\n  0. Burning plastic every time this gets disposed of within our homes on our personal living location´s area regularly as habitual procedure\\n  1. Only littering if at all only doing such minimal amounts environmentally insignificant\\n  2. Reducing, reusing and recycling are effective ways of helping improve and help environmentally to increase protective initiatives for better sustainability and maintaining environmentally good preservation approaches\\n  3. Cutting down all new, young saplings on newly established developing farms for re-planting\\n- What are among the most effective in the protection our land effectively against pollution related damage caused specifically as relates to human interventions that impact environmentally with negative outputs from environmentally adverse outputs of impacts produced directly from detrimental human activity interfering adversely impacting in adverse manner´resulting damage ecologically harmful, which ones can be considered contributing mostly favorably positively improving conservation strategies effectively?\\n  0. We should increase the number of motor vehicles\\n  1. Never switch and make good use our older gadgets at present being functional still working appropriately\\n  2. Recycling is helpful\\n  3. More cutting of the trees from environmentally precious woodlands\\n- What method works suitably towards conservation effort actively engaged positively advancing environmentally improving sustainable ways actively functioning so working positively benefiting efforts, helping positively impacting environments actively helping actively engage protecting various valuable and precious environmentally valuable natural preservation effective initiatives in achieving environmental protective betterment goals.\\n  0. Collecting empty plastic bags for disposing by means incineration\\n  1. Continue buying water only from plastic, rather only doing purchasing in individual bottle-size packs.\\n  2. Planting new seedling trees of many varying types of tree saplings whenever and wherever possible to carry out continuous and continual new planting and replenishing projects to create and cultivate future growth projects in which we grow trees continuously and often so forestation may constantly go-ahead\\n  3. Produce far more quantity of refuse as opposed less to before doing prior previously to implementation\\n- What should be done best working toward our actively making efforts toward effective better actively involved approaches contributing to making our actions focused protecting toward ensuring better environmentally healthy outputs obtained, most particularly having sustainable positive impact for our positive long-term results environmentally effectively resulting successful achievements environmentally beneficial effective outputs aimed improving Earth long-term conservation effectively helping sustainability\\n  0. Using public transportation methods, or riding a cycling whenever possible reducing or omitting when able using individual usage of motor automotive transportation\\n  1. Continuously producing consistently increased outputs environmentally harmful negatively impacting output by volume continually without fail\\n  2. Making very sizable volumes highly increased and massively expanded garbage output quantity. More\\n  3. Dispensing completely without fail always immediately after utilization every instance consistently without delaying doing so any amount that occurs immediately after making new items immediately\\n- The best manner forward towards successfully increasing Earth maintenance toward better effectively environmentally protected Earth sustainably managing positively securing long- term positively achieving great improving results on effective outcomes for successfully achieving positive great environmental effects from actions that will assist working toward improvements to better maintenance securing healthy planet Earth making greatly impact improvements for the highest achieving improved impact resulting good healthy sustainably maintained better earth outcome result success resulting sustainable great improvement positive lasting great successfully maintained and preserved health of Earth successful result of such initiatives positive output environmentally greatly enhanced and successful\\n  0. Producing as much garbage we can every possible time frequently\\n  1. Using and implementing regularly continually frequently repeatedly high usage quantities utilizing energy levels extremely elevated exceedingly large scale output energy consumption greatly heightened levels\\n  2. Polluting as many sites we frequent to make impact whenever feasible possible with whatever time convenient consistently making high impacts on the most number total areas and impacting many possible locations environmentally very much\\n  3. Planting more and more of greater quantities constantly maintaining consistently as highly much number possible many more various sorts and types assorted tree tree seedling of sorts various widely differing saplings from those we already maintain\\n\\nSection: Reading Comprehension Advanced\\nPassage:\\nLong ago, in a village nestled beside a whispering forest, lived a young girl named Mai. Mai found a mysterious map tucked inside an old book. The map depicted a winding path leading to a glistening tree said to grant wishes. Intrigued, Mai set off with her mischievous cat, Bin, acting as her guide. Their journey began amidst vibrant flowers and birds chirping melodies. Yet, along a river bank shaded by willows where mysterious spirits lurked, a puzzling riddle stopped her: \\'What never asks yet replies faithfully, always says yes, but can seldom stay upright?\\' Bin looked as perplexed. The tree was near, but Mai knew that she was being tested; not mere navigation but her wit. Further on was an old wooden bridge spanning over a ravine, showing early stages of rottenness. To a concerned traveler, this tested Mai\\'s quick and agile ability which passed fairly safely; Mai and Bin felt relief knowing they overcame the hurdle. Finally seeing the glistening magical tree, Mai expressed her greatest true wish: A world filled with more joy, love, and kindness. The mighty shimmering beams enveloped both her and her true guide friend Bin.\\n\\nQuestions:\\n- First, what did the magical map show specifically?\\n  0. The map showed the way to a nearby town.\\n  1. The map was in a book describing old maps and legends of magical creatures.\\n  2. The map guided Mai to a tree which grants wishes.\\n  3. The map led to a deep dark jungle and many hidden treasures.\\n- What was unique about the second part of Mai’s mysterious early magical journey?\\n  0. Birds sang pleasantly, flowers were absent.\\n  1. Mai journeyed solely.\\n  2. A river-banks filled with shady lush-green trees, however, animals were present.\\n  3. Obstacles presented before Mai, testing her ability.\\n- What did the riddle likely suggest based on hints?\\n  0. A person.\\n  1. A mountain.\\n  2. The sky or star.\\n  3. An echo.\\n- How did Mai deal with the bridge\\'s fragility (poor nature)?\\n  0. She ignored it and took shortcuts.\\n  1. She passed, the decaying appearance indicating a need for skill and caution to negotiate.\\n  2. The obstacles simply presented the easy route path to get quicker there in front of all dangers.\\n  3. There is another similar bridge close by.\\n- Mai’s wish implied that she what sincerely yearned deepest?\\n  0. More toys\\n  1. The disappearance of Bin instantly\\n  2. Peace and happiness spreading throughout the whole of entire.\\n  3. Finding a hidden cave nearby river.\\n- What finally successfully passed the entire journey showing?\\n  0. Magical power of the river,\\n  1. Magical strength coming to both Mai and her special friend.\\n  2. The will she possesses, the ability of magic\\n  3. Mutual love with companion showing mutual support despite struggles that challenges showed during tough journey helping overcame all those trials that the journey presented.\\n- What kind of journey did Mai overall experience ultimately end what?\\n  0. A journey without challenges.\\n  1. A long adventure that ultimately led up ending sadly which never produced positive impacts.\\n  2. Journey ending perfectly, having happily ever after.\\n  3. A long, complicated, confusing yet successful journey to overcome her final greatest wish ending as happy unexpectedly even despite being filled all obstacles from earlier stages during those perilous journey throughout dangerous situations. She is gifted something unexpectedly more fulfilling after successfully passing hard hurdles during those risky times encountered.\\n- The tale highlighted who specifically was support helpful for Mai for all that crucial obstacles moments she passed during this?\\n  0. Mai showed fear easily throughout those challenging path she passed those tough moments.\\n  1. Bin, a crucial aid and support throughout perilous paths, helped Mai all trials.\\n  2. Mai always faced obstacles single-handedly.\\n  3. Mai didn\\'t require any assistance at her challenges passing the route.\\n- By analyzing the full extent storyline with its context ultimately suggests truly message the story suggests ultimately means is?\\n  0. She used a map to get what she really desperately truly needed for long.\\n  1. The story is ultimately meant that some things exist solely within those places not readily capable experiencing for any travelers simply wishing on places easily reached.\\n  2. The journey shows Mai discovering true magical experience, inner happiness with supporting friend which brought meaningful ending. That experience ultimately led to greatest unexpected rewards greater what she has never thought possible earlier simply by believing journey worth having even facing challenges which were ultimately what brought ultimate greatest discoveries for such meaningful happy life-lasting moments journey made.\\n  3. The conclusion implied some form of disappointment as what had occurred throughout final moments she truly cherished despite any efforts towards greatest expectations having initially envisioned as starting initial path undertaken showing that sometimes initial path initially imagined is the best choice always afterall.\\n'}\n",
            "{'input': {'level': 'easy', 'prompt': 'Generate a new English exam'}, 'output': [{'exam_number': 2, 'sections': [{'passage_text': 'Filmmakers use sound to create emotions in movies. Sometimes, exciting music makes scenes feel _____. A quiet scene builds suspense using minimal sound or even _____. On the other hand, a sudden loud sound might shock a viewer to feel like _____. Background noises, often subtle, also build environment in what manner the _____.', 'questions': [{'correct_option': 0, 'options': ['panic', 'calm', 'boredom', 'acceptance'], 'question_text': \"Replace the best emotional feeling with Blank 3 using your knowledge; Filmmakers use all these in making films for its significance; they utilize sounds to reach people's emotional side.\"}, {'correct_option': 1, 'options': ['happy', 'thrilling', 'boring', 'sad'], 'question_text': 'Fill in Blank 1.'}, {'correct_option': 0, 'options': ['silence', 'no music', 'loud noises', 'dramatic'], 'question_text': 'Fill in Blank 2.'}, {'correct_option': 3, 'options': ['narrator speaks quietly and smoothly explaining how people live', 'no scenes were portrayed regarding people and their emotions', 'camera zooming out on all major actors as sound gets louder', 'characters experience events vividly as they happen'], 'question_text': \"Fill in Blank 4 in terms of expressing scenes from the movie director's sound manipulation knowledge on expressing it (and which type fit) regarding characters & scenario.\"}, {'correct_option': 2, 'options': ['scary music to build mystery', 'funny sound effects to create a comedic tone.', 'intense action music to create excitement', 'a quiet, low-pitched sound that mirrors the sadness in the scene'], 'question_text': 'Which choice best describes how filmmakers use sound effects & what will probably show?'}, {'correct_option': 1, 'options': ['a scene with soft backgrounds and calming characters giving relief expressions', 'sudden noises cause panic or make emotional shock feeling to come viewers towards the screen.', 'absence of music makes happy feelings from inside actors', 'action hero creates calm scenes with the musical sounds he hears helping along with others actors on screens; which made some calmness feel along'], 'question_text': 'If viewers hear, sound effects usage makes audience feeling ______, that was shown correctly.'}], 'section': 1, 'section_name': 'Cloze Grammar Vocabulary'}, {'passage_text': 'My favorite sport is badminton. I love it because it’s very _______. You don’t need lots of _______, just a racket and a shuttlecock. I also like that you only need one other person, or another team of two. It requires only minimal _______ , which makes it easy for me. Even kids can play in a fun and ____ way!', 'questions': [{'correct_option': 0, 'options': ['Simple', 'Difficult', 'Boring', 'Expensive'], 'question_text': 'Which word best describes badminton according to what the author says?'}, {'correct_option': 1, 'options': ['Opponents', 'Equipment', 'Rules', 'Friends'], 'question_text': 'What is indicated after \"lots of\" in this explanation?'}, {'correct_option': 2, 'options': ['training', 'preparation', 'equipment', 'effort'], 'question_text': 'The short phrase \"minimal _______\" refers to...'}, {'correct_option': 3, 'options': ['sad', 'hard', 'scary', 'safe'], 'question_text': 'How are children made aware they can play this easy sport considering the final word?'}, {'correct_option': 2, 'options': ['quickly', 'slowly', 'easily', 'excitedly'], 'question_text': 'In the last part of the passage, it suggests ways even short children can play simple things with more ___?'}, {'correct_option': 2, 'options': ['running', 'movement requiring lots of skills', 'a partner to start playing', 'rules of procedure highly demanding'], 'question_text': 'According to the passage what would make it suitable even for adults to begin playing it?'}], 'section': 2, 'section_name': 'Cloze Contextual Vocabulary'}, {'passage_text': '', 'questions': [{'correct_option': 1, 'options': ['Cleanliness includes everything such as clothes cleaning and more personal washing.', 'To stay neat, wash your clothes; brushing helps keep away bad breath. Always wash your hands!', 'Washing clothes frequently also helps. Personal hygiene also keeps germs from bodies and minds too.', 'We are discussing more ways health helps: Always taking frequent washes help too'], 'question_text': 'Sentence arrangement focusing on hygiene importance?'}, {'correct_option': 0, 'options': ['Firstly, washing hands helps avoid getting sick. Secondly, shower daily. Thirdly, brush teeth twice daily.', 'Wash hands frequently, shower once a day at least. Avoid germs, protect health.', 'Hygiene needs: wash, brush, and bath regularly every day. Hygiene always matters.', 'Daily showering cleans our body; hand washing prevents the spread and transmission of pathogens. Remember mouthwash.'], 'question_text': 'Which option presents these acts clearly and logically regarding personal hygiene?'}, {'correct_option': 3, 'options': ['Taking regular showers is important; but also, remember to brush your teeth every day.', 'Brushing your teeth and washing hands and face are the most important steps.', 'Washing your hands, brushing twice daily. Taking your shower helps you stay clean.', \"It's vital for your health to wash your hands frequently, brush your teeth, take showers daily, and always remember oral hygiene.\"], 'question_text': 'Choose the best arrangement ensuring hygiene:'}, {'correct_option': 0, 'options': [\"1. 'Look before you leap.' means you should think carefully before acting. 2. 'Every river begins from a small spring.' which proves nothing is too small to ignore. 3. Think carefully!\", \"1. This sentence illustrates 'Rome was not built in a day' implies you could spend a lifetime learning about Rome. 3. Do you agree? 4. This sounds unbelievably dull to me. No!\", \"1. Don't be hasty. 2. The idiom tells us to 'Look before you leap.' is simple advice. 4. Plan before committing ourselves.\", \"1. 'Look before you leap.' The phrase exemplifies caution. 2. 'The proverb Look before you leap is frequently used across cultures. 3. Therefore, we should contemplate the outcomes before acting.\"], 'question_text': 'Select the most logical and coherent ordering of these sentences relating to the proverb explanation keeping language concise for simplicity while teaching its moral value'}, {'correct_option': 1, 'options': [\"1. 'A bird in the hand is worth two in the bush.' means you should always value what you have. 2. Are you correct? 3. Yes, it also means you may lose what is already yours in hopes of gaining more.\", \"1. You should always value what you possess. 2. 'A bird in the hand is worth two in the bush.' 3. Do you agree? 4. Absolutely! It emphasizes cherishing what is available here and now.\", \"1. What about their origins? We both wondered. 2. 'Still waters run deep,' reflects the value some cultures place on this more than most others. 4. And is not at all related to trust or character.\", \"1. This idiom promotes patience to overcome big projects. 2. 'A journey of a thousand miles begins with a single step.' teaches us that big objectives are not achieved overnight. 4. You approach everything systematically starting from the beginning is right. We have much more to talk about.\"], 'question_text': \"Which ordering of sentences offers the best meaningful explanation of the English proverb 'A bird in the hand is worth two in the bush,' that might start and remain suitable with level A1 understanding among peers and is true across the cultural world?\"}], 'section': 3, 'section_name': 'Best Arrangement of Utterances'}, {'passage_text': \"My family has many special traditions. Every Lunar New Year, we clean our house thoroughly, getting rid of all the bad luck from the previous year. Then, we prepare traditional food. My grandmother's\", 'questions': [{'correct_option': 0, 'options': ['Before the event', 'During a celebration', 'After getting good results', \"Whenever there's free food\"], 'question_text': 'The paragraph indicates that house cleaning is done specifically during what periods when does the event take place?'}, {'correct_option': 1, 'options': ['Easter', 'Lunar New Year', 'Christmas', 'His birthday'], 'question_text': 'What holiday is discussed in the first paragraph as an example of events involving typical family traditions?'}, {'correct_option': 2, 'options': ['They bake a cake', 'They all leave town.', 'They prepare traditional food.', 'They visit the neighbors.'], 'question_text': 'What do the family members do as their preparations for an annual celebration mentioned earlier in the paragraph? Select one.'}, {'correct_option': 0, 'options': ['Washing our houses', 'Receiving gifts', 'Giving red envelopes', 'Getting together outdoors'], 'question_text': \"Choose what actions remove unhappiness that affects various aspects of everyone's life to kickstart a better run towards annual celebratory days in a specific family practice tradition as mentioned. According to that practice\"}, {'correct_option': 3, 'options': ['First-foot', 'Full-moon', 'Sticky rice balls', 'Red envelopes'], 'question_text': 'Which food or tradition IS mentioned in this paragraph?'}], 'section': 4, 'section_name': 'Cloze Informational Comprehension'}, {'passage_text': 'Different types of transportation help us travel from one place to another. Cars are fast and convenient for short journeys. Buses carry many people and are a cheaper way to travel longer distances. Trains can take even more people comfortably at once, making very long journeys possible. Bikes are fun too! They are also a slow type, good for health and are green. There are different benefits and drawbacks to consider for choosing your transport.', 'questions': [{'correct_option': 0, 'options': ['Cars', 'Buses', 'Trains', 'Bikes'], 'question_text': 'What is a fast way to travel a short distance?'}, {'correct_option': 1, 'options': ['Fast', 'Only for one person', 'Expensive', 'Good for short distances'], 'question_text': 'Which of these IS NOT usually a feature of buses?'}, {'correct_option': 1, 'options': ['Can you walk inside?', 'Many people can ride', 'Short distances only', 'It’s a dangerous ride'], 'question_text': 'What type of benefits do trains normally have compared to other transport?'}, {'correct_option': 2, 'options': ['Fast', 'Convenient', 'Good for health', 'Very crowded'], 'question_text': 'Which one statement below best shows the benefits that bike travels provide?'}, {'correct_option': 0, 'options': ['Cars go faster than bikes', 'Bikes only for short transport while buses for everything', 'Cars are much more healthy since they offer better protection than bikes in traffic', 'All of the Above'], 'question_text': 'What important fact can relate car travels versus bikes and bus travels?'}, {'correct_option': 2, 'options': ['Bike', 'Train', 'Car', 'Bus'], 'question_text': 'Which best describes convenient individual transportation for daily use?'}, {'correct_option': 2, 'options': ['Train', 'Bus', 'Bike', 'Car'], 'question_text': 'Which is ideal and less crowded compared with another transport mentioned?'}, {'correct_option': 2, 'options': ['Expensive', 'Slow transportation rate overall', 'A green, eco-friendly way to travel', 'Long waiting time issue'], 'question_text': 'Which of the statements below describes Bikes most importantly?'}, {'correct_option': 0, 'options': ['Very convenient', 'Healthier generally', 'Affordable traveling fares to people generally', 'None included above'], 'question_text': 'What can conclude commonly to trains, buses, and cars on daily traveling features besides the Bike specifically?'}], 'section': 5, 'section_name': 'Reading Comprehension'}, {'passage_text': 'The old house groaned under the weight of the storm. Rain lashed against the windows like a frustrated banshee, each drop a tiny fist hammering at the glass. Inside, a single candle flickered, casting long, dancing shadows that writhed across the walls like living things escaping a cage. The air hung heavy with the scent of damp earth and forgotten dreams.', 'questions': [{'correct_option': 1, 'options': ['Happy and cheerful', 'Tense', 'Calm and sleepy', 'Cheerful and playful'], 'question_text': 'What feeling does the description of the storm create in mind?'}, {'correct_option': 2, 'options': ['Large', 'Round', 'Long, dancing', 'Bright and bold'], 'question_text': \"How does the author describe the shadows' features? Choose an option closest to its figurative descriptive feature that appears.\"}, {'correct_option': 1, 'options': ['Smell of flowers and sunshine', 'Smell of fear and sadness', 'Smell only of wind', 'Smell of fresh and clean air and dreams'], 'question_text': \"What feeling does the phrase 'scent of damp earth and forgotten dreams' evoke?\"}, {'correct_option': 3, 'options': ['Softly', 'Weakly', 'Mildly', 'Fiercely'], 'question_text': '\"Rain lashed against the windows\" suggests it rains _________.'}, {'correct_option': 1, 'options': ['Comfort and warmth', 'Fear, isolation, and foreboding', 'Excitement and invitation', 'Hope, happiness, and a peaceful journey'], 'question_text': 'The overall mood or atmosphere described in the passage evokes a feeling of_____.'}, {'correct_option': 2, 'options': ['Birds singing', 'A loud fire outside', 'Wind violently assaulting', 'A broken telephone line'], 'question_text': 'Which image best supports the metaphor \"each drop a tiny fist hammering at the glass\"?'}, {'correct_option': 1, 'options': ['Exhilaration', 'Unease', 'Delight', 'Serenity'], 'question_text': \"What is the best description of an unusual and uncomfortably strange description given that's used by using figurative speech and literary tactics?\"}, {'correct_option': 3, 'options': ['Peaceful and reassuring', 'Mysterious but not creepy', 'Frightening and alarming', 'Isolated, empty, dark'], 'question_text': \"Despite not outright naming fear as an emotion in the excerpt— what aspect about that's being illustrated evokes of being mysterious yet evokes eeriness or spookiness but doesn't literally describe the feeling of extreme terror using vague language for example. And some imagery for examples.\"}, {'correct_option': 0, 'options': ['A gentle breeze swaying the leaves in the nearby forests and fields', 'A soft blanket of snow hiding everything outside completely blindingly', \"Sunshine breaking violently through trees like arrows of an unearthly entity that's threatening dark rain pounding in hard rhythmically\", 'The calm waves softly kissing warm dark pebbles in a lonely desert or beach setting'], 'question_text': \"What image contradicts a stormy setting and shows that no ominous event is around that's contrary compared to the actual situation?\"}], 'section': 6, 'section_name': 'Reading Comprehension Advanced'}]}], 'prompt': [], 'formatted_output': 'Section: Cloze Grammar Vocabulary\\nPassage:\\nFilmmakers use sound to create emotions in movies. Sometimes, exciting music makes scenes feel _____. A quiet scene builds suspense using minimal sound or even _____. On the other hand, a sudden loud sound might shock a viewer to feel like _____. Background noises, often subtle, also build environment in what manner the _____.\\n\\nQuestions:\\n- Replace the best emotional feeling with Blank 3 using your knowledge; Filmmakers use all these in making films for its significance; they utilize sounds to reach people\\'s emotional side.\\n  0. panic\\n  1. calm\\n  2. boredom\\n  3. acceptance\\n- Fill in Blank 1.\\n  0. happy\\n  1. thrilling\\n  2. boring\\n  3. sad\\n- Fill in Blank 2.\\n  0. silence\\n  1. no music\\n  2. loud noises\\n  3. dramatic\\n- Fill in Blank 4 in terms of expressing scenes from the movie director\\'s sound manipulation knowledge on expressing it (and which type fit) regarding characters & scenario.\\n  0. narrator speaks quietly and smoothly explaining how people live\\n  1. no scenes were portrayed regarding people and their emotions\\n  2. camera zooming out on all major actors as sound gets louder\\n  3. characters experience events vividly as they happen\\n- Which choice best describes how filmmakers use sound effects & what will probably show?\\n  0. scary music to build mystery\\n  1. funny sound effects to create a comedic tone.\\n  2. intense action music to create excitement\\n  3. a quiet, low-pitched sound that mirrors the sadness in the scene\\n- If viewers hear, sound effects usage makes audience feeling ______, that was shown correctly.\\n  0. a scene with soft backgrounds and calming characters giving relief expressions\\n  1. sudden noises cause panic or make emotional shock feeling to come viewers towards the screen.\\n  2. absence of music makes happy feelings from inside actors\\n  3. action hero creates calm scenes with the musical sounds he hears helping along with others actors on screens; which made some calmness feel along\\n\\nSection: Cloze Contextual Vocabulary\\nPassage:\\nMy favorite sport is badminton. I love it because it’s very _______. You don’t need lots of _______, just a racket and a shuttlecock. I also like that you only need one other person, or another team of two. It requires only minimal _______ , which makes it easy for me. Even kids can play in a fun and ____ way!\\n\\nQuestions:\\n- Which word best describes badminton according to what the author says?\\n  0. Simple\\n  1. Difficult\\n  2. Boring\\n  3. Expensive\\n- What is indicated after \"lots of\" in this explanation?\\n  0. Opponents\\n  1. Equipment\\n  2. Rules\\n  3. Friends\\n- The short phrase \"minimal _______\" refers to...\\n  0. training\\n  1. preparation\\n  2. equipment\\n  3. effort\\n- How are children made aware they can play this easy sport considering the final word?\\n  0. sad\\n  1. hard\\n  2. scary\\n  3. safe\\n- In the last part of the passage, it suggests ways even short children can play simple things with more ___?\\n  0. quickly\\n  1. slowly\\n  2. easily\\n  3. excitedly\\n- According to the passage what would make it suitable even for adults to begin playing it?\\n  0. running\\n  1. movement requiring lots of skills\\n  2. a partner to start playing\\n  3. rules of procedure highly demanding\\n\\nSection: Best Arrangement of Utterances\\nQuestions:\\n- Sentence arrangement focusing on hygiene importance?\\n  0. Cleanliness includes everything such as clothes cleaning and more personal washing.\\n  1. To stay neat, wash your clothes; brushing helps keep away bad breath. Always wash your hands!\\n  2. Washing clothes frequently also helps. Personal hygiene also keeps germs from bodies and minds too.\\n  3. We are discussing more ways health helps: Always taking frequent washes help too\\n- Which option presents these acts clearly and logically regarding personal hygiene?\\n  0. Firstly, washing hands helps avoid getting sick. Secondly, shower daily. Thirdly, brush teeth twice daily.\\n  1. Wash hands frequently, shower once a day at least. Avoid germs, protect health.\\n  2. Hygiene needs: wash, brush, and bath regularly every day. Hygiene always matters.\\n  3. Daily showering cleans our body; hand washing prevents the spread and transmission of pathogens. Remember mouthwash.\\n- Choose the best arrangement ensuring hygiene:\\n  0. Taking regular showers is important; but also, remember to brush your teeth every day.\\n  1. Brushing your teeth and washing hands and face are the most important steps.\\n  2. Washing your hands, brushing twice daily. Taking your shower helps you stay clean.\\n  3. It\\'s vital for your health to wash your hands frequently, brush your teeth, take showers daily, and always remember oral hygiene.\\n- Select the most logical and coherent ordering of these sentences relating to the proverb explanation keeping language concise for simplicity while teaching its moral value\\n  0. 1. \\'Look before you leap.\\' means you should think carefully before acting. 2. \\'Every river begins from a small spring.\\' which proves nothing is too small to ignore. 3. Think carefully!\\n  1. 1. This sentence illustrates \\'Rome was not built in a day\\' implies you could spend a lifetime learning about Rome. 3. Do you agree? 4. This sounds unbelievably dull to me. No!\\n  2. 1. Don\\'t be hasty. 2. The idiom tells us to \\'Look before you leap.\\' is simple advice. 4. Plan before committing ourselves.\\n  3. 1. \\'Look before you leap.\\' The phrase exemplifies caution. 2. \\'The proverb Look before you leap is frequently used across cultures. 3. Therefore, we should contemplate the outcomes before acting.\\n- Which ordering of sentences offers the best meaningful explanation of the English proverb \\'A bird in the hand is worth two in the bush,\\' that might start and remain suitable with level A1 understanding among peers and is true across the cultural world?\\n  0. 1. \\'A bird in the hand is worth two in the bush.\\' means you should always value what you have. 2. Are you correct? 3. Yes, it also means you may lose what is already yours in hopes of gaining more.\\n  1. 1. You should always value what you possess. 2. \\'A bird in the hand is worth two in the bush.\\' 3. Do you agree? 4. Absolutely! It emphasizes cherishing what is available here and now.\\n  2. 1. What about their origins? We both wondered. 2. \\'Still waters run deep,\\' reflects the value some cultures place on this more than most others. 4. And is not at all related to trust or character.\\n  3. 1. This idiom promotes patience to overcome big projects. 2. \\'A journey of a thousand miles begins with a single step.\\' teaches us that big objectives are not achieved overnight. 4. You approach everything systematically starting from the beginning is right. We have much more to talk about.\\n\\nSection: Cloze Informational Comprehension\\nPassage:\\nMy family has many special traditions. Every Lunar New Year, we clean our house thoroughly, getting rid of all the bad luck from the previous year. Then, we prepare traditional food. My grandmother\\'s\\n\\nQuestions:\\n- The paragraph indicates that house cleaning is done specifically during what periods when does the event take place?\\n  0. Before the event\\n  1. During a celebration\\n  2. After getting good results\\n  3. Whenever there\\'s free food\\n- What holiday is discussed in the first paragraph as an example of events involving typical family traditions?\\n  0. Easter\\n  1. Lunar New Year\\n  2. Christmas\\n  3. His birthday\\n- What do the family members do as their preparations for an annual celebration mentioned earlier in the paragraph? Select one.\\n  0. They bake a cake\\n  1. They all leave town.\\n  2. They prepare traditional food.\\n  3. They visit the neighbors.\\n- Choose what actions remove unhappiness that affects various aspects of everyone\\'s life to kickstart a better run towards annual celebratory days in a specific family practice tradition as mentioned. According to that practice\\n  0. Washing our houses\\n  1. Receiving gifts\\n  2. Giving red envelopes\\n  3. Getting together outdoors\\n- Which food or tradition IS mentioned in this paragraph?\\n  0. First-foot\\n  1. Full-moon\\n  2. Sticky rice balls\\n  3. Red envelopes\\n\\nSection: Reading Comprehension\\nPassage:\\nDifferent types of transportation help us travel from one place to another. Cars are fast and convenient for short journeys. Buses carry many people and are a cheaper way to travel longer distances. Trains can take even more people comfortably at once, making very long journeys possible. Bikes are fun too! They are also a slow type, good for health and are green. There are different benefits and drawbacks to consider for choosing your transport.\\n\\nQuestions:\\n- What is a fast way to travel a short distance?\\n  0. Cars\\n  1. Buses\\n  2. Trains\\n  3. Bikes\\n- Which of these IS NOT usually a feature of buses?\\n  0. Fast\\n  1. Only for one person\\n  2. Expensive\\n  3. Good for short distances\\n- What type of benefits do trains normally have compared to other transport?\\n  0. Can you walk inside?\\n  1. Many people can ride\\n  2. Short distances only\\n  3. It’s a dangerous ride\\n- Which one statement below best shows the benefits that bike travels provide?\\n  0. Fast\\n  1. Convenient\\n  2. Good for health\\n  3. Very crowded\\n- What important fact can relate car travels versus bikes and bus travels?\\n  0. Cars go faster than bikes\\n  1. Bikes only for short transport while buses for everything\\n  2. Cars are much more healthy since they offer better protection than bikes in traffic\\n  3. All of the Above\\n- Which best describes convenient individual transportation for daily use?\\n  0. Bike\\n  1. Train\\n  2. Car\\n  3. Bus\\n- Which is ideal and less crowded compared with another transport mentioned?\\n  0. Train\\n  1. Bus\\n  2. Bike\\n  3. Car\\n- Which of the statements below describes Bikes most importantly?\\n  0. Expensive\\n  1. Slow transportation rate overall\\n  2. A green, eco-friendly way to travel\\n  3. Long waiting time issue\\n- What can conclude commonly to trains, buses, and cars on daily traveling features besides the Bike specifically?\\n  0. Very convenient\\n  1. Healthier generally\\n  2. Affordable traveling fares to people generally\\n  3. None included above\\n\\nSection: Reading Comprehension Advanced\\nPassage:\\nThe old house groaned under the weight of the storm. Rain lashed against the windows like a frustrated banshee, each drop a tiny fist hammering at the glass. Inside, a single candle flickered, casting long, dancing shadows that writhed across the walls like living things escaping a cage. The air hung heavy with the scent of damp earth and forgotten dreams.\\n\\nQuestions:\\n- What feeling does the description of the storm create in mind?\\n  0. Happy and cheerful\\n  1. Tense\\n  2. Calm and sleepy\\n  3. Cheerful and playful\\n- How does the author describe the shadows\\' features? Choose an option closest to its figurative descriptive feature that appears.\\n  0. Large\\n  1. Round\\n  2. Long, dancing\\n  3. Bright and bold\\n- What feeling does the phrase \\'scent of damp earth and forgotten dreams\\' evoke?\\n  0. Smell of flowers and sunshine\\n  1. Smell of fear and sadness\\n  2. Smell only of wind\\n  3. Smell of fresh and clean air and dreams\\n- \"Rain lashed against the windows\" suggests it rains _________.\\n  0. Softly\\n  1. Weakly\\n  2. Mildly\\n  3. Fiercely\\n- The overall mood or atmosphere described in the passage evokes a feeling of_____.\\n  0. Comfort and warmth\\n  1. Fear, isolation, and foreboding\\n  2. Excitement and invitation\\n  3. Hope, happiness, and a peaceful journey\\n- Which image best supports the metaphor \"each drop a tiny fist hammering at the glass\"?\\n  0. Birds singing\\n  1. A loud fire outside\\n  2. Wind violently assaulting\\n  3. A broken telephone line\\n- What is the best description of an unusual and uncomfortably strange description given that\\'s used by using figurative speech and literary tactics?\\n  0. Exhilaration\\n  1. Unease\\n  2. Delight\\n  3. Serenity\\n- Despite not outright naming fear as an emotion in the excerpt— what aspect about that\\'s being illustrated evokes of being mysterious yet evokes eeriness or spookiness but doesn\\'t literally describe the feeling of extreme terror using vague language for example. And some imagery for examples.\\n  0. Peaceful and reassuring\\n  1. Mysterious but not creepy\\n  2. Frightening and alarming\\n  3. Isolated, empty, dark\\n- What image contradicts a stormy setting and shows that no ominous event is around that\\'s contrary compared to the actual situation?\\n  0. A gentle breeze swaying the leaves in the nearby forests and fields\\n  1. A soft blanket of snow hiding everything outside completely blindingly\\n  2. Sunshine breaking violently through trees like arrows of an unearthly entity that\\'s threatening dark rain pounding in hard rhythmically\\n  3. The calm waves softly kissing warm dark pebbles in a lonely desert or beach setting\\n'}\n",
            "{'input': {'level': 'easy', 'prompt': 'Generate a new English exam'}, 'output': [{'exam_number': 3, 'sections': [{'passage_text': 'My friends and I had to solve a tricky puzzle during our first weekend away. We spent so much time trying that we even____(1)____lunch! It really tested our ________(2)_______, but eventually we managed together. Working as a team_______(3)_______helped us find a clever idea. We started to solve____(4)____pieces at a time making little______(5)_______ progress till finished. Although challenging, _________(6)_______ it was very rewarding!', 'questions': [{'correct_option': 1, 'options': ['ate', 'missed', 'found', 'cooked'], 'question_text': 'Fill in the blank (1):'}, {'correct_option': 0, 'options': ['patience', 'speed', 'diligence', 'creativity'], 'question_text': 'Fill in the blank (2):'}, {'correct_option': 0, 'options': ['really', 'sometimes', 'often', 'never'], 'question_text': 'Fill in the blank (3):'}, {'correct_option': 2, 'options': ['separate', 'big', 'single', 'entire'], 'question_text': 'Fill in the blank (4):'}, {'correct_option': 1, 'options': ['it was', 'although', 'despite', 'however was'], 'question_text': 'Fill in the blank (5):'}, {'correct_option': 2, 'options': ['fast', 'much', 'slow gradual', 'constant'], 'question_text': 'Fill in the blank (6):'}], 'section': 1, 'section_name': 'Cloze Grammar Vocabulary'}, {'passage_text': 'Meeting new people can be daunting. You want to make a good first __________. Sometimes, we prepare __________ about how we present ourselves which show our best features such as dressing smartly or demonstrating kindness.', 'questions': [{'correct_option': 0, 'options': ['impression', 'expression', 'proposal', 'introduction'], 'question_text': 'Which word best fits in the first blank?'}, {'correct_option': 0, 'options': ['ideas', 'descriptions', 'impressions', 'reputations'], 'question_text': 'Which word best completes the second blank?'}, {'correct_option': 1, 'options': ['shyly', 'nervously', 'confidently', 'arrogantly'], 'question_text': 'Many feel _______ when first meeting someone because their prepared presentation of themselves is scrutinized.'}, {'correct_option': 2, 'options': ['sad', 'gloomy', 'pleasant', 'happy'], 'question_text': 'When well planned, a positive introduction generates a _____ feeling.'}, {'correct_option': 0, 'options': ['smart', 'casual simple', 'formal', 'carefree fashionable'], 'question_text': 'Many would advise one should choose _____ attire in a public setting.'}, {'correct_option': 1, 'options': ['gesture', 'approach', 'method', 'practice'], 'question_text': 'One effective initial ________ is being kind, generally a quality people appreciate.'}], 'section': 2, 'section_name': 'Cloze Contextual Vocabulary'}, {'passage_text': '', 'questions': [{'correct_option': 3, 'options': ['1. The fox has amazing magic, often transforming and escaping. 2. However, he was tricked out of his position also. 3. But sometimes bad characters didn’t have so great achievements. 4. Many animal spirits had special natural magical gifts from the sky to appear frequently as magical creatures in many stories.', \"1. The people’s values changed totally. 2. However, the spirits often protected folks from risks, which mostly always helped good things to have a wide impact locally across Vietnamese communities. 3. This inspired them greatly in daily life; many stories of clever characters' adventures always made success in difficult settings\", '1. The brave fox often gets in difficult challenges. However, that spirit helps others anyway. 2. Clever stories with magical elements are presented among cultures. 3. Its impact is deeply about beliefs that still hold today widely. 4. Yet it reflected strong beliefs with spiritual cultures greatly impacting social culture.', '1. Ancient Vietnamese culture has many legends. 2. These stories feature many characters, often animals or spiritual beings who transform based on magical situations. 3. Some legends focus on smart solutions or battles of wit, demonstrating values like bravery; cunning skill and wisdom; these important morals are highlighted. 4. They remind people to learn about morality also, even now. 5. They remind people of the importance, which continues widely throughout the land. Moreover, they always inspire them positively during many moments despite difficulties.'], 'question_text': 'Select the most logical arrangement of these sentences discussing common themes prevalent in Vietnamese legends, focusing on the animal nature spirits presented often in folklore as main contents.'}, {'correct_option': 0, 'options': [\"1. This legend explains some natural events. 2. Vietnamese legends tell many heroes' legends. 3. Which made impacts widely. 4. Also many stories relate to various folk cultures.\", '1. Many stories explain how some customs began. 2. This has inspired greatly. That many aspects got changed because most young people still love and cherish local traditions even the ancient style. 3. Vietnamese legends keep their value by spreading culture', '1. The magical items give so many challenges. That the Hero must use clever ability and courage both. 5. Then They defeated villains. Using skills, clever strategy; bravery; 3. By conquering the tough things and become successful despite how risky challenging situations and circumstances. It reflected people; culture strongly among Vietnamese society too.', \"That's not available choices to selected from because its contents are not so related much also is impossible to arrange from anything context passage given\"], 'question_text': 'What order best arranges these components that commonly presents characteristics of Vietnam’s culture, particularly within the framework of these folklore stories?'}, {'correct_option': 2, 'options': ['1. He is clever but didn’t study enough at University. 2. Sơn Tinh moved mountains one by one. 3. However, Thủy Tinh used water power. 4. Yet, because of strong will of himself, he won anyway.', '1. Having no skill in controlling rocks but bravery himself. 2, Nevertheless, The water always overcomes. 3. Despite it has so many limits. 4, And one day two brothers bravely fight the mighty monsters.', '1. With such clever fighting styles., 2. Which brought lots and lots of success. 3. Thủy Tinh used skillful water attacks. 4. Many lost with this power so hard, 5. Yet despite so that skillful battle style even the mighty won eventually.', 'All three above are impossible to arrange and correct'], 'question_text': 'Arrange this short passage to summarize the story of Sơn Tinh and Thủy Tinh in classic Vietnamese legends based on strengths & skills.'}, {'correct_option': 2, 'options': ['1. The princess is very kind. 2. She always helps people. 3. The dragon is scary for people in the village. Because, 4. She always bravely fights against something that harms them.', \"1. The princess is kind. 2. Dragons are scary; however, there's a courageous princess, 3. Who also helps villagers bravely.\", '1. Once upon a time, there was a brave princess. 2. She helped the villagers using her magic. 3. People loved her a lot. 4. But, there was a magic dragon too.', 'None of the above is correct'], 'question_text': 'Choose the best order of these sentences to create a short story about a brave princess who fights alongside her people.'}, {'correct_option': 1, 'options': ['Tôi có một gia đình rất hạnh phúc. Tôi yêu bố mẹ và em gái mình rất nhiều. Mẹ tôi là giáo viên, bà ấy rất tốt bụng và yêu thương tụi mình. Bố thì làm bác sĩ, ông ấy rất nghiêm khắc nhưng cũng rất thương con gái.', 'Tôi yêu bố mẹ và em gái mình rất nhiều. Tôi có một gia đình rất hạnh phúc. Bố tôi làm bác sĩ ông ấy rất nghiêm khắc nhưng cũng rất thương con gái. Mẹ tôi là giáo viên, bà ấy rất tốt bụng và yêu thương tụi mình.', 'Mẹ tôi là giáo viên, bà ấy rất tốt bụng và yêu thương tụi mình. Bố tuy là bác sĩ, rất nghiêm khắc các điều Bố nói với tụi mình ông ấy luôn luôn thương con cái của mình . Tôi yêu bố mẹ và em gái mình rất nhiều. Gia đình tôi là 1 GĐ rất hạnh phúc.', 'Gia đình tôi rất tuyệt vời. Mẹ tôi là y tá, hay rất chiều chuộng. Tôi rất yêu cả bố và mẹ. Còn bà tôi thì thường xuyên chăm chút cho con, và những đứa cháu ngoại của mình . Mê hoa là đam mê mà ai trong nhà đều đồng quan điểm ! Em là con tinh thần trong đời các tôi !'], 'question_text': 'Choose the best order of these sentences to describe a happy family in Vietnamese for a high school graduation exam oriented, this specific format will also be needed for answering any follow up questions of the provided passage context.'}], 'section': 3, 'section_name': 'Best Arrangement of Utterances'}, {'passage_text': 'Almonds, cashews, and peanuts are popular nuts. Almonds have a slightly bitter taste and a hard shell. Cashews have a milder, sweeter flavor and a kidney shape. Peanuts, technically legumes, are smooth and often creamy in taste. Their shells are easier to remove when ripe.', 'questions': [{'correct_option': 2, 'options': ['Cashews taste slightly more bitter than almonds.', \"Peanuts' shells are harder than almond shells.\", 'Cashews are mildly sweet unlike almonds.', 'Almonds have a kidney shape like cashews.'], 'question_text': 'Which statement BEST explains the difference in taste between almonds and cashews?'}, {'correct_option': 1, 'options': ['All three have similarly hard shells.', 'Peanuts have a different outer covering which peels more easily than almonds.', 'Cashews come out easily from hulls.', 'Almonds and cashews share an easier shell opening than peanuts if only ripe.'], 'question_text': 'According to the passage, which of the nuts might involve extra shelling effort during harvesting?'}, {'correct_option': 3, 'options': ['Almonds are a sweet, hard-shelled nut.', 'Cashews have an easily removed shell but they are bitter.', \"Peanuts, although a special seed, don’t exactly fit in this passage's type because they lack all characters of almonds and cashews.\", 'Peanuts aren’t properly nuts but rather are easy soft shell legumes different in texture, taste, and look in this paragraph from nuts.'], 'question_text': 'How does peanuts being a legume differ from nuts as per the passage?'}, {'correct_option': 0, 'options': ['Both peanuts and almonds have similar shapes.', 'Almonds possess milder flavour with similar looking outer part to cashew', \"Peanuts have equally better flavor and cream and kidney type exterior shape cashew with both mild sweet to sweeter notes that is smooth like peanuts' shells.\", 'Only two almonds and Cashoes have the resemblance of exterior hard shell outer to ease peel if ripe during shell harvest season compared similarly in to legumes'], 'question_text': 'What feature is less obvious and yet shows the shared traits among almonds both only peanuts and cashew alike with some distinctions according the selection:'}, {'correct_option': 3, 'options': ['All three nuts have soft smooth flavor', 'Almonds contain sweeter and harsher aftertaste against cashews relatively harder shells too in comparison with peanut and the softer legume', \"Peanuts don't only not look, taste and have less sweet creamy nutty note or softer than hard nuts texture and other traits too thus not fit nuts but lack only smoother yet legume softer traits, neither.\", 'The author explains there is a vast difference in almond creamy or peanuts yet these types contrast in shape, shell, peeling or taste traits with these differences explained comparing among types alike nuts as examples including comparison including even peanuts too only legume type with yet smoother texture or other distinct differences'], 'question_text': 'The passage distinguishes these nut sorts mainly for what key reasons?'}], 'section': 4, 'section_name': 'Cloze Informational Comprehension'}, {'passage_text': 'The human body is amazing! It has many systems working together. The nervous system controls our actions and senses. The digestive system breaks down food. The circulatory system moves blood, carrying oxygen and nutrients. Our bones protect our organs and support our body, part of the skeletal system. Skin protects us from germs and keeps water inside.', 'questions': [{'correct_option': 0, 'options': ['Nervous system', 'Digestive system', 'Circulatory system', 'Immune system'], 'question_text': 'Which system controls actions and senses?'}, {'correct_option': 3, 'options': ['The skeletal system', 'The nervous system', 'The immune system', 'The digestive system'], 'question_text': 'What system breaks down the food we eat?'}, {'correct_option': 2, 'options': ['The digestive system', 'The endocrine system', 'The circulatory system', 'The respiratory system'], 'question_text': 'Which system moves blood around the body?'}, {'correct_option': 3, 'options': ['Heart', 'Brain', 'Blood Vessels', 'Bones'], 'question_text': 'What supports and gives the body its structure and framework?'}, {'correct_option': 0, 'options': ['Skin', 'Lungs', 'Heart', 'Brain'], 'question_text': 'What outer layer of the organism protects from our environment and helps regulate body temperature?'}, {'correct_option': 1, 'options': ['Broken bones heal faster', 'Bones support the body', 'Bones are a hard substance', 'Bone marrow makes hormones'], 'question_text': 'Which sentence shows the structural supporting role played by bones and the skeletal system?'}, {'correct_option': 1, 'options': ['The respiratory system only carries out breathing', 'Your respiratory system brings O2 to the body and excretes CO2', 'Blood exchanges CO2 only with the lungs in the body', \"Blood carries O2 all over into the body's internal structures\"], 'question_text': 'What happens if the respiratory system fails?'}, {'correct_option': 1, 'options': ['Stomach acid helps digest food', 'The immune system identifies and helps remove foreign pathogens', 'Nutrient absorption takes place in the liver', 'Excretory system carries O2 from around tissues to the lungs for O2 and blood gases transportation'], 'question_text': 'Select the line in the description that describes the immune system properly'}, {'correct_option': 3, 'options': ['Oxygen is taken in through the digestive system', 'Bones control movement', 'The circulatory system is only related to your skin', 'Nutrients are distributed throughout your body through blood'], 'question_text': 'Which statement best shows cooperation among all working body organs?'}], 'section': 5, 'section_name': 'Reading Comprehension'}, {'passage_text': \"A circular garden has a diameter of 10 meters. A gardener wants to create two more smaller circular gardens within the larger one, each with a perimeter smaller than the center's garden. The first is half the garden's radius as its radius. The first is perfectly placed along the circumference. The second small garden's perimeter is 1/5 more than half its smaller circle's diameter.\", 'questions': [{'correct_option': 2, 'options': [\"The smaller circle's diameter is 15 meters.\", 'The perimeter of the original bigger circle is larger than the total smaller area of the circle with approximately a 32-meter difference, which is more appropriate', 'The radius of the central circle is similar to both the smaller areas with little change of less than 2 meters in perimeter, making this an approximation that is accurate to solve a geometrical construction problem.', 'This question cannot be reasoned because to obtain results one cannot compare with given information'], 'question_text': 'Considering both of the two half gardens and the complete whole garden, how do their radii compare size-wise?'}, {'correct_option': 1, 'options': ['The total gardens and how radii approximately equal, is there a constant?', 'The entire total gardens is bigger comparatively speaking and hence radii are not exact compared to the main then entire bigger are approximately comparative of a little under total or about size as in comparison is approximate with near radius size with more the same circumference', 'This problem is unable to be solved completely', 'None of the above'], 'question_text': \"Comparing the area including a single diameter length, including two inner smaller gardens' combined perimeter areas compared to the total length, which accurately states approximately their combined shape including central circular with another circular relation?\"}, {'correct_option': 1, 'options': [\"The combined area of smaller circles is bigger proportionally twice than the entire initial areas garden's smaller combined small area, both sizes radius size.\", 'The combined area of these of the both innermost radius gardens proportionally covers almost equally with combined garden compared approximate comparative measure including both twice area combined then single small gardens', 'Radius compared are twice the sum approximate areas approximately double and smaller each radius with difference compared larger circular sizes proportionally related.', 'Gardens are unable to compare sizes with exact measurements sizes sizes sizes'], 'question_text': 'What exactly is the relationship of approximately equal proportion between the inner and outer perimeters of the garden total and comparatively each of which comparatively proportionally combined total these circles are proportionally?'}, {'correct_option': 0, 'options': ['The area to each one has radius that it is half to what combined circles both of one one.', 'Both two areas combined has exact smaller is half exact perimeter proportion as this bigger circle bigger radius diameter hence radius and combined two total exact same to entire are proportion half.', \"Radius areas all three gardens proportional proportion double this that half what garden main larger one's double equal exactly half equal proportions but main.\", 'There is no exact relationship ratio calculation available because insufficient information is present to calculate all these precisely'], 'question_text': 'Considering both areas with relation, considering the proportion these exactly sizes with exact measurement relations areas proportion how exactly does relationship look like for comparing areas together with these proportion?'}, {'correct_option': 3, 'options': ['This circle total proportionally this circles double half double exactly to large.', 'Total half garden larger comparatively with almost combined proportion bigger comparative comparatively this large sizes proportionally speaking and considering circumference size', 'Area are double but circumference are this proportion less because they exactly exactly related.', 'This comparison is mathematically inappropriate to calculate proportions precisely compared to get values both these compare with without all given radius lengths diameters and total combined garden circles three including smaller that are both two'], 'question_text': 'Talking about proportion of areas sizes, both the innermost, hence both inner circular of these total this areas including these circle both sizes proportional proportion both how approximately proportionally do comparing of sizes and compare both proportional accurately.'}, {'correct_option': 1, 'options': ['Circumferences are proportionally related to diameter radius smaller.', 'Circumference circles areas compared have a ratio comparing their approximate are ratio between diameter, smaller garden.', 'This exactly proportional exactly relationship diameter of exactly radius precisely but circumference also approximate size difference exactly related approximately very smaller comparative small compared overall large but that makes relation approximation inaccurate proportionally sizes.', \"This problem can't exactly solve this solve accurately approximately it related sizes ratio diameter can compute using exact\"], 'question_text': 'How proportion these radius with diameters these the all three total all approximately are they related precisely proportion or it approximately related only approximately that approximately sizes?'}, {'correct_option': 2, 'options': ['Sum radiuses total all combined exactly three', 'Smaller two exact areas hence total comparing three exactly twice twice big once combined once approximate near equal approximately but close comparatively size combined combined.', 'Areas sum are less then exactly close combined garden size garden both double small circle this approximate this proportion approximation this comparative approximately approximate same relation to main largest to proportion total', 'None above proportion available compute exactly proportional proportion available to compute calculate compare comparison obtain proportion ratio size of main largest'], 'question_text': 'Using the combining of smaller radii twice compared to main what we got finally approximately relation between proportional to their total hence total combined circles with main size approximate how proportional in finally exact with ratio exact values or only approximately relation both?'}, {'correct_option': 0, 'options': ['Radius compared are twice and area proportionally that too approximately half approximately proportional only not approximately exactly only it is this proportion approximately half proportionally not', 'Both combine exact area this almost exactly half approximately only total comparing comparing the of each approximate same this is this close smaller smaller once proportion exactly then total this area hence exactly related compared ratio', 'Total the circles smaller garden approximately related proportionally because these to proportionally double of this which main circle total.', 'This question difficult answer accurately due its inherent uncertainties inherent proportion compare of this to main related ratio approximate and with lack provided precise informations'], 'question_text': 'Using the proportion relation diameter the large comparing the double ratio of which diameter then using of which the radius half it is then total areas proportionally its these then how these relate finally proportion combined considering.'}, {'correct_option': 3, 'options': ['Both radiuses combined comparatively size area also approximately twice main total', 'There combined almost three comparative equal areas and sum of twice with this.', 'Approximate equal diameter comparatively sizes related proportion', 'No information available given exactly how areas the sizes hence not available compare total areas comparatively their accurate relations can compare this insufficient calculation precise numbers provided make comparison with each proportional proportions not precise'], 'question_text': 'How both smaller comparatively proportions both exactly relation these approximately calculate their with ratio precisely but only approximation which approximate sizes but proportion these related exactly each related with proportion how compared .'}], 'section': 6, 'section_name': 'Reading Comprehension Advanced'}]}], 'prompt': [], 'formatted_output': \"Section: Cloze Grammar Vocabulary\\nPassage:\\nMy friends and I had to solve a tricky puzzle during our first weekend away. We spent so much time trying that we even____(1)____lunch! It really tested our ________(2)_______, but eventually we managed together. Working as a team_______(3)_______helped us find a clever idea. We started to solve____(4)____pieces at a time making little______(5)_______ progress till finished. Although challenging, _________(6)_______ it was very rewarding!\\n\\nQuestions:\\n- Fill in the blank (1):\\n  0. ate\\n  1. missed\\n  2. found\\n  3. cooked\\n- Fill in the blank (2):\\n  0. patience\\n  1. speed\\n  2. diligence\\n  3. creativity\\n- Fill in the blank (3):\\n  0. really\\n  1. sometimes\\n  2. often\\n  3. never\\n- Fill in the blank (4):\\n  0. separate\\n  1. big\\n  2. single\\n  3. entire\\n- Fill in the blank (5):\\n  0. it was\\n  1. although\\n  2. despite\\n  3. however was\\n- Fill in the blank (6):\\n  0. fast\\n  1. much\\n  2. slow gradual\\n  3. constant\\n\\nSection: Cloze Contextual Vocabulary\\nPassage:\\nMeeting new people can be daunting. You want to make a good first __________. Sometimes, we prepare __________ about how we present ourselves which show our best features such as dressing smartly or demonstrating kindness.\\n\\nQuestions:\\n- Which word best fits in the first blank?\\n  0. impression\\n  1. expression\\n  2. proposal\\n  3. introduction\\n- Which word best completes the second blank?\\n  0. ideas\\n  1. descriptions\\n  2. impressions\\n  3. reputations\\n- Many feel _______ when first meeting someone because their prepared presentation of themselves is scrutinized.\\n  0. shyly\\n  1. nervously\\n  2. confidently\\n  3. arrogantly\\n- When well planned, a positive introduction generates a _____ feeling.\\n  0. sad\\n  1. gloomy\\n  2. pleasant\\n  3. happy\\n- Many would advise one should choose _____ attire in a public setting.\\n  0. smart\\n  1. casual simple\\n  2. formal\\n  3. carefree fashionable\\n- One effective initial ________ is being kind, generally a quality people appreciate.\\n  0. gesture\\n  1. approach\\n  2. method\\n  3. practice\\n\\nSection: Best Arrangement of Utterances\\nQuestions:\\n- Select the most logical arrangement of these sentences discussing common themes prevalent in Vietnamese legends, focusing on the animal nature spirits presented often in folklore as main contents.\\n  0. 1. The fox has amazing magic, often transforming and escaping. 2. However, he was tricked out of his position also. 3. But sometimes bad characters didn’t have so great achievements. 4. Many animal spirits had special natural magical gifts from the sky to appear frequently as magical creatures in many stories.\\n  1. 1. The people’s values changed totally. 2. However, the spirits often protected folks from risks, which mostly always helped good things to have a wide impact locally across Vietnamese communities. 3. This inspired them greatly in daily life; many stories of clever characters' adventures always made success in difficult settings\\n  2. 1. The brave fox often gets in difficult challenges. However, that spirit helps others anyway. 2. Clever stories with magical elements are presented among cultures. 3. Its impact is deeply about beliefs that still hold today widely. 4. Yet it reflected strong beliefs with spiritual cultures greatly impacting social culture.\\n  3. 1. Ancient Vietnamese culture has many legends. 2. These stories feature many characters, often animals or spiritual beings who transform based on magical situations. 3. Some legends focus on smart solutions or battles of wit, demonstrating values like bravery; cunning skill and wisdom; these important morals are highlighted. 4. They remind people to learn about morality also, even now. 5. They remind people of the importance, which continues widely throughout the land. Moreover, they always inspire them positively during many moments despite difficulties.\\n- What order best arranges these components that commonly presents characteristics of Vietnam’s culture, particularly within the framework of these folklore stories?\\n  0. 1. This legend explains some natural events. 2. Vietnamese legends tell many heroes' legends. 3. Which made impacts widely. 4. Also many stories relate to various folk cultures.\\n  1. 1. Many stories explain how some customs began. 2. This has inspired greatly. That many aspects got changed because most young people still love and cherish local traditions even the ancient style. 3. Vietnamese legends keep their value by spreading culture\\n  2. 1. The magical items give so many challenges. That the Hero must use clever ability and courage both. 5. Then They defeated villains. Using skills, clever strategy; bravery; 3. By conquering the tough things and become successful despite how risky challenging situations and circumstances. It reflected people; culture strongly among Vietnamese society too.\\n  3. That's not available choices to selected from because its contents are not so related much also is impossible to arrange from anything context passage given\\n- Arrange this short passage to summarize the story of Sơn Tinh and Thủy Tinh in classic Vietnamese legends based on strengths & skills.\\n  0. 1. He is clever but didn’t study enough at University. 2. Sơn Tinh moved mountains one by one. 3. However, Thủy Tinh used water power. 4. Yet, because of strong will of himself, he won anyway.\\n  1. 1. Having no skill in controlling rocks but bravery himself. 2, Nevertheless, The water always overcomes. 3. Despite it has so many limits. 4, And one day two brothers bravely fight the mighty monsters.\\n  2. 1. With such clever fighting styles., 2. Which brought lots and lots of success. 3. Thủy Tinh used skillful water attacks. 4. Many lost with this power so hard, 5. Yet despite so that skillful battle style even the mighty won eventually.\\n  3. All three above are impossible to arrange and correct\\n- Choose the best order of these sentences to create a short story about a brave princess who fights alongside her people.\\n  0. 1. The princess is very kind. 2. She always helps people. 3. The dragon is scary for people in the village. Because, 4. She always bravely fights against something that harms them.\\n  1. 1. The princess is kind. 2. Dragons are scary; however, there's a courageous princess, 3. Who also helps villagers bravely.\\n  2. 1. Once upon a time, there was a brave princess. 2. She helped the villagers using her magic. 3. People loved her a lot. 4. But, there was a magic dragon too.\\n  3. None of the above is correct\\n- Choose the best order of these sentences to describe a happy family in Vietnamese for a high school graduation exam oriented, this specific format will also be needed for answering any follow up questions of the provided passage context.\\n  0. Tôi có một gia đình rất hạnh phúc. Tôi yêu bố mẹ và em gái mình rất nhiều. Mẹ tôi là giáo viên, bà ấy rất tốt bụng và yêu thương tụi mình. Bố thì làm bác sĩ, ông ấy rất nghiêm khắc nhưng cũng rất thương con gái.\\n  1. Tôi yêu bố mẹ và em gái mình rất nhiều. Tôi có một gia đình rất hạnh phúc. Bố tôi làm bác sĩ ông ấy rất nghiêm khắc nhưng cũng rất thương con gái. Mẹ tôi là giáo viên, bà ấy rất tốt bụng và yêu thương tụi mình.\\n  2. Mẹ tôi là giáo viên, bà ấy rất tốt bụng và yêu thương tụi mình. Bố tuy là bác sĩ, rất nghiêm khắc các điều Bố nói với tụi mình ông ấy luôn luôn thương con cái của mình . Tôi yêu bố mẹ và em gái mình rất nhiều. Gia đình tôi là 1 GĐ rất hạnh phúc.\\n  3. Gia đình tôi rất tuyệt vời. Mẹ tôi là y tá, hay rất chiều chuộng. Tôi rất yêu cả bố và mẹ. Còn bà tôi thì thường xuyên chăm chút cho con, và những đứa cháu ngoại của mình . Mê hoa là đam mê mà ai trong nhà đều đồng quan điểm ! Em là con tinh thần trong đời các tôi !\\n\\nSection: Cloze Informational Comprehension\\nPassage:\\nAlmonds, cashews, and peanuts are popular nuts. Almonds have a slightly bitter taste and a hard shell. Cashews have a milder, sweeter flavor and a kidney shape. Peanuts, technically legumes, are smooth and often creamy in taste. Their shells are easier to remove when ripe.\\n\\nQuestions:\\n- Which statement BEST explains the difference in taste between almonds and cashews?\\n  0. Cashews taste slightly more bitter than almonds.\\n  1. Peanuts' shells are harder than almond shells.\\n  2. Cashews are mildly sweet unlike almonds.\\n  3. Almonds have a kidney shape like cashews.\\n- According to the passage, which of the nuts might involve extra shelling effort during harvesting?\\n  0. All three have similarly hard shells.\\n  1. Peanuts have a different outer covering which peels more easily than almonds.\\n  2. Cashews come out easily from hulls.\\n  3. Almonds and cashews share an easier shell opening than peanuts if only ripe.\\n- How does peanuts being a legume differ from nuts as per the passage?\\n  0. Almonds are a sweet, hard-shelled nut.\\n  1. Cashews have an easily removed shell but they are bitter.\\n  2. Peanuts, although a special seed, don’t exactly fit in this passage's type because they lack all characters of almonds and cashews.\\n  3. Peanuts aren’t properly nuts but rather are easy soft shell legumes different in texture, taste, and look in this paragraph from nuts.\\n- What feature is less obvious and yet shows the shared traits among almonds both only peanuts and cashew alike with some distinctions according the selection:\\n  0. Both peanuts and almonds have similar shapes.\\n  1. Almonds possess milder flavour with similar looking outer part to cashew\\n  2. Peanuts have equally better flavor and cream and kidney type exterior shape cashew with both mild sweet to sweeter notes that is smooth like peanuts' shells.\\n  3. Only two almonds and Cashoes have the resemblance of exterior hard shell outer to ease peel if ripe during shell harvest season compared similarly in to legumes\\n- The passage distinguishes these nut sorts mainly for what key reasons?\\n  0. All three nuts have soft smooth flavor\\n  1. Almonds contain sweeter and harsher aftertaste against cashews relatively harder shells too in comparison with peanut and the softer legume\\n  2. Peanuts don't only not look, taste and have less sweet creamy nutty note or softer than hard nuts texture and other traits too thus not fit nuts but lack only smoother yet legume softer traits, neither.\\n  3. The author explains there is a vast difference in almond creamy or peanuts yet these types contrast in shape, shell, peeling or taste traits with these differences explained comparing among types alike nuts as examples including comparison including even peanuts too only legume type with yet smoother texture or other distinct differences\\n\\nSection: Reading Comprehension\\nPassage:\\nThe human body is amazing! It has many systems working together. The nervous system controls our actions and senses. The digestive system breaks down food. The circulatory system moves blood, carrying oxygen and nutrients. Our bones protect our organs and support our body, part of the skeletal system. Skin protects us from germs and keeps water inside.\\n\\nQuestions:\\n- Which system controls actions and senses?\\n  0. Nervous system\\n  1. Digestive system\\n  2. Circulatory system\\n  3. Immune system\\n- What system breaks down the food we eat?\\n  0. The skeletal system\\n  1. The nervous system\\n  2. The immune system\\n  3. The digestive system\\n- Which system moves blood around the body?\\n  0. The digestive system\\n  1. The endocrine system\\n  2. The circulatory system\\n  3. The respiratory system\\n- What supports and gives the body its structure and framework?\\n  0. Heart\\n  1. Brain\\n  2. Blood Vessels\\n  3. Bones\\n- What outer layer of the organism protects from our environment and helps regulate body temperature?\\n  0. Skin\\n  1. Lungs\\n  2. Heart\\n  3. Brain\\n- Which sentence shows the structural supporting role played by bones and the skeletal system?\\n  0. Broken bones heal faster\\n  1. Bones support the body\\n  2. Bones are a hard substance\\n  3. Bone marrow makes hormones\\n- What happens if the respiratory system fails?\\n  0. The respiratory system only carries out breathing\\n  1. Your respiratory system brings O2 to the body and excretes CO2\\n  2. Blood exchanges CO2 only with the lungs in the body\\n  3. Blood carries O2 all over into the body's internal structures\\n- Select the line in the description that describes the immune system properly\\n  0. Stomach acid helps digest food\\n  1. The immune system identifies and helps remove foreign pathogens\\n  2. Nutrient absorption takes place in the liver\\n  3. Excretory system carries O2 from around tissues to the lungs for O2 and blood gases transportation\\n- Which statement best shows cooperation among all working body organs?\\n  0. Oxygen is taken in through the digestive system\\n  1. Bones control movement\\n  2. The circulatory system is only related to your skin\\n  3. Nutrients are distributed throughout your body through blood\\n\\nSection: Reading Comprehension Advanced\\nPassage:\\nA circular garden has a diameter of 10 meters. A gardener wants to create two more smaller circular gardens within the larger one, each with a perimeter smaller than the center's garden. The first is half the garden's radius as its radius. The first is perfectly placed along the circumference. The second small garden's perimeter is 1/5 more than half its smaller circle's diameter.\\n\\nQuestions:\\n- Considering both of the two half gardens and the complete whole garden, how do their radii compare size-wise?\\n  0. The smaller circle's diameter is 15 meters.\\n  1. The perimeter of the original bigger circle is larger than the total smaller area of the circle with approximately a 32-meter difference, which is more appropriate\\n  2. The radius of the central circle is similar to both the smaller areas with little change of less than 2 meters in perimeter, making this an approximation that is accurate to solve a geometrical construction problem.\\n  3. This question cannot be reasoned because to obtain results one cannot compare with given information\\n- Comparing the area including a single diameter length, including two inner smaller gardens' combined perimeter areas compared to the total length, which accurately states approximately their combined shape including central circular with another circular relation?\\n  0. The total gardens and how radii approximately equal, is there a constant?\\n  1. The entire total gardens is bigger comparatively speaking and hence radii are not exact compared to the main then entire bigger are approximately comparative of a little under total or about size as in comparison is approximate with near radius size with more the same circumference\\n  2. This problem is unable to be solved completely\\n  3. None of the above\\n- What exactly is the relationship of approximately equal proportion between the inner and outer perimeters of the garden total and comparatively each of which comparatively proportionally combined total these circles are proportionally?\\n  0. The combined area of smaller circles is bigger proportionally twice than the entire initial areas garden's smaller combined small area, both sizes radius size.\\n  1. The combined area of these of the both innermost radius gardens proportionally covers almost equally with combined garden compared approximate comparative measure including both twice area combined then single small gardens\\n  2. Radius compared are twice the sum approximate areas approximately double and smaller each radius with difference compared larger circular sizes proportionally related.\\n  3. Gardens are unable to compare sizes with exact measurements sizes sizes sizes\\n- Considering both areas with relation, considering the proportion these exactly sizes with exact measurement relations areas proportion how exactly does relationship look like for comparing areas together with these proportion?\\n  0. The area to each one has radius that it is half to what combined circles both of one one.\\n  1. Both two areas combined has exact smaller is half exact perimeter proportion as this bigger circle bigger radius diameter hence radius and combined two total exact same to entire are proportion half.\\n  2. Radius areas all three gardens proportional proportion double this that half what garden main larger one's double equal exactly half equal proportions but main.\\n  3. There is no exact relationship ratio calculation available because insufficient information is present to calculate all these precisely\\n- Talking about proportion of areas sizes, both the innermost, hence both inner circular of these total this areas including these circle both sizes proportional proportion both how approximately proportionally do comparing of sizes and compare both proportional accurately.\\n  0. This circle total proportionally this circles double half double exactly to large.\\n  1. Total half garden larger comparatively with almost combined proportion bigger comparative comparatively this large sizes proportionally speaking and considering circumference size\\n  2. Area are double but circumference are this proportion less because they exactly exactly related.\\n  3. This comparison is mathematically inappropriate to calculate proportions precisely compared to get values both these compare with without all given radius lengths diameters and total combined garden circles three including smaller that are both two\\n- How proportion these radius with diameters these the all three total all approximately are they related precisely proportion or it approximately related only approximately that approximately sizes?\\n  0. Circumferences are proportionally related to diameter radius smaller.\\n  1. Circumference circles areas compared have a ratio comparing their approximate are ratio between diameter, smaller garden.\\n  2. This exactly proportional exactly relationship diameter of exactly radius precisely but circumference also approximate size difference exactly related approximately very smaller comparative small compared overall large but that makes relation approximation inaccurate proportionally sizes.\\n  3. This problem can't exactly solve this solve accurately approximately it related sizes ratio diameter can compute using exact\\n- Using the combining of smaller radii twice compared to main what we got finally approximately relation between proportional to their total hence total combined circles with main size approximate how proportional in finally exact with ratio exact values or only approximately relation both?\\n  0. Sum radiuses total all combined exactly three\\n  1. Smaller two exact areas hence total comparing three exactly twice twice big once combined once approximate near equal approximately but close comparatively size combined combined.\\n  2. Areas sum are less then exactly close combined garden size garden both double small circle this approximate this proportion approximation this comparative approximately approximate same relation to main largest to proportion total\\n  3. None above proportion available compute exactly proportional proportion available to compute calculate compare comparison obtain proportion ratio size of main largest\\n- Using the proportion relation diameter the large comparing the double ratio of which diameter then using of which the radius half it is then total areas proportionally its these then how these relate finally proportion combined considering.\\n  0. Radius compared are twice and area proportionally that too approximately half approximately proportional only not approximately exactly only it is this proportion approximately half proportionally not\\n  1. Both combine exact area this almost exactly half approximately only total comparing comparing the of each approximate same this is this close smaller smaller once proportion exactly then total this area hence exactly related compared ratio\\n  2. Total the circles smaller garden approximately related proportionally because these to proportionally double of this which main circle total.\\n  3. This question difficult answer accurately due its inherent uncertainties inherent proportion compare of this to main related ratio approximate and with lack provided precise informations\\n- How both smaller comparatively proportions both exactly relation these approximately calculate their with ratio precisely but only approximation which approximate sizes but proportion these related exactly each related with proportion how compared .\\n  0. Both radiuses combined comparatively size area also approximately twice main total\\n  1. There combined almost three comparative equal areas and sum of twice with this.\\n  2. Approximate equal diameter comparatively sizes related proportion\\n  3. No information available given exactly how areas the sizes hence not available compare total areas comparatively their accurate relations can compare this insufficient calculation precise numbers provided make comparison with each proportional proportions not precise\\n\"}\n",
            "{'input': {'level': 'easy', 'prompt': 'Generate a new English exam'}, 'output': [{'exam_number': 4, 'sections': [{'passage_text': 'Building the pyramids was a huge task. Ancient Egyptians used simple tools, _______(1)____ they moved massive stone blocks. They also needed a giant workforce ______ (2)______ complete the work. The _______(3)_____ of workers lived near the site to lessen travel time, and their diets __________ (4) ________ mainly of bread and onions. Amazingly, these engineering _________(5)__________, constructed thousands of years ago, survive _____ (6)_______ today.', 'questions': [{'correct_option': 1, 'options': ['because', 'although', 'before', 'so'], 'question_text': 'Fill in the blank with the correct grammatical conjunction or linking word for blank 1.'}, {'correct_option': 2, 'options': ['to', 'in order that', 'so that', 'for to'], 'question_text': 'Fill in blank 2 using the conjunction/linking word to connect the clause; to describe the importance of a giant workforce.'}, {'correct_option': 2, 'options': ['few', 'much', 'many', 'more'], 'question_text': \"Which word correctly describes 'many'?\"}, {'correct_option': 1, 'options': ['consist', 'consisted', 'consists', 'To consist'], 'question_text': 'Fill blank 4 to correctly describe how the workforce obtained food during work.'}, {'correct_option': 3, 'options': ['miraculous', 'mysterious', 'mysterious', 'achievements'], 'question_text': 'Which word best describes success and result? Multiple options may be correct; select the closest.'}, {'correct_option': 1, 'options': ['for', 'from', 'until', 'towards'], 'question_text': 'Which preposition should be used for blank 6 to make the sentence grammatically valid?'}], 'section': 1, 'section_name': 'Cloze Grammar Vocabulary'}, {'passage_text': 'Making cartoons is a complex process. First, artists create storyboards, a __1__ of pictures that shows each scene. Next, they design the characters. __2__, the artists draw each character pose, called key posing. Then comes the in-between phases that require many drawings. __3__ this step is to put life and continuity into frames thus requiring much attention. Next, backgrounds are drawn carefully, matching colors chosen earlier. __4__ the images are colored using methods including painting with many digital tools. Finally, sound to match with animations is __6__.', 'questions': [{'correct_option': 0, 'options': ['set', 'group', 'bunch', 'crowd'], 'question_text': 'Select the best word to fill in blank 1.'}, {'correct_option': 2, 'options': ['After', 'Before', 'Next', 'Later'], 'question_text': 'Choose the perfect word for blank 2.'}, {'correct_option': 0, 'options': ['Purpose of', 'Objective of', 'The reason for', 'The goal of'], 'question_text': 'What replaces blank 3 correctly here?'}, {'correct_option': 1, 'options': ['After', 'then', 'later', 'earlier'], 'question_text': 'Select the correct pronoun to input for blank 4.'}, {'correct_option': 1, 'options': ['coloring', 'colored', 'color', 'colors'], 'question_text': 'Which word matches blank 5 appropriately?'}, {'correct_option': 0, 'options': ['added', 'included', 'joined', 'attached'], 'question_text': 'Choose an appropriate word to fill in the last sentence for blank 6.'}], 'section': 2, 'section_name': 'Cloze Contextual Vocabulary'}, {'passage_text': '', 'questions': [{'correct_option': 2, 'options': ['A. \"It originates from Hue.\" - \"Oh, I think I have tried it.\" - \"Which flavour particularly stands out?\" - \"My favorite Vietnamese traditional food is Bún bò Huế.\"', 'B. \"My favorite Vietnamese traditional food is Bún bò Huế.\" - \"Which flavour particularly stands out?\" - \"It originates from Hue.\" - \"Oh, I think I have tried it.\"', 'C. \"My favorite Vietnamese traditional food is Bún bò Huế.\" - \"It originates from Hue.\" - \"Oh, I think I\\'ve tried it.\" - \"Which flavour particularly stands out?\"', 'D. \"Which flavour particularly stands out?\" - \"My favorite Vietnamese traditional food is Bún bò Huế.\" - \"Oh, I think I have tried it.\" - \"It originates from Hue.\"'], 'question_text': 'Which choice shows the most natural and logical conversation flow about a favourite Vietnamese dish and its place of origin?'}, {'correct_option': 1, 'options': [\"A. Why don't you drink more milk? My friend often gives me this advice. To get more vitamin intake, that's all. Yes, I know very clearly already. I often get itchy quite strongly. What did your teacher advise for that?\", 'B. I often get my body itchy. What does your teacher often warn to do? Why avoid less milk? My friend said to keep a good body condition, you must drink milk. How about getting vitamin support, too?', \"C. I got so itchy quite a lot this month. What did your school teacher advise? Because you lack milk, that's why. Drink every day, right? To get vitamins, you should take more from fruits and supplement foods too!\", \"D. To get more vitamins, you should drink some milk but also take some supplements. What was the teacher's advice? I feel itchy so much. So my classmate told me to eat a lot of vegetables too.\"], 'question_text': 'Reorder the following conversation snippets logically: Showing health issues - Asking/giving causes - Offering suggestions/solutions - Confirming information / giving further comments.'}, {'correct_option': 2, 'options': ['A. \"Last night, I often got stomachaches because of too many sweets.\" - What must you eat to reduce this discomfort? - My mom often advises... - It depends on the symptoms that will be shown.', 'B. What must you eat to prevent your stomach from hurting? - It depends on other causes also. - Last night it hurt again badly. - My mom advised to eat more cauliflower regularly.', 'C. My stomach hurts badly after sweet candies that I have eaten last night. - What else can help? - What should you do for stomach care? - It depends too.', 'D. My mom advised to eat a lot of vegetables every day to care for the stomach. - It also depends on some conditions. - Because I ate too much candy last night, then I got quite a big stomach pain. - Should I take medicine?'], 'question_text': 'Organize the conversation by Stating the health complaint, offering a preventive plan, giving additional information/comment, Asking follow-up questions.'}, {'correct_option': 0, 'options': ['A. \"I am having an earache, Mom.\" -- \"Well, try to take a rest, my child. Don\\'t worry.\" --- \"When is the clinic available?\" -- \"Let\\'s go and see Dr. Thomas.\"', 'B. \"I am having an earache, my child.\" -- \"Don\\'t worry, my child.\" ---- \"Let\\'s go see our family doctor.\" --- \"Is our clinic available soon?\"', 'C. \"When is the clinic available?\" -- \"Let\\'s go and see the specialist.\" - \"I am suffering from a heavy headache.\" - --\"Don\\'t worry.\"', 'D. \"When is the clinic available?\" -\"Don\\'t worry, my child.\"-\" Let\\'s go see our family clinic.\" -- \"I\\'m having a headache, Mom.\"'], 'question_text': \"Choose the sequence for a conversation about a child's illness showing pain - Giving sympathy - Making an appointment - Offering immediate treatment.\"}, {'correct_option': 1, 'options': ['A. My brother is having a stuffy nose. - What a pity! Did the nurse give him medicines? - Well, hopefully, his symptoms soon get better. - Yes, of course.', 'B. What a pity! Did the nurse give him any medicine? - My brother is having a stuffy nose. - Yes, of course. - Well, hopefully, his symptoms will get better soon.', 'C. My brother is having a stuffy nose. - Does the nurse give the medicine yet? - Hopefully, they will be well. - It feels sorry.', \"D. What a pity - My brother is having a stuffy nose. - Yes, hopefully, it's soon alright - Did the nurse give him medicine already?\"], 'question_text': 'Choose the most suitable order for short conversations: Expressing sympathy - Asking for help/solution - Describing the issue - Showing positive hopefulness.'}], 'section': 3, 'section_name': 'Best Arrangement of Utterances'}, {'passage_text': \"Baseball has many rules. One important rule is about strikes. A strike is a bad pitch. If a batter has three strikes, he is 'out'. In the past, these rules did not always apply completely. Very recently, this particular ruling has changed.\", 'questions': [{'correct_option': 1, 'options': ['At the beginning of baseball', 'In the past, some adjustments to those rules have been applied recently.', 'Baseball just became harder lately.', 'Three strikes remains the common method all over the globe.'], 'question_text': \"Which statement best summarizes recent events concerning baseball's most important rules?\"}, {'correct_option': 3, 'options': ['A homerun grants four points automatically.', 'Scoring many consecutive hits.', 'Base hits.', \"Getting three 'strikes'.\"], 'question_text': \"What causes a player to be known as 'out'?\"}, {'correct_option': 1, 'options': ['A baseball is mainly made of ice', \"The exact composition or evolution wasn't completely clear long ago\", 'Many people once threw baseballs very far for leisure', 'This is a difficult question for me to answer.'], 'question_text': \"What, of the information provided, demonstrates how early information wasn't complete, given various potential perspectives?\"}, {'correct_option': 3, 'options': ['A \"strike\" means a player hits the wall.', 'It occurs while running around three pads', 'A missed landing at base', 'A bad or missed throw by the pitcher.'], 'question_text': \"What usually defines a 'Strike'?\"}, {'correct_option': 1, 'options': ['These are different forms of basketball and softball games respectively.', 'It implies there are minor variants regarding certain main rules. Some people also simply played the opposite way without strict standards before.', 'This game was actually played just with kicks until several ages backward. Thus, is one form or two.', 'A pitch requires certain movement to be valid even today.'], 'question_text': 'This baseball rule seems not fully standardized and had not consistently applied earlier. How best does this explain the possible changes?'}], 'section': 4, 'section_name': 'Cloze Informational Comprehension'}, {'passage_text': 'The Wright brothers, Orville and Wilbur, are famous for designing and building the first successful airplane. They made their first flight in 1903. Amelia Earhart was a brave pilot who disappeared during a flight attempt around the world. Banh Mi is a popular Vietnamese sandwich. Sir Tim Berners-Lee invented the World Wide Web. These are just a few examples highlighting technological strides in history. Early planes were very different to ones we see today!', 'questions': [{'correct_option': 2, 'options': ['Orville and Wilbur built a helicopter.', 'Their airplane was made over 100 years ago.', 'The Wright Brothers helped make the first airplanes successful.', \"They didn't successfully create vehicles that could go to space.\"], 'question_text': \"What is special about the Wright Brothers' contributions to aviation?\"}, {'correct_option': 1, 'options': ['Orville served as a president from Kentucky', 'Amelia Earhart aimed for history by flying near other continents.', 'Planes were extremely different in size when developed than we see today.', 'Inventors designed their machines over many millennia, many years before humans appeared on Earth.'], 'question_text': \"What is mentioned about Amelia Earhart's achievements related to aeronautics?\"}, {'correct_option': 3, 'options': ['They are famous for creating delicious submarine sandwiches in a Vietnamese shop near the flight test location.', 'Together these two men advanced early internet systems.', 'They created machines that eventually reached and explored multiple places near our solar system.', 'The brothers produced flying-related machinery.'], 'question_text': 'What kind of inventions did the people in this text create?'}, {'correct_option': 2, 'options': ['All modern aircrafts created since 1000 years back look absolutely the same.', \"It's still debatable about when people really created functioning aircraft.\", 'Very older airplanes show amazing changes when seeing them from before up until modern technology has improved planes greatly.', 'None of these points appear mentioned previously in this document.'], 'question_text': 'How do the airplanes we witness nowadays show improvements as indicated in this reading about historic inventions?'}, {'correct_option': 1, 'options': ['I believe there are no differences that existed during early days compared to those created today.', 'There were remarkable size differences.', 'Aviation only recently begun, only about less than half a century ago compared to the creation dates of the airplanes mentioned.', \"That doesn't include aviation from earlier times, considering history shows differences between both earlier developments and other developments afterward.\"], 'question_text': 'How might the earliest manufactured air transport objects compare to those built several time periods/generations back then to the type manufactured these days (now)?'}, {'correct_option': 2, 'options': ['Making Banh Mi.', 'Developing the World Wide Web.', 'Creating the first airplanes.', 'Studying in high-schools and beyond before moving to further studying in future Universities outside Vietnam.'], 'question_text': 'What achievement are the Wrights noted by multiple people in history references mentioned for widely?'}, {'correct_option': 3, 'options': ['The text compares different inventions and other developments within aviation.', \"Orville's life has significantly moved into space exploration discoveries.\", \"Sir Tim's developments never affected the development (and/or success of) the future air flights to any large degrees involving the aviation topic.\", \"Earhart's accomplishments focus specifically on aviation-related pursuits developed within this area/expertise only without any possible comparisons to other types of technology anywhere or even others.\"], 'question_text': \"Select the suitable detail summarizing Amelia Earhart's achievements in the Aviation industry.\"}, {'correct_option': 2, 'options': ['The developments focus on computer, submarine (or possibly submarine-like related technology inventions).', 'That included the advancements and creations involved in space explorations, but never airplane innovations to affect our lives greatly.', 'Improvements that improve types of transportation to our locations, plus increase types of mobility involve aviation mentioned herein; are mentioned as improvements of great influence affecting this history.', 'History never mentions many key things mentioned throughout these sentences.'], 'question_text': 'The inventions created here what common thread regarding affecting our everyday existence today?'}, {'correct_option': 1, 'options': [\"The passage mainly focuses on showing the earliest inventions' achievements, from inventions to inventions.\", 'An advancement or evolution is emphasized to show emphasis involving the evolution of the innovations, changes as we see today.', \"Mainly to reveal earlier development achievements' comparisons.\", 'Only explaining achievements made or comparing multiple similar technologies created during history time/timelines shown in passages before including details from timelines given during their various durations before during/those times; respectively.'], 'question_text': 'What is the key idea across the majority of aspects/information described involving content mentioned in the text provided particularly related primarily specifically to topics presented previously that should be taken away as an impression made to this reader?'}], 'section': 5, 'section_name': 'Reading Comprehension'}, {'passage_text': \"Thai proverbs and idioms offer rich cultural insights. One states, 'Even a fish on land knows no shame.' It doesn’t directly describe a literal fish. Similarly, 'Don’t carry a dead fish for years to come.'\", 'questions': [{'correct_option': 1, 'options': ['It emphasizes the resilience of fish.', 'It implies accepting humiliation rather than complaining loudly to help ease such a circumstance.', 'The phrase signifies being ashamed even having made a mistake.', 'It stresses that hard challenges we may face can be resolved naturally.'], 'question_text': \"What does the metaphorical proverb 'Even a fish knows no shame' most likely suggest?\"}, {'correct_option': 1, 'options': ['Carrying many useless goods.', 'Being burdened by past mistakes.', 'One must get off at their respective stops.', 'Letting go of burdens without thinking hard about the cause.'], 'question_text': \"What could accurately characterize this expression: 'Don’t carry a dead fish for years'?\"}, {'correct_option': 1, 'options': ['Thai proverbs never use figurative words or actions directly depicting what you said.', 'Abstract sayings sometimes avoid the topic stated literally.', 'It has no specific context given.', 'All Thai proverbs provide both explanations and illustrations in meaning.'], 'question_text': \"Why is it challenging to interpret Thai expressions such as 'Even a fish...'?\"}, {'correct_option': 3, 'options': ['It needs you to find ways to help yourself when no luck is given or in general.', 'Learn skills associated with each culture effectively for understanding their wisdom in idioms.', 'A successful life brings fortune only if the luck of the country is favorable.', 'Indirect ways of stating are usually hidden inside traditional metaphors associated only with that group of people speaking and using it.'], 'question_text': 'Can we gather certain patterns and themes to tackle idiom comprehension?'}, {'correct_option': 1, 'options': ['They rarely mention morality principles expressed inside their words.', 'Figurative language helps reflect that they always state with another indirect layer.', 'They are very easy to find.', \"Any proverb explains clearly its words' definitions inside the expression itself given.\"], 'question_text': 'Thai proverbs are often characterized by what aspect that is worth examining?'}, {'correct_option': 0, 'options': ['These proverbs have historical values relating strongly to a topic being presented as illustrations from them.', 'Its primary goal includes encouraging each audience to find common lessons despite background differences.', \"Traditional lessons presented should respect current beliefs among today's individuals only while referring to it indirectly still as an illustration only using examples related to historical figures or events.\", 'Moral and practical advice may appear separately as each individual lessons instead of conveying them inside words only in proverbs specifically created for showing moral instructions.'], 'question_text': 'What potential functions do we find usually inside similar types of traditional sayings often studied?'}, {'correct_option': 2, 'options': [\"People study hard proverbs to understand clearly what's stated from the expression used clearly from the context.\", \"Cultural misunderstandings should depend less on context; idioms may be found harder to understand compared than ordinary terms when referring to things around one's daily use and environment.\", 'Learning a language involves much to culture; we could understand others if we only examine this as only learning proverbs and only to give answers relating to that without digging deeper details from each statement involved inside them.', 'Studying Thai idioms alone can give us the full understanding behind every single unique meaning present related cultures only without digging deeper behind lessons implied or mentioned elsewhere throughout Thai communities particularly.'], 'question_text': 'In analyzing culture understanding when one aims specifically just to look for deeper explanation using one single idiom from some given book describing specifically the context involved inside that selected material without aiming to find the other various clues from somewhere else or context surrounding that context but just on particular aspect focusing on finding answers related to idioms specifically within selected topics only instead of outside resources is usually a bad approach for helping to understand things especially ones may be explained vaguely from that limited information available why?'}, {'correct_option': 3, 'options': ['One should focus entirely on idioms without examining further insights culturally relevant topics only present directly stated given proverb example rather learn how context affects interpretations and conclusions formed throughout learning materials while looking around various related fields outside solely relying on given provided information only also.', 'Study traditional statements focusing their words inside that context given proverbs related to Thai culture. You ignore details from further findings around these points relating proverbs while examining solely them individually and not consider insights beyond that individual element itself. It helps to improve better understanding of each of the proverbs discussed while learning.', 'Approach every single traditional lesson aiming solely at studying aspects inside phrases regardless of whether finding extra outside context or hints clues from other references elsewhere may improve understandings these cultural references usually provide each of the individuals using the statement. You use an approach as learn solely focusing aspects shown from proverbs with understanding meanings individually without relying on outside contexts.', 'We must synthesize and correlate various perspectives for a broad cultural awareness particularly regarding each interpretation of each lesson involved with their phrases, comparing meanings between each lesson, finding references through other information sources around these elements studied with deeper examinations regarding those given selected items with references outside material related cultural learning perspectives overall. That should give us perspectives that broad contextual awareness required complete insights relating behind culturally present statements mentioned from them.'], 'question_text': 'How might one improve their skill at grasping meanings inside various perspectives may improve better grasp at comprehending proverbs within culture studies especially one related specifically certain kinds sayings typically culturally based specifically through cultural learning perspective within individuals while one learns?'}, {'correct_option': 0, 'options': ['Literally interpreting each selected sentence leads the answer shown correct throughout the selection.', 'Finding out synonyms listed correctly leads correctly interpretations of the meaning accurately explaining phrases without studying the background or using contexts explaining such details further throughout reading other literature helping us comprehend such topics further improving the grasp that such topic usually includes culturally throughout the lessons.', \"Context-centered approaches in assessing answers throughout solving problems involving interpretations regarding what's happening during such particular parts help gain deeper understanding towards such problems involved and hence improved solutions are shown accurately towards providing answers accurately while examining carefully during analyses performed which would help improve the ability for solving these particular related parts particularly. Focusing these during learning phrases improve ability learn better while grasping their words further involved for correctly provide proper statements reflecting interpretations for evaluating words within phrases selected.\", 'Relying on direct translation from a dictionary sometimes hinders understanding of implications meaning of such figurative terms; applying specific details culturally helps deepen analyses provided from words using these idioms for determining the answer throughout problem-solving questions accurately shown specifically while analyzing carefully.'], 'question_text': 'Which study will offer greater culturally related learning improving learning towards such aspect?'}], 'section': 6, 'section_name': 'Reading Comprehension Advanced'}]}], 'prompt': [], 'formatted_output': 'Section: Cloze Grammar Vocabulary\\nPassage:\\nBuilding the pyramids was a huge task. Ancient Egyptians used simple tools, _______(1)____ they moved massive stone blocks. They also needed a giant workforce ______ (2)______ complete the work. The _______(3)_____ of workers lived near the site to lessen travel time, and their diets __________ (4) ________ mainly of bread and onions. Amazingly, these engineering _________(5)__________, constructed thousands of years ago, survive _____ (6)_______ today.\\n\\nQuestions:\\n- Fill in the blank with the correct grammatical conjunction or linking word for blank 1.\\n  0. because\\n  1. although\\n  2. before\\n  3. so\\n- Fill in blank 2 using the conjunction/linking word to connect the clause; to describe the importance of a giant workforce.\\n  0. to\\n  1. in order that\\n  2. so that\\n  3. for to\\n- Which word correctly describes \\'many\\'?\\n  0. few\\n  1. much\\n  2. many\\n  3. more\\n- Fill blank 4 to correctly describe how the workforce obtained food during work.\\n  0. consist\\n  1. consisted\\n  2. consists\\n  3. To consist\\n- Which word best describes success and result? Multiple options may be correct; select the closest.\\n  0. miraculous\\n  1. mysterious\\n  2. mysterious\\n  3. achievements\\n- Which preposition should be used for blank 6 to make the sentence grammatically valid?\\n  0. for\\n  1. from\\n  2. until\\n  3. towards\\n\\nSection: Cloze Contextual Vocabulary\\nPassage:\\nMaking cartoons is a complex process. First, artists create storyboards, a __1__ of pictures that shows each scene. Next, they design the characters. __2__, the artists draw each character pose, called key posing. Then comes the in-between phases that require many drawings. __3__ this step is to put life and continuity into frames thus requiring much attention. Next, backgrounds are drawn carefully, matching colors chosen earlier. __4__ the images are colored using methods including painting with many digital tools. Finally, sound to match with animations is __6__.\\n\\nQuestions:\\n- Select the best word to fill in blank 1.\\n  0. set\\n  1. group\\n  2. bunch\\n  3. crowd\\n- Choose the perfect word for blank 2.\\n  0. After\\n  1. Before\\n  2. Next\\n  3. Later\\n- What replaces blank 3 correctly here?\\n  0. Purpose of\\n  1. Objective of\\n  2. The reason for\\n  3. The goal of\\n- Select the correct pronoun to input for blank 4.\\n  0. After\\n  1. then\\n  2. later\\n  3. earlier\\n- Which word matches blank 5 appropriately?\\n  0. coloring\\n  1. colored\\n  2. color\\n  3. colors\\n- Choose an appropriate word to fill in the last sentence for blank 6.\\n  0. added\\n  1. included\\n  2. joined\\n  3. attached\\n\\nSection: Best Arrangement of Utterances\\nQuestions:\\n- Which choice shows the most natural and logical conversation flow about a favourite Vietnamese dish and its place of origin?\\n  0. A. \"It originates from Hue.\" - \"Oh, I think I have tried it.\" - \"Which flavour particularly stands out?\" - \"My favorite Vietnamese traditional food is Bún bò Huế.\"\\n  1. B. \"My favorite Vietnamese traditional food is Bún bò Huế.\" - \"Which flavour particularly stands out?\" - \"It originates from Hue.\" - \"Oh, I think I have tried it.\"\\n  2. C. \"My favorite Vietnamese traditional food is Bún bò Huế.\" - \"It originates from Hue.\" - \"Oh, I think I\\'ve tried it.\" - \"Which flavour particularly stands out?\"\\n  3. D. \"Which flavour particularly stands out?\" - \"My favorite Vietnamese traditional food is Bún bò Huế.\" - \"Oh, I think I have tried it.\" - \"It originates from Hue.\"\\n- Reorder the following conversation snippets logically: Showing health issues - Asking/giving causes - Offering suggestions/solutions - Confirming information / giving further comments.\\n  0. A. Why don\\'t you drink more milk? My friend often gives me this advice. To get more vitamin intake, that\\'s all. Yes, I know very clearly already. I often get itchy quite strongly. What did your teacher advise for that?\\n  1. B. I often get my body itchy. What does your teacher often warn to do? Why avoid less milk? My friend said to keep a good body condition, you must drink milk. How about getting vitamin support, too?\\n  2. C. I got so itchy quite a lot this month. What did your school teacher advise? Because you lack milk, that\\'s why. Drink every day, right? To get vitamins, you should take more from fruits and supplement foods too!\\n  3. D. To get more vitamins, you should drink some milk but also take some supplements. What was the teacher\\'s advice? I feel itchy so much. So my classmate told me to eat a lot of vegetables too.\\n- Organize the conversation by Stating the health complaint, offering a preventive plan, giving additional information/comment, Asking follow-up questions.\\n  0. A. \"Last night, I often got stomachaches because of too many sweets.\" - What must you eat to reduce this discomfort? - My mom often advises... - It depends on the symptoms that will be shown.\\n  1. B. What must you eat to prevent your stomach from hurting? - It depends on other causes also. - Last night it hurt again badly. - My mom advised to eat more cauliflower regularly.\\n  2. C. My stomach hurts badly after sweet candies that I have eaten last night. - What else can help? - What should you do for stomach care? - It depends too.\\n  3. D. My mom advised to eat a lot of vegetables every day to care for the stomach. - It also depends on some conditions. - Because I ate too much candy last night, then I got quite a big stomach pain. - Should I take medicine?\\n- Choose the sequence for a conversation about a child\\'s illness showing pain - Giving sympathy - Making an appointment - Offering immediate treatment.\\n  0. A. \"I am having an earache, Mom.\" -- \"Well, try to take a rest, my child. Don\\'t worry.\" --- \"When is the clinic available?\" -- \"Let\\'s go and see Dr. Thomas.\"\\n  1. B. \"I am having an earache, my child.\" -- \"Don\\'t worry, my child.\" ---- \"Let\\'s go see our family doctor.\" --- \"Is our clinic available soon?\"\\n  2. C. \"When is the clinic available?\" -- \"Let\\'s go and see the specialist.\" - \"I am suffering from a heavy headache.\" - --\"Don\\'t worry.\"\\n  3. D. \"When is the clinic available?\" -\"Don\\'t worry, my child.\"-\" Let\\'s go see our family clinic.\" -- \"I\\'m having a headache, Mom.\"\\n- Choose the most suitable order for short conversations: Expressing sympathy - Asking for help/solution - Describing the issue - Showing positive hopefulness.\\n  0. A. My brother is having a stuffy nose. - What a pity! Did the nurse give him medicines? - Well, hopefully, his symptoms soon get better. - Yes, of course.\\n  1. B. What a pity! Did the nurse give him any medicine? - My brother is having a stuffy nose. - Yes, of course. - Well, hopefully, his symptoms will get better soon.\\n  2. C. My brother is having a stuffy nose. - Does the nurse give the medicine yet? - Hopefully, they will be well. - It feels sorry.\\n  3. D. What a pity - My brother is having a stuffy nose. - Yes, hopefully, it\\'s soon alright - Did the nurse give him medicine already?\\n\\nSection: Cloze Informational Comprehension\\nPassage:\\nBaseball has many rules. One important rule is about strikes. A strike is a bad pitch. If a batter has three strikes, he is \\'out\\'. In the past, these rules did not always apply completely. Very recently, this particular ruling has changed.\\n\\nQuestions:\\n- Which statement best summarizes recent events concerning baseball\\'s most important rules?\\n  0. At the beginning of baseball\\n  1. In the past, some adjustments to those rules have been applied recently.\\n  2. Baseball just became harder lately.\\n  3. Three strikes remains the common method all over the globe.\\n- What causes a player to be known as \\'out\\'?\\n  0. A homerun grants four points automatically.\\n  1. Scoring many consecutive hits.\\n  2. Base hits.\\n  3. Getting three \\'strikes\\'.\\n- What, of the information provided, demonstrates how early information wasn\\'t complete, given various potential perspectives?\\n  0. A baseball is mainly made of ice\\n  1. The exact composition or evolution wasn\\'t completely clear long ago\\n  2. Many people once threw baseballs very far for leisure\\n  3. This is a difficult question for me to answer.\\n- What usually defines a \\'Strike\\'?\\n  0. A \"strike\" means a player hits the wall.\\n  1. It occurs while running around three pads\\n  2. A missed landing at base\\n  3. A bad or missed throw by the pitcher.\\n- This baseball rule seems not fully standardized and had not consistently applied earlier. How best does this explain the possible changes?\\n  0. These are different forms of basketball and softball games respectively.\\n  1. It implies there are minor variants regarding certain main rules. Some people also simply played the opposite way without strict standards before.\\n  2. This game was actually played just with kicks until several ages backward. Thus, is one form or two.\\n  3. A pitch requires certain movement to be valid even today.\\n\\nSection: Reading Comprehension\\nPassage:\\nThe Wright brothers, Orville and Wilbur, are famous for designing and building the first successful airplane. They made their first flight in 1903. Amelia Earhart was a brave pilot who disappeared during a flight attempt around the world. Banh Mi is a popular Vietnamese sandwich. Sir Tim Berners-Lee invented the World Wide Web. These are just a few examples highlighting technological strides in history. Early planes were very different to ones we see today!\\n\\nQuestions:\\n- What is special about the Wright Brothers\\' contributions to aviation?\\n  0. Orville and Wilbur built a helicopter.\\n  1. Their airplane was made over 100 years ago.\\n  2. The Wright Brothers helped make the first airplanes successful.\\n  3. They didn\\'t successfully create vehicles that could go to space.\\n- What is mentioned about Amelia Earhart\\'s achievements related to aeronautics?\\n  0. Orville served as a president from Kentucky\\n  1. Amelia Earhart aimed for history by flying near other continents.\\n  2. Planes were extremely different in size when developed than we see today.\\n  3. Inventors designed their machines over many millennia, many years before humans appeared on Earth.\\n- What kind of inventions did the people in this text create?\\n  0. They are famous for creating delicious submarine sandwiches in a Vietnamese shop near the flight test location.\\n  1. Together these two men advanced early internet systems.\\n  2. They created machines that eventually reached and explored multiple places near our solar system.\\n  3. The brothers produced flying-related machinery.\\n- How do the airplanes we witness nowadays show improvements as indicated in this reading about historic inventions?\\n  0. All modern aircrafts created since 1000 years back look absolutely the same.\\n  1. It\\'s still debatable about when people really created functioning aircraft.\\n  2. Very older airplanes show amazing changes when seeing them from before up until modern technology has improved planes greatly.\\n  3. None of these points appear mentioned previously in this document.\\n- How might the earliest manufactured air transport objects compare to those built several time periods/generations back then to the type manufactured these days (now)?\\n  0. I believe there are no differences that existed during early days compared to those created today.\\n  1. There were remarkable size differences.\\n  2. Aviation only recently begun, only about less than half a century ago compared to the creation dates of the airplanes mentioned.\\n  3. That doesn\\'t include aviation from earlier times, considering history shows differences between both earlier developments and other developments afterward.\\n- What achievement are the Wrights noted by multiple people in history references mentioned for widely?\\n  0. Making Banh Mi.\\n  1. Developing the World Wide Web.\\n  2. Creating the first airplanes.\\n  3. Studying in high-schools and beyond before moving to further studying in future Universities outside Vietnam.\\n- Select the suitable detail summarizing Amelia Earhart\\'s achievements in the Aviation industry.\\n  0. The text compares different inventions and other developments within aviation.\\n  1. Orville\\'s life has significantly moved into space exploration discoveries.\\n  2. Sir Tim\\'s developments never affected the development (and/or success of) the future air flights to any large degrees involving the aviation topic.\\n  3. Earhart\\'s accomplishments focus specifically on aviation-related pursuits developed within this area/expertise only without any possible comparisons to other types of technology anywhere or even others.\\n- The inventions created here what common thread regarding affecting our everyday existence today?\\n  0. The developments focus on computer, submarine (or possibly submarine-like related technology inventions).\\n  1. That included the advancements and creations involved in space explorations, but never airplane innovations to affect our lives greatly.\\n  2. Improvements that improve types of transportation to our locations, plus increase types of mobility involve aviation mentioned herein; are mentioned as improvements of great influence affecting this history.\\n  3. History never mentions many key things mentioned throughout these sentences.\\n- What is the key idea across the majority of aspects/information described involving content mentioned in the text provided particularly related primarily specifically to topics presented previously that should be taken away as an impression made to this reader?\\n  0. The passage mainly focuses on showing the earliest inventions\\' achievements, from inventions to inventions.\\n  1. An advancement or evolution is emphasized to show emphasis involving the evolution of the innovations, changes as we see today.\\n  2. Mainly to reveal earlier development achievements\\' comparisons.\\n  3. Only explaining achievements made or comparing multiple similar technologies created during history time/timelines shown in passages before including details from timelines given during their various durations before during/those times; respectively.\\n\\nSection: Reading Comprehension Advanced\\nPassage:\\nThai proverbs and idioms offer rich cultural insights. One states, \\'Even a fish on land knows no shame.\\' It doesn’t directly describe a literal fish. Similarly, \\'Don’t carry a dead fish for years to come.\\'\\n\\nQuestions:\\n- What does the metaphorical proverb \\'Even a fish knows no shame\\' most likely suggest?\\n  0. It emphasizes the resilience of fish.\\n  1. It implies accepting humiliation rather than complaining loudly to help ease such a circumstance.\\n  2. The phrase signifies being ashamed even having made a mistake.\\n  3. It stresses that hard challenges we may face can be resolved naturally.\\n- What could accurately characterize this expression: \\'Don’t carry a dead fish for years\\'?\\n  0. Carrying many useless goods.\\n  1. Being burdened by past mistakes.\\n  2. One must get off at their respective stops.\\n  3. Letting go of burdens without thinking hard about the cause.\\n- Why is it challenging to interpret Thai expressions such as \\'Even a fish...\\'?\\n  0. Thai proverbs never use figurative words or actions directly depicting what you said.\\n  1. Abstract sayings sometimes avoid the topic stated literally.\\n  2. It has no specific context given.\\n  3. All Thai proverbs provide both explanations and illustrations in meaning.\\n- Can we gather certain patterns and themes to tackle idiom comprehension?\\n  0. It needs you to find ways to help yourself when no luck is given or in general.\\n  1. Learn skills associated with each culture effectively for understanding their wisdom in idioms.\\n  2. A successful life brings fortune only if the luck of the country is favorable.\\n  3. Indirect ways of stating are usually hidden inside traditional metaphors associated only with that group of people speaking and using it.\\n- Thai proverbs are often characterized by what aspect that is worth examining?\\n  0. They rarely mention morality principles expressed inside their words.\\n  1. Figurative language helps reflect that they always state with another indirect layer.\\n  2. They are very easy to find.\\n  3. Any proverb explains clearly its words\\' definitions inside the expression itself given.\\n- What potential functions do we find usually inside similar types of traditional sayings often studied?\\n  0. These proverbs have historical values relating strongly to a topic being presented as illustrations from them.\\n  1. Its primary goal includes encouraging each audience to find common lessons despite background differences.\\n  2. Traditional lessons presented should respect current beliefs among today\\'s individuals only while referring to it indirectly still as an illustration only using examples related to historical figures or events.\\n  3. Moral and practical advice may appear separately as each individual lessons instead of conveying them inside words only in proverbs specifically created for showing moral instructions.\\n- In analyzing culture understanding when one aims specifically just to look for deeper explanation using one single idiom from some given book describing specifically the context involved inside that selected material without aiming to find the other various clues from somewhere else or context surrounding that context but just on particular aspect focusing on finding answers related to idioms specifically within selected topics only instead of outside resources is usually a bad approach for helping to understand things especially ones may be explained vaguely from that limited information available why?\\n  0. People study hard proverbs to understand clearly what\\'s stated from the expression used clearly from the context.\\n  1. Cultural misunderstandings should depend less on context; idioms may be found harder to understand compared than ordinary terms when referring to things around one\\'s daily use and environment.\\n  2. Learning a language involves much to culture; we could understand others if we only examine this as only learning proverbs and only to give answers relating to that without digging deeper details from each statement involved inside them.\\n  3. Studying Thai idioms alone can give us the full understanding behind every single unique meaning present related cultures only without digging deeper behind lessons implied or mentioned elsewhere throughout Thai communities particularly.\\n- How might one improve their skill at grasping meanings inside various perspectives may improve better grasp at comprehending proverbs within culture studies especially one related specifically certain kinds sayings typically culturally based specifically through cultural learning perspective within individuals while one learns?\\n  0. One should focus entirely on idioms without examining further insights culturally relevant topics only present directly stated given proverb example rather learn how context affects interpretations and conclusions formed throughout learning materials while looking around various related fields outside solely relying on given provided information only also.\\n  1. Study traditional statements focusing their words inside that context given proverbs related to Thai culture. You ignore details from further findings around these points relating proverbs while examining solely them individually and not consider insights beyond that individual element itself. It helps to improve better understanding of each of the proverbs discussed while learning.\\n  2. Approach every single traditional lesson aiming solely at studying aspects inside phrases regardless of whether finding extra outside context or hints clues from other references elsewhere may improve understandings these cultural references usually provide each of the individuals using the statement. You use an approach as learn solely focusing aspects shown from proverbs with understanding meanings individually without relying on outside contexts.\\n  3. We must synthesize and correlate various perspectives for a broad cultural awareness particularly regarding each interpretation of each lesson involved with their phrases, comparing meanings between each lesson, finding references through other information sources around these elements studied with deeper examinations regarding those given selected items with references outside material related cultural learning perspectives overall. That should give us perspectives that broad contextual awareness required complete insights relating behind culturally present statements mentioned from them.\\n- Which study will offer greater culturally related learning improving learning towards such aspect?\\n  0. Literally interpreting each selected sentence leads the answer shown correct throughout the selection.\\n  1. Finding out synonyms listed correctly leads correctly interpretations of the meaning accurately explaining phrases without studying the background or using contexts explaining such details further throughout reading other literature helping us comprehend such topics further improving the grasp that such topic usually includes culturally throughout the lessons.\\n  2. Context-centered approaches in assessing answers throughout solving problems involving interpretations regarding what\\'s happening during such particular parts help gain deeper understanding towards such problems involved and hence improved solutions are shown accurately towards providing answers accurately while examining carefully during analyses performed which would help improve the ability for solving these particular related parts particularly. Focusing these during learning phrases improve ability learn better while grasping their words further involved for correctly provide proper statements reflecting interpretations for evaluating words within phrases selected.\\n  3. Relying on direct translation from a dictionary sometimes hinders understanding of implications meaning of such figurative terms; applying specific details culturally helps deepen analyses provided from words using these idioms for determining the answer throughout problem-solving questions accurately shown specifically while analyzing carefully.\\n'}\n",
            "{'input': {'level': 'easy', 'prompt': 'Generate a new English exam'}, 'output': [{'exam_number': 5, 'sections': [{'passage_text': 'Honeybees live in large groups called colonies. Each colony has one queen bee, who is responsible for ______ eggs. Worker bees collect nectar from flowers and make honey, while drone bees _____ mate with the queen. Bees use a special dance _____ each other about their sources of food.', 'questions': [{'correct_option': 0, 'options': ['lays', 'laying', 'to lay', 'laid'], 'question_text': '1. Choose the grammatically correct and contextually appropriate verb form for the blank in the first sentence.'}, {'correct_option': 1, 'options': ['do', 'to', 'does', 'doing'], 'question_text': \"2. Select the word that best completes the meaning considering drone bees' roles in the colony.\"}, {'correct_option': 0, 'options': ['to communicate', 'communication', 'communicate', 'communicating'], 'question_text': '3. Pick the correct verb to properly connect the idea about using dance to inform insects.'}, {'correct_option': 3, 'options': ['some', 'much', 'more', 'many'], 'question_text': \"4. Choose the word best suiting '_____ flowers are needed to create honey', from a colony that contains both the foragers from older bees and newer brood members which must sustain itself as an entity.\"}, {'correct_option': 0, 'options': ['sweetness', 'sweet', 'sweetly', 'sweeter'], 'question_text': \"5. Choose words best describing the deliciousness concerning 'Honey has a delightful ______'.\"}, {'correct_option': 1, 'options': ['on', 'in', 'at', 'above'], 'question_text': \"6. Choose the appropriate preposition for the question: Bee's nectar originates _____ various regions in the natural world considering various flower locations.\"}], 'section': 1, 'section_name': 'Cloze Grammar Vocabulary'}, {'passage_text': 'The internet has changed our lives in many ways. We can now (1) ___ with people all over the world instantly. We buy things (2) ___ and we learn new things through (3) _____. We even have (4) ___ access to libraries. Reading and entertainment have evolved through this digital space. There are unlimited options to both explore new experiences (5)____and enhance leisure. It has, to significant advantage, replaced (6) _____ processes where things had to be in writing with electronic ways of going about our lives.', 'questions': [{'correct_option': 0, 'options': ['communicate', 'listen', 'sing', 'watch'], 'question_text': 'Choose options that best fits (1).'}, {'correct_option': 0, 'options': ['quickly', 'slowly', 'carefully', 'rudely'], 'question_text': 'Choose the word that best fits (2).'}, {'correct_option': 2, 'options': ['letters', 'meetings', 'websites', 'phones'], 'question_text': 'What suits best to fit (3)?'}, {'correct_option': 1, 'options': ['difficult', 'easy', 'old fashioned', 'expensive'], 'question_text': 'Select the most appropriate word for (4).'}, {'correct_option': 0, 'options': ['and', 'yet', 'so', 'but'], 'question_text': 'Choose a good connector that joins meanings of the 2 phrases after it, best fits in blank that (5) shows.'}, {'correct_option': 2, 'options': ['new', 'modern', 'traditional', 'old'], 'question_text': '\"(?) traditional processes\", it correctly describes such traditional processes that should be completed physically. Which fits perfectly among option, hence replacing this(?) should best explain correctly.'}], 'section': 2, 'section_name': 'Cloze Contextual Vocabulary'}, {'passage_text': '', 'questions': [{'correct_option': 0, 'options': ['The fox turned into a rabbit with beautiful white fur.', \"However, other heavenly creatures thought no; she stayed in home that made everyone laugh. They're all excited about the nice warm moment, and everyone around becomes happy.\", 'A kind fox and other stars appeared happily.', 'Once upon a time, near that little magical house they played and made them stay happily forever. Even made all that they celebrated and had wonderful gifts! This means she gets new job!'], 'question_text': \"Organize the next statements related to Moon's friends in a logical narration order from the story to tell an exciting joyful story of friendly friendship.\"}, {'correct_option': 2, 'options': ['She looked at clouds above seeing everything. And she became the happy one.', 'This meant we celebrate Mid.', 'It was a Full Harvest moon.', 'They had a big party that autumn day.'], 'question_text': 'Put the sentences in order to show a celebration of the moon.'}, {'correct_option': 1, 'options': ['The old woman and the kids did enjoy it.', 'The girl saw it in Moon. Then She was grateful.', 'It brightened as he wished happiness upon several kids who felt thankful upon it and her friends helped her friends.', 'One night before Halloween her parents enjoyed having fun eating meals.'], 'question_text': 'Rearrange these sentences to create a short story about the Moon becoming brighter:'}, {'correct_option': 0, 'options': ['Once upon a time, there was a beautiful girl who lived on Earth. Then came this big scary fox. The girl lived as happily as before.', 'Once upon a time, there was a girl who climbed Heaven, saw all, and became the Moon.', 'There was no moon as beautiful moon that bright.', 'The rabbit on sky loved it even more.'], 'question_text': 'Arrange the following sentences to make a meaningful story about the Moon:'}, {'correct_option': 3, 'options': [\"A. I find many ancient artefacts such as bronzes have spiritual depth and great meaning. B. That unique approach is definitely attractive, isn't it? It's quite a rare beauty among others.. C. Bronze represents a cultural symbol for Vietnamese artistic evolution\", 'A.You could visit Hoi An to admire more exquisite stone and lacquer items? B.Yes sure indeed C. That sounds interesting. What about pottery and ceramic, any suggestions?, . , D. There are very abundant resources within areas displaying lots those special type products \". . E. Very valuable resources , F. That helps to conserve beauty and national identities .G. Are those local hand crafting, H. Such great conservation!', \"Actually, this contemporary art I am viewing seems quite symbolic! Its spiritual. B. Oh Really! . How many years It lasted in making? ?. That incredible isn't. B. Many techniques combined. Are we currently witnessing those materials What does mean for creating?, C. Most amazing technique!\", 'A. Well let me see There are more than two different layers. B. Those special process indeed C. But quite tedious work. Lots time effort And needs so great attention Is there certain style or technique used to depict culture of local community ? .. . . D. Yeah really lots great detailed Lots small work requires attention .. . E. These art are great resources to conserve cultures deeply to promote and preserving identity F. Such a marvelous techniques involved. .Very amazing!'], 'question_text': 'Select the most logically sequenced dialogue concerning discussion about the uniqueness of Vietnamese Fine Artwork particularly Lacquerware or artistic styles made specifically?'}], 'section': 3, 'section_name': 'Best Arrangement of Utterances'}, {'passage_text': 'My dream house is a cozy cottage near the beach. It’s small, but comfortable. _____________(1) The walls are painted a calming blue, and the roof is made of orange tiles. Inside, _________(2) It will have a large kitchen because I love to cook and ________(3) There’s going to be two rooms including an artistic looking bathroom, and the big window that I need. A garden full of __________ flowers and my cozy house looks like they’re belonging to another dreamy realm!', 'questions': [{'correct_option': 0, 'options': ['It suggests a peaceful and natural feel.', 'It has a very spacious design, to feel more calm', 'The environment sounds too modern thus not relevant.', 'It appears as to not fit very accurately into the context given earlier'], 'question_text': 'From the text, which among option (0).(1),.2),(3,) sentences sound correctly described the overall described mood and style based on the description presented in the writing'}, {'correct_option': 1, 'options': ['It needs a small garden.', 'It has big windows and lots of natural light.', 'Its garden is small and simple.', 'The walls are brown and ugly'], 'question_text': 'Which of these BEST describes what can be read in section 1 of the passage?'}, {'correct_option': 3, 'options': ['there will many rooms.', 'there will lots of small tables next to the kitchen island .', 'the house needs fixing.', 'it has many relaxing attributes'], 'question_text': 'What can readers understand, and infer in (Sentence 2)? which options BEST complete(s) The passage'}, {'correct_option': 3, 'options': ['the garden is beautiful.', 'I only want just for myself one room.', 'I want a big open area kitchen.', 'it will have space for family guests and pets.'], 'question_text': 'Based directly on (Sentence 3), What can be accurately completed to fill sentence 3?'}, {'correct_option': 0, 'options': ['colorful and bright', 'few small bonsai trees and grasses included', 'dark and moody colors with grey roses', 'boring and plain'], 'question_text': 'What detail could best accurately add, into, section (4) of the passage?'}], 'section': 4, 'section_name': 'Cloze Informational Comprehension'}, {'passage_text': \"My favorite food is pho. Pho is a delicious Vietnamese noodle soup. It's made with fragrant broth, rice noodles, and often includes beef, chicken, or tofu. The broth is usually simmered for hours to develop its full flavor. I love to eat pho at a small restaurant near my house because the food is fresh and they use their own family recipes!\", 'questions': [{'correct_option': 2, 'options': ['Noodles are never included in pho.', 'Pho is a sweet dessert only served after dinner.', 'A special homemade style of soup called pho is in the piece', 'It explains cooking is hard and never easy'], 'question_text': 'What is the main point of the reading?'}, {'correct_option': 1, 'options': ['It is typically eaten quickly.', 'It might include meat and/ or protein.', 'The rice ingredient is hard to deal with.', 'Rare meat can poison your internal system.'], 'question_text': 'What can be added to pho?'}, {'correct_option': 1, 'options': ['A large buffet offers a variety type.', 'The soup usually involves different tastes and preferences', 'People drink pho by shaking their cup.', 'Soup broth involves lots of different chemicals involved making a healthy meal.'], 'question_text': 'What can you discover in this story involving this typical Vietnamese food soup?'}, {'correct_option': 1, 'options': [\"The taste lacks uniqueness and it isn't healthy.\", \"There's family cooking involved in such style cooking at their small restaurant mentioned the details.\", 'Vietnamese food mostly comes cheap and never gets very spicy when asked.', 'This article details only healthy food around people love including beef'], 'question_text': 'Where is it usually tasted as mentioned here?'}, {'correct_option': 1, 'options': ['Pho contains few types of ingredients.', \"Pho's broth takes hours long simmers.\", 'It only offers tofu as an added item.', 'Pho comes extremely spicy all the times.'], 'question_text': 'What makes the recipe uniquely mentioned different here involving this special taste mentioned there described here?'}, {'correct_option': 3, 'options': [\"It's a delicious type of cake mostly coming from Germany originally\", 'There are numerous restaurants located there.', 'Rice plays significant role of an essential nutritious item.', 'Its rich broth contains various type ingredients.'], 'question_text': 'Other than the noodle is it involved with some other ingredients?'}, {'correct_option': 3, 'options': ['One cooks at anytime within 5 minutes in such case. (It takes long as one requires.)', 'Food is rarely simple and it looks appetizing that way. No description that this dish actually serves as main part.', 'Beef takes extremely a long time to simmer therefore one cannot even try such dish. That would look absolutely inedible. One simply wouldn’t know where to stop. It’s only just available there since a while as this text tells.', 'Preparation time needed more usually because this broth often simmered for hours involved developing involved here the overall full, the amazing flavorful taste.'], 'question_text': 'According to details which cooking does often involves several hours'}, {'correct_option': 1, 'options': ['The article details only healthy food', 'The recipe appears simple, delicious, easy way describe food style', 'They sometimes employ various styles making family types mentioned details.', 'Several recipes exists there involving same items involved which looks yummy in general, although that also depends sometimes actually'], 'question_text': 'What else also can explain the recipe well, the main point of overall passage?'}, {'correct_option': 1, 'options': ['The author dislikes pho despite many saying they love its food taste typically.', 'The passage describes is simple describing favorite food', 'Making home soup tastes disgusting without adding ingredients.', 'Pho can be rather difficult cook in reality mostly'], 'question_text': 'Which statement summarizes best passage overall regarding cooking main theme, or this important typical food?'}], 'section': 5, 'section_name': 'Reading Comprehension'}, {'passage_text': 'Sound waves are vibrations that travel through a medium, such as air, water, or solids. When an object vibrates, it pushes and pulls on the air particles surrounding it which push and pull on further particles in a wave-like chain. High and low sounds correspond to the vibration or frequency. When these vibrations travel to reach ears, ears work to hear how. The eardrum, the outermost part vibrates to transfer further to cause vibrations that lead towards brain perceiving sound signal. Music results from complex sound waves making hearing music a dynamic system to process. The unique blend of waves which generate sounds is very vital to produce varied and complex types.', 'questions': [{'correct_option': 2, 'options': ['Air can hear sound waves from a distant loudspeaker just as an individual hears with eardrum involvement exclusively.', 'A speaker creates pressure disturbances traveling throughout its surrounding via wave-like pulses.', 'Hearing mechanism occurs by transferring ear-related vibrato signals eventually brain interprets what’s interpreted. Only brain interprets in hearing event while it disregards other body organs.', 'The frequency of certain sound will vary from person each so musical concerts produce an identical level of frequencies amongst individual listeners within this type setting that musical types creates better or improved music'], 'question_text': 'How does the structure for music and hearing event proceed via wave theory with biological impact which eventually becomes involved on perceiving sound as it is? Which explanation best describes above idea of creating harmonious musical blending that eventually allows successful hearing?'}, {'correct_option': 1, 'options': ['Similar sounds in concert are heard differently across individuals. Thus meaning similar musical genres can change entirely depending which listening ear it’s involving overall across varied audiences based musical concert or song that produces better or improved music for any types created.', 'Increased pressure caused via speakers is a factor of a concert to create unique music blends.', 'Ear components that affect vibration such like brain, eardrums plays essential part when involving interpreting various frequencies, especially since frequencies eventually change in its final perception with varied experiences across those creating certain varied listeners to varied degree based created music that produces a result of overall hearing impact better improved better improved throughout creating type for example. It varies significantly across everyone.', 'All musical genres should focus exclusively on sound waves generated via speaker amplification or technology used. Only this impacts quality creating overall success within specific listener of a song, rather others outside affecting outcome at all. Sound quality is exclusive event only via technological enhancement or usage to involve hearing events only rather entirely. It is sole type outcome defining concert event.'], 'question_text': 'Considering the technology involvement concerts, how might technologies significantly improve overall sound outcome during concerts, such including creating blend unique music overall across experiences in how technologies contribute?'}, {'correct_option': 3, 'options': ['Water conducts some amounts sound but only better within water when only comparing certain limited mediums like solids, compared air specifically.', 'Each sense of frequencies produces significantly impacting brain as one frequency or musical type impacts hearing compared ones individually.', 'Waves within sounds determine sound level frequencies. Hence specific high frequencies determine how far spread a source transmits it over space.', 'Vibrated objects create displacement based frequency, impacting which eventually reach brains thus generating some resulting events across hearing and brain within concert musical event which results unique results per musical type.'], 'question_text': 'How high and low frequency sounds contribute differently across different listening in similar medium?'}, {'correct_option': 0, 'options': ['Vibrating frequencies directly control outcome involving both high and low across every types for listening, in any particular mediums.', 'Human physiology determines which brain is influenced thus entirely disregarding impacting overall via external factors.', 'Musical blending across specific genres heavily relying purely frequencies based entirely solely creating thus resulting better types concert involving entirely focusing mainly external musical frequencies outside other influencing events thus results different based solely musical type focused based only on particular event.', 'The interactions between frequencies, eardrums is not essential process necessary generate significant influence generating music rather entire aspects entirely rely external factors involving how certain music impacts overall to involve a final product better.'], 'question_text': 'Focusing solely how physics impact, without directly mentioning specific biology, how impacts high various sounds overall create unique soundscapes to produce impactful event across diverse concert experience in focusing uniquely?'}, {'correct_option': 1, 'options': ['The speed that it which travels depends types based impacting thus relying medium’s factor that medium’s physical features only uniquely depends entire final events based solely exclusively this factor entirely only based specific feature.', 'Sound wave transmission only possible throughout liquid environment to reach brains’ resulting successful events across only specific musical outcomes. Solid mediums block most if entirely of frequency impacts on concert within event impacting across several audiences, mostly significantly impairing sound event.', 'It purely relies based entirely technology such speakers used during event across musical experiences to generate impacting levels. There are several specific other factor entirely relies only technologies to help producing best sound experiences only impacting several other outcomes including across this only. Other technologies produces events rather mainly speakers determine quality event.', \"Every listeners brains determines how various frequencies in resulting several significant various concerts only specific audience impacting entirely listeners' minds therefore events various frequencies based solely audiences impact determines outcome entirely.\"], 'question_text': 'Which best explanation to describe involving how sound waves transmit through other types environments?'}, {'correct_option': 3, 'options': ['Higher loudness exclusively depends solely several loud devices to function effectively overall.', 'Sound waves travels through many other varied environments that impacts thus impacting overall thus it mostly likely uniquely varied overall solely frequency impact that impact entirely on event across concert experience during final event resulting uniquely creating most outcome better successful overall.', \"The technology of speakers uniquely involved concerts thus primarily generating music overall creates concert outcome better resulting thus event unique mainly uniquely based thus generating unique experience overall concert based speakers rather overall sound quality overall improved across experiences entirely. There are many speakers resulting uniquely event across speakers' impact overall uniquely. Mostly its frequencies impact to better result.\", 'Every person’s preferences involved uniquely only individual person involved. There are other events which impacted musical performances unique results but mainly relying individually therefore most unique person involved mainly determining impact resulting entirely events on it.'], 'question_text': 'What impact most regarding varied unique music resulting concert environments in explaining what generate high level improved unique listening experiences via impacting events and concert via various levels how?'}, {'correct_option': 0, 'options': ['Concert sounds blend across different locations or various halls are a mix both technology usage and listeners overall across various environment impacts generating unique various sounds impact.', 'External factors entirely determines impact overall since listeners mostly impacted greatly external factors impacting uniquely several audiences impacting therefore entire event determined by listeners uniquely across entirely mostly across individual experience. Most people create impacting across various others determining entire sound rather musical events. Many other impacting determining several unique individuals resulting impacting across variety individuals generating better events thus concerts experience most entirely impacted external environments', 'Purely technologies determine concert or entirely relies entirely events therefore most concerts depend quality unique improved events generating uniquely across technologies which determined result impacting unique varied type events across technology generated most impacting across technologies', 'High frequency result exclusively determine results exclusively impacted via how frequency determines rather mostly unique frequencies thus mostly frequencies impacts more entirely therefore mostly frequency entirely relying mainly only high quality events result in higher end sound across many technologies involved to producing thus concerts involve solely technologies and not influenced listener itself mostly across listeners mostly.'], 'question_text': 'What is the overall factors determined unique listening sound experience?'}, {'correct_option': 2, 'options': ['Brain alone responsible determine interpret events for sound signals determining impacting results and influencing creating better quality across concert events thus listeners entirely influenced purely entirely brains’ interpret creating different types outcomes for it entirely impacting thus generating most success results events.', 'Mostly external factors involve frequencies determines quality across all event involving therefore only relies exclusively on events or experiences and impacting concerts which created via influencing others’ experiencing soundscapes events mostly rely various various frequencies from generating sources thus sound mostly therefore entirely relying exclusively frequencies.', 'Frequency relates with impacting how vibrations occurs in impacting and translating based various eardrums and transferring towards brain for signal events therefore impacts are impacting how overall sound signals reach into specific audiences hence creating different levels and impacting specific overall unique events musical quality creating unique experiences.', 'Speakers overall generated frequencies in improving successful outcomes and technologies are essential aspect that overall concert events need entirely involving impacting therefore musical improving generating concerts need exclusively involve mainly improved higher end devices mainly to achieving successful high impact concerts to successful higher musical results quality producing a result mainly concerts.'], 'question_text': 'How is brain directly impacted when involving across multiple musical scenarios with brain impacts?'}, {'correct_option': 1, 'options': ['The environment with specific frequencies in overall only affects how impactful the end level listener across events impacts within various impacts on listeners mostly likely via external and purely impact environment only via it various overall listening events impact thus significantly impact listeners most significantly impactful most entirely.', 'How people interpret varies based which unique music blends with therefore creating different unique musical various events for mostly specific impact individuals creates better overall successful outcomes, across many events.', 'Human ears work independently via specific varied events for translating thus involving multiple others generating creating impacts in various multiple unique experiences based many various other unique impacting experiences that impact across each and impacting varies other varied environments creating impact other external affecting impacts across event via multiple events varies impacts.', 'Unique type event produces across specific events musical experience unique experiences vary various environments creates impacting therefore mainly overall environment itself created uniquely varying impacted therefore unique others creates affecting entire impacting others mainly based environments.'], 'question_text': \"How uniquely environments or different spaces vary impacts of concert thus impact across each concerts' quality, therefore generating higher level of unique concerts results?\"}], 'section': 6, 'section_name': 'Reading Comprehension Advanced'}]}], 'prompt': [], 'formatted_output': 'Section: Cloze Grammar Vocabulary\\nPassage:\\nHoneybees live in large groups called colonies. Each colony has one queen bee, who is responsible for ______ eggs. Worker bees collect nectar from flowers and make honey, while drone bees _____ mate with the queen. Bees use a special dance _____ each other about their sources of food.\\n\\nQuestions:\\n- 1. Choose the grammatically correct and contextually appropriate verb form for the blank in the first sentence.\\n  0. lays\\n  1. laying\\n  2. to lay\\n  3. laid\\n- 2. Select the word that best completes the meaning considering drone bees\\' roles in the colony.\\n  0. do\\n  1. to\\n  2. does\\n  3. doing\\n- 3. Pick the correct verb to properly connect the idea about using dance to inform insects.\\n  0. to communicate\\n  1. communication\\n  2. communicate\\n  3. communicating\\n- 4. Choose the word best suiting \\'_____ flowers are needed to create honey\\', from a colony that contains both the foragers from older bees and newer brood members which must sustain itself as an entity.\\n  0. some\\n  1. much\\n  2. more\\n  3. many\\n- 5. Choose words best describing the deliciousness concerning \\'Honey has a delightful ______\\'.\\n  0. sweetness\\n  1. sweet\\n  2. sweetly\\n  3. sweeter\\n- 6. Choose the appropriate preposition for the question: Bee\\'s nectar originates _____ various regions in the natural world considering various flower locations.\\n  0. on\\n  1. in\\n  2. at\\n  3. above\\n\\nSection: Cloze Contextual Vocabulary\\nPassage:\\nThe internet has changed our lives in many ways. We can now (1) ___ with people all over the world instantly. We buy things (2) ___ and we learn new things through (3) _____. We even have (4) ___ access to libraries. Reading and entertainment have evolved through this digital space. There are unlimited options to both explore new experiences (5)____and enhance leisure. It has, to significant advantage, replaced (6) _____ processes where things had to be in writing with electronic ways of going about our lives.\\n\\nQuestions:\\n- Choose options that best fits (1).\\n  0. communicate\\n  1. listen\\n  2. sing\\n  3. watch\\n- Choose the word that best fits (2).\\n  0. quickly\\n  1. slowly\\n  2. carefully\\n  3. rudely\\n- What suits best to fit (3)?\\n  0. letters\\n  1. meetings\\n  2. websites\\n  3. phones\\n- Select the most appropriate word for (4).\\n  0. difficult\\n  1. easy\\n  2. old fashioned\\n  3. expensive\\n- Choose a good connector that joins meanings of the 2 phrases after it, best fits in blank that (5) shows.\\n  0. and\\n  1. yet\\n  2. so\\n  3. but\\n- \"(?) traditional processes\", it correctly describes such traditional processes that should be completed physically. Which fits perfectly among option, hence replacing this(?) should best explain correctly.\\n  0. new\\n  1. modern\\n  2. traditional\\n  3. old\\n\\nSection: Best Arrangement of Utterances\\nQuestions:\\n- Organize the next statements related to Moon\\'s friends in a logical narration order from the story to tell an exciting joyful story of friendly friendship.\\n  0. The fox turned into a rabbit with beautiful white fur.\\n  1. However, other heavenly creatures thought no; she stayed in home that made everyone laugh. They\\'re all excited about the nice warm moment, and everyone around becomes happy.\\n  2. A kind fox and other stars appeared happily.\\n  3. Once upon a time, near that little magical house they played and made them stay happily forever. Even made all that they celebrated and had wonderful gifts! This means she gets new job!\\n- Put the sentences in order to show a celebration of the moon.\\n  0. She looked at clouds above seeing everything. And she became the happy one.\\n  1. This meant we celebrate Mid.\\n  2. It was a Full Harvest moon.\\n  3. They had a big party that autumn day.\\n- Rearrange these sentences to create a short story about the Moon becoming brighter:\\n  0. The old woman and the kids did enjoy it.\\n  1. The girl saw it in Moon. Then She was grateful.\\n  2. It brightened as he wished happiness upon several kids who felt thankful upon it and her friends helped her friends.\\n  3. One night before Halloween her parents enjoyed having fun eating meals.\\n- Arrange the following sentences to make a meaningful story about the Moon:\\n  0. Once upon a time, there was a beautiful girl who lived on Earth. Then came this big scary fox. The girl lived as happily as before.\\n  1. Once upon a time, there was a girl who climbed Heaven, saw all, and became the Moon.\\n  2. There was no moon as beautiful moon that bright.\\n  3. The rabbit on sky loved it even more.\\n- Select the most logically sequenced dialogue concerning discussion about the uniqueness of Vietnamese Fine Artwork particularly Lacquerware or artistic styles made specifically?\\n  0. A. I find many ancient artefacts such as bronzes have spiritual depth and great meaning. B. That unique approach is definitely attractive, isn\\'t it? It\\'s quite a rare beauty among others.. C. Bronze represents a cultural symbol for Vietnamese artistic evolution\\n  1. A.You could visit Hoi An to admire more exquisite stone and lacquer items? B.Yes sure indeed C. That sounds interesting. What about pottery and ceramic, any suggestions?, . , D. There are very abundant resources within areas displaying lots those special type products \". . E. Very valuable resources , F. That helps to conserve beauty and national identities .G. Are those local hand crafting, H. Such great conservation!\\n  2. Actually, this contemporary art I am viewing seems quite symbolic! Its spiritual. B. Oh Really! . How many years It lasted in making? ?. That incredible isn\\'t. B. Many techniques combined. Are we currently witnessing those materials What does mean for creating?, C. Most amazing technique!\\n  3. A. Well let me see There are more than two different layers. B. Those special process indeed C. But quite tedious work. Lots time effort And needs so great attention Is there certain style or technique used to depict culture of local community ? .. . . D. Yeah really lots great detailed Lots small work requires attention .. . E. These art are great resources to conserve cultures deeply to promote and preserving identity F. Such a marvelous techniques involved. .Very amazing!\\n\\nSection: Cloze Informational Comprehension\\nPassage:\\nMy dream house is a cozy cottage near the beach. It’s small, but comfortable. _____________(1) The walls are painted a calming blue, and the roof is made of orange tiles. Inside, _________(2) It will have a large kitchen because I love to cook and ________(3) There’s going to be two rooms including an artistic looking bathroom, and the big window that I need. A garden full of __________ flowers and my cozy house looks like they’re belonging to another dreamy realm!\\n\\nQuestions:\\n- From the text, which among option (0).(1),.2),(3,) sentences sound correctly described the overall described mood and style based on the description presented in the writing\\n  0. It suggests a peaceful and natural feel.\\n  1. It has a very spacious design, to feel more calm\\n  2. The environment sounds too modern thus not relevant.\\n  3. It appears as to not fit very accurately into the context given earlier\\n- Which of these BEST describes what can be read in section 1 of the passage?\\n  0. It needs a small garden.\\n  1. It has big windows and lots of natural light.\\n  2. Its garden is small and simple.\\n  3. The walls are brown and ugly\\n- What can readers understand, and infer in (Sentence 2)? which options BEST complete(s) The passage\\n  0. there will many rooms.\\n  1. there will lots of small tables next to the kitchen island .\\n  2. the house needs fixing.\\n  3. it has many relaxing attributes\\n- Based directly on (Sentence 3), What can be accurately completed to fill sentence 3?\\n  0. the garden is beautiful.\\n  1. I only want just for myself one room.\\n  2. I want a big open area kitchen.\\n  3. it will have space for family guests and pets.\\n- What detail could best accurately add, into, section (4) of the passage?\\n  0. colorful and bright\\n  1. few small bonsai trees and grasses included\\n  2. dark and moody colors with grey roses\\n  3. boring and plain\\n\\nSection: Reading Comprehension\\nPassage:\\nMy favorite food is pho. Pho is a delicious Vietnamese noodle soup. It\\'s made with fragrant broth, rice noodles, and often includes beef, chicken, or tofu. The broth is usually simmered for hours to develop its full flavor. I love to eat pho at a small restaurant near my house because the food is fresh and they use their own family recipes!\\n\\nQuestions:\\n- What is the main point of the reading?\\n  0. Noodles are never included in pho.\\n  1. Pho is a sweet dessert only served after dinner.\\n  2. A special homemade style of soup called pho is in the piece\\n  3. It explains cooking is hard and never easy\\n- What can be added to pho?\\n  0. It is typically eaten quickly.\\n  1. It might include meat and/ or protein.\\n  2. The rice ingredient is hard to deal with.\\n  3. Rare meat can poison your internal system.\\n- What can you discover in this story involving this typical Vietnamese food soup?\\n  0. A large buffet offers a variety type.\\n  1. The soup usually involves different tastes and preferences\\n  2. People drink pho by shaking their cup.\\n  3. Soup broth involves lots of different chemicals involved making a healthy meal.\\n- Where is it usually tasted as mentioned here?\\n  0. The taste lacks uniqueness and it isn\\'t healthy.\\n  1. There\\'s family cooking involved in such style cooking at their small restaurant mentioned the details.\\n  2. Vietnamese food mostly comes cheap and never gets very spicy when asked.\\n  3. This article details only healthy food around people love including beef\\n- What makes the recipe uniquely mentioned different here involving this special taste mentioned there described here?\\n  0. Pho contains few types of ingredients.\\n  1. Pho\\'s broth takes hours long simmers.\\n  2. It only offers tofu as an added item.\\n  3. Pho comes extremely spicy all the times.\\n- Other than the noodle is it involved with some other ingredients?\\n  0. It\\'s a delicious type of cake mostly coming from Germany originally\\n  1. There are numerous restaurants located there.\\n  2. Rice plays significant role of an essential nutritious item.\\n  3. Its rich broth contains various type ingredients.\\n- According to details which cooking does often involves several hours\\n  0. One cooks at anytime within 5 minutes in such case. (It takes long as one requires.)\\n  1. Food is rarely simple and it looks appetizing that way. No description that this dish actually serves as main part.\\n  2. Beef takes extremely a long time to simmer therefore one cannot even try such dish. That would look absolutely inedible. One simply wouldn’t know where to stop. It’s only just available there since a while as this text tells.\\n  3. Preparation time needed more usually because this broth often simmered for hours involved developing involved here the overall full, the amazing flavorful taste.\\n- What else also can explain the recipe well, the main point of overall passage?\\n  0. The article details only healthy food\\n  1. The recipe appears simple, delicious, easy way describe food style\\n  2. They sometimes employ various styles making family types mentioned details.\\n  3. Several recipes exists there involving same items involved which looks yummy in general, although that also depends sometimes actually\\n- Which statement summarizes best passage overall regarding cooking main theme, or this important typical food?\\n  0. The author dislikes pho despite many saying they love its food taste typically.\\n  1. The passage describes is simple describing favorite food\\n  2. Making home soup tastes disgusting without adding ingredients.\\n  3. Pho can be rather difficult cook in reality mostly\\n\\nSection: Reading Comprehension Advanced\\nPassage:\\nSound waves are vibrations that travel through a medium, such as air, water, or solids. When an object vibrates, it pushes and pulls on the air particles surrounding it which push and pull on further particles in a wave-like chain. High and low sounds correspond to the vibration or frequency. When these vibrations travel to reach ears, ears work to hear how. The eardrum, the outermost part vibrates to transfer further to cause vibrations that lead towards brain perceiving sound signal. Music results from complex sound waves making hearing music a dynamic system to process. The unique blend of waves which generate sounds is very vital to produce varied and complex types.\\n\\nQuestions:\\n- How does the structure for music and hearing event proceed via wave theory with biological impact which eventually becomes involved on perceiving sound as it is? Which explanation best describes above idea of creating harmonious musical blending that eventually allows successful hearing?\\n  0. Air can hear sound waves from a distant loudspeaker just as an individual hears with eardrum involvement exclusively.\\n  1. A speaker creates pressure disturbances traveling throughout its surrounding via wave-like pulses.\\n  2. Hearing mechanism occurs by transferring ear-related vibrato signals eventually brain interprets what’s interpreted. Only brain interprets in hearing event while it disregards other body organs.\\n  3. The frequency of certain sound will vary from person each so musical concerts produce an identical level of frequencies amongst individual listeners within this type setting that musical types creates better or improved music\\n- Considering the technology involvement concerts, how might technologies significantly improve overall sound outcome during concerts, such including creating blend unique music overall across experiences in how technologies contribute?\\n  0. Similar sounds in concert are heard differently across individuals. Thus meaning similar musical genres can change entirely depending which listening ear it’s involving overall across varied audiences based musical concert or song that produces better or improved music for any types created.\\n  1. Increased pressure caused via speakers is a factor of a concert to create unique music blends.\\n  2. Ear components that affect vibration such like brain, eardrums plays essential part when involving interpreting various frequencies, especially since frequencies eventually change in its final perception with varied experiences across those creating certain varied listeners to varied degree based created music that produces a result of overall hearing impact better improved better improved throughout creating type for example. It varies significantly across everyone.\\n  3. All musical genres should focus exclusively on sound waves generated via speaker amplification or technology used. Only this impacts quality creating overall success within specific listener of a song, rather others outside affecting outcome at all. Sound quality is exclusive event only via technological enhancement or usage to involve hearing events only rather entirely. It is sole type outcome defining concert event.\\n- How high and low frequency sounds contribute differently across different listening in similar medium?\\n  0. Water conducts some amounts sound but only better within water when only comparing certain limited mediums like solids, compared air specifically.\\n  1. Each sense of frequencies produces significantly impacting brain as one frequency or musical type impacts hearing compared ones individually.\\n  2. Waves within sounds determine sound level frequencies. Hence specific high frequencies determine how far spread a source transmits it over space.\\n  3. Vibrated objects create displacement based frequency, impacting which eventually reach brains thus generating some resulting events across hearing and brain within concert musical event which results unique results per musical type.\\n- Focusing solely how physics impact, without directly mentioning specific biology, how impacts high various sounds overall create unique soundscapes to produce impactful event across diverse concert experience in focusing uniquely?\\n  0. Vibrating frequencies directly control outcome involving both high and low across every types for listening, in any particular mediums.\\n  1. Human physiology determines which brain is influenced thus entirely disregarding impacting overall via external factors.\\n  2. Musical blending across specific genres heavily relying purely frequencies based entirely solely creating thus resulting better types concert involving entirely focusing mainly external musical frequencies outside other influencing events thus results different based solely musical type focused based only on particular event.\\n  3. The interactions between frequencies, eardrums is not essential process necessary generate significant influence generating music rather entire aspects entirely rely external factors involving how certain music impacts overall to involve a final product better.\\n- Which best explanation to describe involving how sound waves transmit through other types environments?\\n  0. The speed that it which travels depends types based impacting thus relying medium’s factor that medium’s physical features only uniquely depends entire final events based solely exclusively this factor entirely only based specific feature.\\n  1. Sound wave transmission only possible throughout liquid environment to reach brains’ resulting successful events across only specific musical outcomes. Solid mediums block most if entirely of frequency impacts on concert within event impacting across several audiences, mostly significantly impairing sound event.\\n  2. It purely relies based entirely technology such speakers used during event across musical experiences to generate impacting levels. There are several specific other factor entirely relies only technologies to help producing best sound experiences only impacting several other outcomes including across this only. Other technologies produces events rather mainly speakers determine quality event.\\n  3. Every listeners brains determines how various frequencies in resulting several significant various concerts only specific audience impacting entirely listeners\\' minds therefore events various frequencies based solely audiences impact determines outcome entirely.\\n- What impact most regarding varied unique music resulting concert environments in explaining what generate high level improved unique listening experiences via impacting events and concert via various levels how?\\n  0. Higher loudness exclusively depends solely several loud devices to function effectively overall.\\n  1. Sound waves travels through many other varied environments that impacts thus impacting overall thus it mostly likely uniquely varied overall solely frequency impact that impact entirely on event across concert experience during final event resulting uniquely creating most outcome better successful overall.\\n  2. The technology of speakers uniquely involved concerts thus primarily generating music overall creates concert outcome better resulting thus event unique mainly uniquely based thus generating unique experience overall concert based speakers rather overall sound quality overall improved across experiences entirely. There are many speakers resulting uniquely event across speakers\\' impact overall uniquely. Mostly its frequencies impact to better result.\\n  3. Every person’s preferences involved uniquely only individual person involved. There are other events which impacted musical performances unique results but mainly relying individually therefore most unique person involved mainly determining impact resulting entirely events on it.\\n- What is the overall factors determined unique listening sound experience?\\n  0. Concert sounds blend across different locations or various halls are a mix both technology usage and listeners overall across various environment impacts generating unique various sounds impact.\\n  1. External factors entirely determines impact overall since listeners mostly impacted greatly external factors impacting uniquely several audiences impacting therefore entire event determined by listeners uniquely across entirely mostly across individual experience. Most people create impacting across various others determining entire sound rather musical events. Many other impacting determining several unique individuals resulting impacting across variety individuals generating better events thus concerts experience most entirely impacted external environments\\n  2. Purely technologies determine concert or entirely relies entirely events therefore most concerts depend quality unique improved events generating uniquely across technologies which determined result impacting unique varied type events across technology generated most impacting across technologies\\n  3. High frequency result exclusively determine results exclusively impacted via how frequency determines rather mostly unique frequencies thus mostly frequencies impacts more entirely therefore mostly frequency entirely relying mainly only high quality events result in higher end sound across many technologies involved to producing thus concerts involve solely technologies and not influenced listener itself mostly across listeners mostly.\\n- How is brain directly impacted when involving across multiple musical scenarios with brain impacts?\\n  0. Brain alone responsible determine interpret events for sound signals determining impacting results and influencing creating better quality across concert events thus listeners entirely influenced purely entirely brains’ interpret creating different types outcomes for it entirely impacting thus generating most success results events.\\n  1. Mostly external factors involve frequencies determines quality across all event involving therefore only relies exclusively on events or experiences and impacting concerts which created via influencing others’ experiencing soundscapes events mostly rely various various frequencies from generating sources thus sound mostly therefore entirely relying exclusively frequencies.\\n  2. Frequency relates with impacting how vibrations occurs in impacting and translating based various eardrums and transferring towards brain for signal events therefore impacts are impacting how overall sound signals reach into specific audiences hence creating different levels and impacting specific overall unique events musical quality creating unique experiences.\\n  3. Speakers overall generated frequencies in improving successful outcomes and technologies are essential aspect that overall concert events need entirely involving impacting therefore musical improving generating concerts need exclusively involve mainly improved higher end devices mainly to achieving successful high impact concerts to successful higher musical results quality producing a result mainly concerts.\\n- How uniquely environments or different spaces vary impacts of concert thus impact across each concerts\\' quality, therefore generating higher level of unique concerts results?\\n  0. The environment with specific frequencies in overall only affects how impactful the end level listener across events impacts within various impacts on listeners mostly likely via external and purely impact environment only via it various overall listening events impact thus significantly impact listeners most significantly impactful most entirely.\\n  1. How people interpret varies based which unique music blends with therefore creating different unique musical various events for mostly specific impact individuals creates better overall successful outcomes, across many events.\\n  2. Human ears work independently via specific varied events for translating thus involving multiple others generating creating impacts in various multiple unique experiences based many various other unique impacting experiences that impact across each and impacting varies other varied environments creating impact other external affecting impacts across event via multiple events varies impacts.\\n  3. Unique type event produces across specific events musical experience unique experiences vary various environments creates impacting therefore mainly overall environment itself created uniquely varying impacted therefore unique others creates affecting entire impacting others mainly based environments.\\n'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability and move the model accordingly\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to_empty(device=device)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset['train'],\n",
        "    dataset_text_field=\"formatted_output\",\n",
        "    max_seq_length=6144,\n",
        "    dataset_num_proc=4,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=4,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=5,\n",
        "        warmup_steps=50,\n",
        "        learning_rate=1e-4,\n",
        "        fp16=True,\n",
        "        bf16=False,\n",
        "        logging_steps=50,\n",
        "        save_steps=10,\n",
        "        save_total_limit=2,\n",
        "        optim=\"adamw_torch\",\n",
        "        weight_decay=0.01,\n",
        "        output_dir=\"outputs\",\n",
        "        seed=3407,\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")\n"
      ],
      "metadata": {
        "id": "Zfd9JcaZFU-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "xznHUCzPFZ0r",
        "outputId": "0a0d4657-b5ac-46a8-b3b4-af1534bacf72",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 176 | Num Epochs = 5\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 16 | Total steps = 55\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='55' max='55' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [55/55 20:35, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>10.397200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=55, training_loss=10.397210415926846, metrics={'train_runtime': 1262.3054, 'train_samples_per_second': 0.697, 'train_steps_per_second': 0.044, 'total_flos': 2.1405627007382323e+17, 'train_loss': 10.397210415926846, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.save_pretrained(\"mistral_7B_instruct\")\n",
        "# tokenizer.save_pretrained(\"mistral_7B_instruct\")"
      ],
      "metadata": {
        "id": "7kyLL39UBRBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_gguf( new_model, tokenizer, quantization_method=\"f16\")"
      ],
      "metadata": {
        "id": "Qf1SLQiuCerA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf1d39c-2a27-46cb-ce82-fbffda02fddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 14.5G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 60.78 out of 83.48 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 62.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting mistral model. Can use fast conversion = True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['f16'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
            "Unsloth: [1] Converting model at testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m into f16 GGUF format.\n",
            "The output location will be /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 32768}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 32768}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 32768\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 2\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 2\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {%- if messages[0][\"role\"] == \"system\" %}\n",
            "    {%- set system_message = messages[0][\"content\"] %}\n",
            "    {%- set loop_messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set loop_messages = messages %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}\n",
            "\n",
            "{#- This block checks for alternating user/assistant messages, skipping tool calling messages #}\n",
            "{%- set ns = namespace() %}\n",
            "{%- set ns.index = 0 %}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if not (message.role == \"tool\" or message.role == \"tool_results\" or (message.tool_calls is defined and message.tool_calls is not none)) %}\n",
            "        {%- if (message[\"role\"] == \"user\") != (ns.index % 2 == 0) %}\n",
            "            {{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
            "        {%- endif %}\n",
            "        {%- set ns.index = ns.index + 1 %}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "{{- bos_token }}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if message[\"role\"] == \"user\" %}\n",
            "        {%- if tools is not none and (message == user_messages[-1]) %}\n",
            "            {{- \"[AVAILABLE_TOOLS] [\" }}\n",
            "            {%- for tool in tools %}\n",
            "                {%- set tool = tool.function %}\n",
            "                {{- '{\"type\": \"function\", \"function\": {' }}\n",
            "                {%- for key, val in tool.items() if key != \"return\" %}\n",
            "                    {%- if val is string %}\n",
            "                        {{- '\"' + key + '\": \"' + val + '\"' }}\n",
            "                    {%- else %}\n",
            "                        {{- '\"' + key + '\": ' + val|tojson }}\n",
            "                    {%- endif %}\n",
            "                    {%- if not loop.last %}\n",
            "                        {{- \", \" }}\n",
            "                    {%- endif %}\n",
            "                {%- endfor %}\n",
            "                {{- \"}}\" }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- else %}\n",
            "                    {{- \"]\" }}\n",
            "                {%- endif %}\n",
            "            {%- endfor %}\n",
            "            {{- \"[/AVAILABLE_TOOLS]\" }}\n",
            "            {%- endif %}\n",
            "        {%- if loop.last and system_message is defined %}\n",
            "            {{- \"[INST] \" + system_message + \"\\n\\n\" + message[\"content\"] + \"[/INST]\" }}\n",
            "        {%- else %}\n",
            "            {{- \"[INST] \" + message[\"content\"] + \"[/INST]\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.tool_calls is defined and message.tool_calls is not none %}\n",
            "        {{- \"[TOOL_CALLS] [\" }}\n",
            "        {%- for tool_call in message.tool_calls %}\n",
            "            {%- set out = tool_call.function|tojson %}\n",
            "            {{- out[:-1] }}\n",
            "            {%- if not tool_call.id is defined or tool_call.id|length != 9 %}\n",
            "                {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
            "            {%- endif %}\n",
            "            {{- ', \"id\": \"' + tool_call.id + '\"}' }}\n",
            "            {%- if not loop.last %}\n",
            "                {{- \", \" }}\n",
            "            {%- else %}\n",
            "                {{- \"]\" + eos_token }}\n",
            "            {%- endif %}\n",
            "        {%- endfor %}\n",
            "    {%- elif message[\"role\"] == \"assistant\" %}\n",
            "        {{- \" \" + message[\"content\"]|trim + eos_token}}\n",
            "    {%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}\n",
            "        {%- if message.content is defined and message.content.content is defined %}\n",
            "            {%- set content = message.content.content %}\n",
            "        {%- else %}\n",
            "            {%- set content = message.content %}\n",
            "        {%- endif %}\n",
            "        {{- '[TOOL_RESULTS] {\"content\": ' + content|string + \", \" }}\n",
            "        {%- if not message.tool_call_id is defined or message.tool_call_id|length != 9 %}\n",
            "            {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
            "        {%- endif %}\n",
            "        {{- '\"call_id\": \"' + message.tool_call_id + '\"}[/TOOL_RESULTS]' }}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf: n_tensors = 291, total_size = 14.5G\n",
            "Writing: 100%|██████████| 14.5G/14.5G [00:45<00:00, 321Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained_gguf( new_model, tokenizer, quantization_method=\"q4_k_m\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxhDYj9fe_Mt",
        "outputId": "ae2462a7-58fd-4a1e-8739-99c5198f8214",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 61.14 out of 83.48 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 72.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: [1] Converting model at testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m into f16 GGUF format.\n",
            "The output location will be /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 32768}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 32768}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 32768\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 2\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 2\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {%- if messages[0][\"role\"] == \"system\" %}\n",
            "    {%- set system_message = messages[0][\"content\"] %}\n",
            "    {%- set loop_messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set loop_messages = messages %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}\n",
            "\n",
            "{#- This block checks for alternating user/assistant messages, skipping tool calling messages #}\n",
            "{%- set ns = namespace() %}\n",
            "{%- set ns.index = 0 %}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if not (message.role == \"tool\" or message.role == \"tool_results\" or (message.tool_calls is defined and message.tool_calls is not none)) %}\n",
            "        {%- if (message[\"role\"] == \"user\") != (ns.index % 2 == 0) %}\n",
            "            {{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
            "        {%- endif %}\n",
            "        {%- set ns.index = ns.index + 1 %}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "{{- bos_token }}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if message[\"role\"] == \"user\" %}\n",
            "        {%- if tools is not none and (message == user_messages[-1]) %}\n",
            "            {{- \"[AVAILABLE_TOOLS] [\" }}\n",
            "            {%- for tool in tools %}\n",
            "                {%- set tool = tool.function %}\n",
            "                {{- '{\"type\": \"function\", \"function\": {' }}\n",
            "                {%- for key, val in tool.items() if key != \"return\" %}\n",
            "                    {%- if val is string %}\n",
            "                        {{- '\"' + key + '\": \"' + val + '\"' }}\n",
            "                    {%- else %}\n",
            "                        {{- '\"' + key + '\": ' + val|tojson }}\n",
            "                    {%- endif %}\n",
            "                    {%- if not loop.last %}\n",
            "                        {{- \", \" }}\n",
            "                    {%- endif %}\n",
            "                {%- endfor %}\n",
            "                {{- \"}}\" }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- else %}\n",
            "                    {{- \"]\" }}\n",
            "                {%- endif %}\n",
            "            {%- endfor %}\n",
            "            {{- \"[/AVAILABLE_TOOLS]\" }}\n",
            "            {%- endif %}\n",
            "        {%- if loop.last and system_message is defined %}\n",
            "            {{- \"[INST] \" + system_message + \"\\n\\n\" + message[\"content\"] + \"[/INST]\" }}\n",
            "        {%- else %}\n",
            "            {{- \"[INST] \" + message[\"content\"] + \"[/INST]\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.tool_calls is defined and message.tool_calls is not none %}\n",
            "        {{- \"[TOOL_CALLS] [\" }}\n",
            "        {%- for tool_call in message.tool_calls %}\n",
            "            {%- set out = tool_call.function|tojson %}\n",
            "            {{- out[:-1] }}\n",
            "            {%- if not tool_call.id is defined or tool_call.id|length != 9 %}\n",
            "                {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
            "            {%- endif %}\n",
            "            {{- ', \"id\": \"' + tool_call.id + '\"}' }}\n",
            "            {%- if not loop.last %}\n",
            "                {{- \", \" }}\n",
            "            {%- else %}\n",
            "                {{- \"]\" + eos_token }}\n",
            "            {%- endif %}\n",
            "        {%- endfor %}\n",
            "    {%- elif message[\"role\"] == \"assistant\" %}\n",
            "        {{- \" \" + message[\"content\"]|trim + eos_token}}\n",
            "    {%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}\n",
            "        {%- if message.content is defined and message.content.content is defined %}\n",
            "            {%- set content = message.content.content %}\n",
            "        {%- else %}\n",
            "            {%- set content = message.content %}\n",
            "        {%- endif %}\n",
            "        {{- '[TOOL_RESULTS] {\"content\": ' + content|string + \", \" }}\n",
            "        {%- if not message.tool_call_id is defined or message.tool_call_id|length != 9 %}\n",
            "            {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
            "        {%- endif %}\n",
            "        {{- '\"call_id\": \"' + message.tool_call_id + '\"}[/TOOL_RESULTS]' }}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf: n_tensors = 291, total_size = 14.5G\n",
            "Writing: 100%|██████████| 14.5G/14.5G [00:44<00:00, 324Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 4806 (c43af927)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf' to '/content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 35 key-value pairs and 291 tensors from /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Mistral 7b Instruct v0.3\n",
            "llama_model_loader: - kv   3:                            general.version str              = v0.3\n",
            "llama_model_loader: - kv   4:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   5:                           general.finetune str              = instruct\n",
            "llama_model_loader: - kv   6:                           general.basename str              = mistral\n",
            "llama_model_loader: - kv   7:                         general.size_label str              = 7B\n",
            "llama_model_loader: - kv   8:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   9:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  11:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  12:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  13:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  14:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  15:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  16:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  17:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  18:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  19:                           llama.vocab_size u32              = 32768\n",
            "llama_model_loader: - kv  20:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.scores arr[f32,32768]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,32768]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 2\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  31:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  32:                    tokenizer.chat_template str              = {%- if messages[0][\"role\"] == \"system...\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.add_space_prefix bool             = true\n",
            "llama_model_loader: - kv  34:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 4096, 32768,     1,     1], type =    f16, converting to q6_K .. size =   256.00 MiB ->   105.00 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 4096, 32768,     1,     1], type =    f16, converting to q4_K .. size =   256.00 MiB ->    72.00 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "llama_model_quantize_impl: model size  = 13825.02 MB\n",
            "llama_model_quantize_impl: quant size  =  4169.52 MB\n",
            "\n",
            "main: quantize time = 158951.07 ms\n",
            "main:    total time = 158951.07 ms\n",
            "Unsloth: Conversion completed! Output location: /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.Q4_K_M.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub_gguf(new_model, token=hf_token, tokenizer = tokenizer, quantization_method = \"q4_k_m\")"
      ],
      "metadata": {
        "id": "tTBPp3Byyfev",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "32a3956c5fc14a04ae8ab7a8d1717e15",
            "dd573ad96f0b463c8901fe9062ba2fb8",
            "0d654113e14248c9ad20ebd877fced6b",
            "e0a0996fb9044069b46536b64705245e",
            "f1153fae60744e679dc407938cb37a0d",
            "02dd604a804d4b50a91f552534883349",
            "5e24c19eaefe4ddf8a5abcb6bbb3bdf1",
            "64bdfc6b2eae42a6b5af341693a38a16",
            "3fd0ef1558d74872935aa32860cf1198",
            "c8a125fdf48f40668c0a94a18ea8bced",
            "16d5fb05ea4141e48533c1e9faf17e3a"
          ]
        },
        "outputId": "993dc54b-53c0-447e-d927-ed0ee58b0ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 61.25 out of 83.48 RAM for saving.\n",
            "Unsloth: Saving model... This might take 5 minutes ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 32/32 [00:00<00:00, 70.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Done.\n",
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
            "Unsloth: [1] Converting model at testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m into f16 GGUF format.\n",
            "The output location will be /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "This might take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 32768}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00003.safetensors'\n",
            "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 32768}\n",
            "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
            "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
            "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
            "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 32768\n",
            "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Setting special token type bos to 1\n",
            "INFO:gguf.vocab:Setting special token type eos to 2\n",
            "INFO:gguf.vocab:Setting special token type unk to 0\n",
            "INFO:gguf.vocab:Setting special token type pad to 2\n",
            "INFO:gguf.vocab:Setting add_bos_token to True\n",
            "INFO:gguf.vocab:Setting add_eos_token to False\n",
            "INFO:gguf.vocab:Setting chat_template to {%- if messages[0][\"role\"] == \"system\" %}\n",
            "    {%- set system_message = messages[0][\"content\"] %}\n",
            "    {%- set loop_messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set loop_messages = messages %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "{%- set user_messages = loop_messages | selectattr(\"role\", \"equalto\", \"user\") | list %}\n",
            "\n",
            "{#- This block checks for alternating user/assistant messages, skipping tool calling messages #}\n",
            "{%- set ns = namespace() %}\n",
            "{%- set ns.index = 0 %}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if not (message.role == \"tool\" or message.role == \"tool_results\" or (message.tool_calls is defined and message.tool_calls is not none)) %}\n",
            "        {%- if (message[\"role\"] == \"user\") != (ns.index % 2 == 0) %}\n",
            "            {{- raise_exception(\"After the optional system message, conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
            "        {%- endif %}\n",
            "        {%- set ns.index = ns.index + 1 %}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "{{- bos_token }}\n",
            "{%- for message in loop_messages %}\n",
            "    {%- if message[\"role\"] == \"user\" %}\n",
            "        {%- if tools is not none and (message == user_messages[-1]) %}\n",
            "            {{- \"[AVAILABLE_TOOLS] [\" }}\n",
            "            {%- for tool in tools %}\n",
            "                {%- set tool = tool.function %}\n",
            "                {{- '{\"type\": \"function\", \"function\": {' }}\n",
            "                {%- for key, val in tool.items() if key != \"return\" %}\n",
            "                    {%- if val is string %}\n",
            "                        {{- '\"' + key + '\": \"' + val + '\"' }}\n",
            "                    {%- else %}\n",
            "                        {{- '\"' + key + '\": ' + val|tojson }}\n",
            "                    {%- endif %}\n",
            "                    {%- if not loop.last %}\n",
            "                        {{- \", \" }}\n",
            "                    {%- endif %}\n",
            "                {%- endfor %}\n",
            "                {{- \"}}\" }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- else %}\n",
            "                    {{- \"]\" }}\n",
            "                {%- endif %}\n",
            "            {%- endfor %}\n",
            "            {{- \"[/AVAILABLE_TOOLS]\" }}\n",
            "            {%- endif %}\n",
            "        {%- if loop.last and system_message is defined %}\n",
            "            {{- \"[INST] \" + system_message + \"\\n\\n\" + message[\"content\"] + \"[/INST]\" }}\n",
            "        {%- else %}\n",
            "            {{- \"[INST] \" + message[\"content\"] + \"[/INST]\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.tool_calls is defined and message.tool_calls is not none %}\n",
            "        {{- \"[TOOL_CALLS] [\" }}\n",
            "        {%- for tool_call in message.tool_calls %}\n",
            "            {%- set out = tool_call.function|tojson %}\n",
            "            {{- out[:-1] }}\n",
            "            {%- if not tool_call.id is defined or tool_call.id|length != 9 %}\n",
            "                {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
            "            {%- endif %}\n",
            "            {{- ', \"id\": \"' + tool_call.id + '\"}' }}\n",
            "            {%- if not loop.last %}\n",
            "                {{- \", \" }}\n",
            "            {%- else %}\n",
            "                {{- \"]\" + eos_token }}\n",
            "            {%- endif %}\n",
            "        {%- endfor %}\n",
            "    {%- elif message[\"role\"] == \"assistant\" %}\n",
            "        {{- \" \" + message[\"content\"]|trim + eos_token}}\n",
            "    {%- elif message[\"role\"] == \"tool_results\" or message[\"role\"] == \"tool\" %}\n",
            "        {%- if message.content is defined and message.content.content is defined %}\n",
            "            {%- set content = message.content.content %}\n",
            "        {%- else %}\n",
            "            {%- set content = message.content %}\n",
            "        {%- endif %}\n",
            "        {{- '[TOOL_RESULTS] {\"content\": ' + content|string + \", \" }}\n",
            "        {%- if not message.tool_call_id is defined or message.tool_call_id|length != 9 %}\n",
            "            {{- raise_exception(\"Tool call IDs should be alphanumeric strings with length 9!\") }}\n",
            "        {%- endif %}\n",
            "        {{- '\"call_id\": \"' + message.tool_call_id + '\"}[/TOOL_RESULTS]' }}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Only user and assistant roles are supported, with the exception of an initial optional system message!\") }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf: n_tensors = 291, total_size = 14.5G\n",
            "Writing: 100%|██████████| 14.5G/14.5G [00:42<00:00, 343Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
            "main: build = 4806 (c43af927)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf' to '/content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
            "llama_model_loader: loaded meta data with 35 key-value pairs and 291 tensors from /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Mistral 7b Instruct v0.3\n",
            "llama_model_loader: - kv   3:                            general.version str              = v0.3\n",
            "llama_model_loader: - kv   4:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   5:                           general.finetune str              = instruct\n",
            "llama_model_loader: - kv   6:                           general.basename str              = mistral\n",
            "llama_model_loader: - kv   7:                         general.size_label str              = 7B\n",
            "llama_model_loader: - kv   8:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   9:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  11:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  12:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  13:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  14:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  15:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  16:                 llama.attention.key_length u32              = 128\n",
            "llama_model_loader: - kv  17:               llama.attention.value_length u32              = 128\n",
            "llama_model_loader: - kv  18:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  19:                           llama.vocab_size u32              = 32768\n",
            "llama_model_loader: - kv  20:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = default\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,32768]   = [\"<unk>\", \"<s>\", \"</s>\", \"[INST]\", \"[...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.scores arr[f32,32768]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,32768]   = [3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, ...\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  28:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  29:            tokenizer.ggml.padding_token_id u32              = 2\n",
            "llama_model_loader: - kv  30:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  31:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  32:                    tokenizer.chat_template str              = {%- if messages[0][\"role\"] == \"system...\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.add_space_prefix bool             = true\n",
            "llama_model_loader: - kv  34:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:  226 tensors\n",
            "[   1/ 291]                        output.weight - [ 4096, 32768,     1,     1], type =    f16, converting to q6_K .. size =   256.00 MiB ->   105.00 MiB\n",
            "[   2/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   3/ 291]                    token_embd.weight - [ 4096, 32768,     1,     1], type =    f16, converting to q4_K .. size =   256.00 MiB ->    72.00 MiB\n",
            "[   4/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   5/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[   6/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   7/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   8/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[   9/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  10/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  11/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  12/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  13/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  14/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  15/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  16/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  17/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  18/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  19/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  20/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  21/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  22/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  23/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  24/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  25/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  26/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  29/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  30/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  31/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  32/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  33/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  34/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  35/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  38/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  39/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  40/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  41/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  42/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  43/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  44/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  47/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  48/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  49/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  50/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  51/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  52/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  53/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  56/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  57/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  58/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  59/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  60/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  61/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  62/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  65/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  66/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  67/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  68/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  69/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  70/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  71/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  74/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  75/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  76/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  77/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  78/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  79/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  80/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  83/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  84/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  85/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  86/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  87/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  88/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  89/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  92/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  93/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[  94/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  95/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[  96/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  97/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  98/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 100/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 101/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 102/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 103/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 104/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 105/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 106/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 107/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 108/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 109/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 110/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 111/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 112/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 113/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 114/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 115/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 116/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 117/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 118/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 119/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 120/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 121/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 122/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 123/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 124/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 125/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 126/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 127/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 128/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 129/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 130/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 131/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 132/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 133/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 134/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 135/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 136/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 137/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 138/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 139/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 140/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 141/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 142/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 143/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 144/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 145/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 146/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 147/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 148/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 149/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 150/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 151/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 152/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 153/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 154/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 155/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 156/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 157/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 158/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 159/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 160/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 161/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 162/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 163/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 164/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 165/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 166/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 167/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 168/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 169/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 170/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 171/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 172/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 173/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 174/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 175/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 176/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 177/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 178/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 179/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 180/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 181/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 182/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 183/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 184/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 185/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 186/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 187/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 188/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 189/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 190/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 191/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 192/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 193/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 194/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 195/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 196/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 197/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 198/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 199/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 200/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 201/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 202/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 203/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 204/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 205/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 206/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 207/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 208/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 210/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 212/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 213/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 214/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 215/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 216/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 217/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 219/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 220/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 221/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 222/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 223/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 224/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 225/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 226/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 227/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 228/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 229/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 230/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 231/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 232/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 233/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 234/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 235/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 236/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 237/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 238/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 239/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 240/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 241/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 242/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 243/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 244/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 245/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 246/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 247/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 248/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 249/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 250/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 251/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 252/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 253/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 254/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 255/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 256/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 257/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 258/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 259/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 260/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 261/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 262/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 263/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 264/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 265/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 266/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 267/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 268/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 269/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 270/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 271/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 272/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 273/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 274/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 275/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 276/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 277/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 278/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 279/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 280/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 281/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 282/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 283/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 284/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 285/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 286/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 287/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
            "[ 288/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
            "[ 289/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "[ 290/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
            "[ 291/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
            "llama_model_quantize_impl: model size  = 13825.02 MB\n",
            "llama_model_quantize_impl: quant size  =  4169.52 MB\n",
            "\n",
            "main: quantize time = 159079.69 ms\n",
            "main:    total time = 159079.69 ms\n",
            "Unsloth: Conversion completed! Output location: /content/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m/unsloth.Q4_K_M.gguf\n",
            "Unsloth: Uploading GGUF to Huggingface Hub...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "unsloth.Q4_K_M.gguf:   0%|          | 0.00/4.37G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32a3956c5fc14a04ae8ab7a8d1717e15"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved GGUF to https://huggingface.co/testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit-GGUF-q4_k_m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade transformers torch outlines\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "65zddvQJp9ut",
        "outputId": "1368cd69-ede4-4b0f-907a-1f1d6cb28c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: outlines in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: interegular in /usr/local/lib/python3.11/dist-packages (from outlines) (0.3.3)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.11/dist-packages (from outlines) (1.2.2)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (from outlines) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from outlines) (3.1.1)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.11/dist-packages (from outlines) (5.6.3)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from outlines) (2.10.6)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.11/dist-packages (from outlines) (0.36.2)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from outlines) (4.23.0)\n",
            "Requirement already satisfied: iso3166 in /usr/local/lib/python3.11/dist-packages (from outlines) (2.1.1)\n",
            "Requirement already satisfied: airportsdata in /usr/local/lib/python3.11/dist-packages (from outlines) (20250224)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /usr/local/lib/python3.11/dist-packages (from outlines) (0.1.26)\n",
            "Requirement already satisfied: genson in /usr/local/lib/python3.11/dist-packages (from outlines) (1.3.0)\n",
            "Requirement already satisfied: pre-commit>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from outlines) (4.1.0)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=4.0.1->outlines) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=4.0.1->outlines) (2.6.8)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=4.0.1->outlines) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.11/dist-packages (from pre-commit>=4.0.1->outlines) (20.29.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->outlines) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->outlines) (2.27.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (25.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->outlines) (0.23.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.0.1->outlines) (4.3.6)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.47.1\n",
            "    Uninstalling transformers-4.47.1:\n",
            "      Successfully uninstalled transformers-4.47.1\n",
            "Successfully installed transformers-4.49.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "ec5c0227dee14976bda617b184f09b5a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import torch\n",
        "from typing import List\n",
        "from pydantic import BaseModel, Field\n",
        "from outlines import generate, models\n",
        "from google.colab import userdata\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, logging, BitsAndBytesConfig\n",
        "\n",
        "logging.set_verbosity_error()  # Suppress warnings\n",
        "model_name = \"testliai-main/testliai-generate-exam-mistral-7b-instruct-v0.3-bnb-4bit\"\n",
        "# Check for GPU availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Model and authentication setup\n",
        "\n",
        "hf_token = userdata.get('thongtestli')  # Hugging Face token\n",
        "\n",
        "# Enable 4-bit quantization to reduce VRAM usage\n",
        "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
        "\n",
        "# Load model with 4-bit precision to reduce memory usage\n",
        "llm = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=quantization_config,\n",
        "    token=hf_token\n",
        ").to(device)\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
        "\n",
        "# Define exam schema\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Question(BaseModel):\n",
        "    question_text: str = Field(..., description=\"The question text.\")\n",
        "    options: List[str] = Field(..., min_items=4, max_items=4, description=\"Four multiple-choice answer options.\")\n",
        "    correct_option: int = Field(..., ge=0, le=3, description=\"Index of the correct answer (0-3).\")\n",
        "\n",
        "class ExamSection(BaseModel):\n",
        "    section_name: str = Field(..., description=\"The name of the exam section.\")\n",
        "    section: int = Field(..., description=\"The section ID.\")\n",
        "    passage_text: Optional[str] = Field(None, description=\"The passage text, if applicable.\")\n",
        "    questions: List[Question] = Field(..., description=\"List of questions in the section.\")\n",
        "\n",
        "class Exam(BaseModel):\n",
        "    exam_number: int\n",
        "    sections: List[ExamSection] = Field(..., min_items=3, max_items=6, description=\"List of exam sections.\")\n",
        "\n",
        "# Clear GPU memory before running\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "\n",
        "# Instantiate Outlines Transformers model\n",
        "model = models.Transformers(llm, tokenizer)\n",
        "\n",
        "# Limit token generation to prevent OOM errors\n",
        "generator = generate.json(model, Exam)\n",
        "\n",
        "# Define prompt\n",
        "text = \"\"\"### English Exam Generator ###\n",
        "Generate a brand-new English exam at the easy level.\n",
        "Follow the same format as learned.\n",
        "\n",
        "### English Exam ###\n",
        "\"\"\"\n",
        "\n",
        "# Run generation safely\n",
        "with torch.no_grad():  # Prevents unnecessary computation graph storage\n",
        "    result3 = generator(text)\n",
        "\n",
        "# Clear GPU memory after running\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n",
        "\n",
        "# Print the formatted JSON output\n",
        "print(result3.model_dump_json(indent=4))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 804,
          "referenced_widgets": [
            "28f2a659e97e49ddb6edfe847713eed1",
            "ff6585a18c1b4b58bd12f5bd385ebc69",
            "8083b69fbd174da7af962468f95ed313",
            "c93dd51d13274435800bcb4ed25afcea",
            "249be5d2d07a432d934b4355a554f2c3",
            "075a1f675ece455cab62fedb8efbdbaa",
            "e64c91bcdac74a1eaa68a9d28ff85a00",
            "ca0d7510c9a9482a924856ac3e018f3a",
            "f36f806c9d8e495a89f21c06d24fa48e",
            "23d2dbc2fbbc470e9c89e10da8c7161f",
            "958cdb21628c4e8aab36d6003fa53ec4",
            "6b634502073d4f53b6ab2edc706fde02",
            "678e0e424fb444f18ab27595321509bb",
            "567d42e3d40a4ba4b0739692bf7aa25c",
            "743a567f04c4444e9cfc8a6a8b731c37",
            "0daf2cd0636c4391bd680de8bfebea64",
            "577f23d1d31141bc8e50472829c0d76f",
            "bfda717fde97420a8aefd9314dd1c4f4",
            "6a5d59e813524752a4ea20efc74831c9",
            "0286c62f6ec44f988ede926b5a3e87c0",
            "c31055d547364a9fb03c6732696a61a1",
            "48d86f7b5759475d9326007cb1c7618d",
            "97300d374b9648088f8ec2c878f29feb",
            "1586e9601b02430b84ae0056e6f48a0d",
            "c29615c9556c408a9a6e8a75c92145ee",
            "ff5372ea1ddb49e0871f162162dbee5d",
            "be7d050ceaac4df89e5aedea5b0d298b",
            "199cce7ed30e4e50a643f9a94e69717f",
            "da2059a534bb4b379dd7429315d47476",
            "e7a1e4e7d8614502bba82f81fb7aec34",
            "529ee8af4dad4bb187a876909768a4d3",
            "454992edcc29408c8021bc041ef409b4",
            "127a297b94514d38bf447cec377ead5d",
            "a5101485e43345668b4a29490608e8e6",
            "d9958b8b784148b6b7e20db8bb47599c",
            "495ca8537b5c4eb688780ab2eb7a18fd",
            "d479180a38ce4964baeccc385bbb69cf",
            "4536d938d8944049b99814b630820d5f",
            "f164fbd7b6664cb892403022d2e76463",
            "3359db84ad3940cfb5ffdf2150be32cc",
            "d9d3c0dfe1ca4417bf8a074fd40db0ed",
            "b060c80508c441fd9e2d75e227e9357d",
            "5396b2d979b0495885503ede511543f5",
            "bdde41687e3240418f16df8861c11adb",
            "06d9dcdb34e94d7581374c5e38fd9383",
            "5f31cc78b1e9445dba57bea4b91e420d",
            "d0be6c3f2fe9421e81d649f251b6c045",
            "93e306e0836f4a6c8bde5d347e233cfe",
            "0655911851524af3bf3ce38cee294a22",
            "0069c48378fe490999a8779e39913f66",
            "fe42b07715484da780f1e1b614024577",
            "4d07ef3c66fb4cb1a0c3a71b3074b45f",
            "57dc30558e304eaabb9ba9bfee76de88",
            "24da8fb1f4f64abdb2b272245bcbf727",
            "26faee4d02fb49c28d7ca86e72f3b157",
            "e8d972458968458d8599efbfa56215d9",
            "b890e0ca046c4c41b63bfc69d1682a6f",
            "f341816be48c46fbb3effeb2806b2706",
            "c2226d730e8b4ebda2bc35cba89a56ff",
            "ab969a60454a456bbefc5da75dde7487",
            "1147c7569d8843728c3ed288538fb580",
            "e006feb706b940b0ba2b99cc0bb74427",
            "a0633cb22c174c27b326ad37d23c3668",
            "21f5e76cd088458c97827e1cca7b0961",
            "0b7bfa93af3b4809a73c3aa1d6c5e326",
            "9d2b820175f541829aa05c0b047055ad",
            "ac5a6a08f9d64e44804f5f93553fd91c",
            "78eb13a1047f45b4b67af071b2e7b630",
            "3f89df2e3ae74098a0c2c159546baf96",
            "60a2b75f4447445887d7010a79bc6cc2",
            "2f840e0d2a5740a5a32ccf4a30f999b1",
            "4c871e4114e34c6f86753754f8713d10",
            "a2b68b3ee6d943f2aa85b923bf1970d2",
            "765355e83bac422e90a01b2357a15893",
            "57025e14a53f41588a1ff37d36a1e575",
            "5601746326824b209a49e0a77ab75580",
            "dfab269861ff4380b33482566216e0c5",
            "b7582d941a6343aaa68df274ad31f5f3",
            "4e4b181bbeff40ce9f1c6ef572a2b802",
            "ae31a3318f774728a9af4ee151f1deb0",
            "2815c3463a694f13956256f5af6f5feb",
            "2c324ba5efc442939e5c972295ea08c3",
            "9d4966b8308d44fd867dcd019848cde2",
            "af16740f87544b609d06ac6165897d84",
            "5211ecd466de4669af236c62d33f85af",
            "cb2c1afbeb3443969fcb9ad9bebeba82",
            "95d6e5fe680e4a189bd778364a7b4fda",
            "61c330b18ba942e3b33f259d4fe39234",
            "80227a8e1010419ea07d99ad16037483",
            "3e265164287d484598e5bfb5d8a5ef15",
            "7be4ff2b96b64258892143e28257deff",
            "6d844df5b9df46cfa1b696a32a8884cd",
            "0601f569a8944d9b97065c266cf54d5d",
            "589c3744b91c4134b597faf960112971",
            "9b3de80b599643248119300c2db882d1",
            "de6f87f198cf4e42853bb99955035790",
            "7fd431860e9b4309ada1b11e9e48bcda",
            "eecb6bfed3ce45a2becb3179f2dba472",
            "b480fc75fae34829bcb30efe3a123460",
            "ae2862dd0d9647f597a86d5e0df5bbe3",
            "425f2c2c50a042f88486b400f4df71e8",
            "a49a432626734ea6a6b6ed3a53f24010",
            "f05dd230c8e848368b25b49a97f2ac88",
            "8e47e9ba83d94bad8c5c94f5331c6200",
            "c72da06d12c946a6843c0f7f68b7ddd0",
            "9197c0bc590841539c17d6acc15e6887",
            "c7433d4f8cfe493eb4043a53106e4228",
            "91632bbce65c45f1b10a4bee290585f9",
            "35c8b8c90ada499faf4545bd01a5e18a",
            "33e40acb5a50459996f872b4ff0d51c0",
            "dfef43f1260f492f8d07847918caa4be",
            "e1c7d15ac43540ab86292db176d9ac96",
            "7afea7fcd9444ecdbe7e0ef343d1ed21",
            "50187a6047f04c57b253b6ed3904347d",
            "ac2e752c4ebe4521b5574ccc07e79609",
            "eec2aabe0fa940cd97b1247fe13db19d",
            "80d87d679282444e9f1d0bf2e922d582",
            "1cc20096d3df4ab489f917435a14d0f4",
            "8497dda45ef44a85899c829bdd96fe48",
            "30e07bb8c52c4f6abd9e21551e019b90",
            "6c0ed2810b394886b5405bf346e0fd37",
            "d9dc3ed0f73f4f67a2df8d53fa1e2e28",
            "8efa2f00446b4194b84134868458a25f",
            "0755ea4b3b3d4b2fb935de0777b08db1",
            "7adddacd821e4f7c9fe1ce0c45d674ea",
            "18b96e11f1bd40e7b1f5b7881f8321ce",
            "b508a2020ec24e119a302a0e9125be6e",
            "9077ee91e4734b65ad287750d17ee6b7",
            "1770560d061d4447a86b9d5b1afc6fe4",
            "4104f0ba150047a69f9bd7e9fd05987c",
            "7b6fe1474bb146a6b7123446217f1d1e",
            "bea6724a83c440669402cb1495db67bc",
            "f8b2f685fb174b57a24598221d7b93b5",
            "918cddc51d6c43dfbc5ba4bd1c0d474f",
            "b76e83b62e5545d8b10092487dbba985",
            "f4a41efe83d84044be4c2bc488ce8deb",
            "633704e717774f74a04f496dd95df975",
            "8049362bc29248d8a647ebe58034633f",
            "ce9584bd4eab4b86bad5a07bb5d31c37",
            "55d8a3c4ebd34382bd2e4741cd090428",
            "65d433ebe8f24754a69704c9cae7edf8",
            "ba1169d59d33476fbeb1484f0718af9b",
            "a9c5ebb252aa485f86c977989315176e",
            "0fa66044c77d488bad05ca2b498ab302",
            "c13d4d2033f5413084a050dd6b7d7ae4",
            "947dfffd02a841489079f3b939e18648",
            "94008ecf00d645059aed28240c29193a",
            "4ff07f6dfc1e4195b78b7ba0ae37eb88",
            "d43dc9855e4840799ec528210f42f019",
            "cdeb9175cb6346748a46761c6a1c6e69",
            "726afbc5dc8e4fd6966bcd626f7904b4",
            "bb8297d00a4143209b5350dcd4c805d1",
            "3d74992fd0224ce18a9ee3ac2e72d616",
            "3e85287610e3434285bc863b8c8f702e"
          ]
        },
        "id": "vapclFcGFgEJ",
        "outputId": "9aaf5441-ed9f-4734-abb9-e706aaa10f3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28f2a659e97e49ddb6edfe847713eed1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/715 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b634502073d4f53b6ab2edc706fde02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97300d374b9648088f8ec2c878f29feb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5101485e43345668b4a29490608e8e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06d9dcdb34e94d7581374c5e38fd9383"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8d972458968458d8599efbfa56215d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.55G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac5a6a08f9d64e44804f5f93553fd91c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7582d941a6343aaa68df274ad31f5f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/157 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80227a8e1010419ea07d99ad16037483"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae2862dd0d9647f597a86d5e0df5bbe3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/137k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfef43f1260f492f8d07847918caa4be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9dc3ed0f73f4f67a2df8d53fa1e2e28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/3.67M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8b2f685fb174b57a24598221d7b93b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/437 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0fa66044c77d488bad05ca2b498ab302"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'MistralForCausalLM' object has no attribute 'max_seq_length'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-d7a330ae0093>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m# Run generation safely\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Prevents unnecessary computation graph storage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mresult3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Clear GPU memory after running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/outlines/generate/api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompts, max_tokens, stop_at, seed, **model_specific_params)\u001b[0m\n\u001b[1;32m    488\u001b[0m         )\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m         completions = self.model.generate(\n\u001b[0m\u001b[1;32m    491\u001b[0m             \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0mgeneration_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/outlines/models/transformers.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, prompts, generation_parameters, logits_processor, sampling_parameters)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0msampling_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         )\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0mgenerated_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_output_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgeneration_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;31m# if single str input and single sample per input, convert to a 1D output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/outlines/models/transformers.py\u001b[0m in \u001b[0;36m_generate_output_seq\u001b[0;34m(self, prompts, inputs, generation_config, **generation_kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m     ):\n\u001b[1;32m    349\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         output_ids = self.model.generate(\n\u001b[0m\u001b[1;32m    351\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgeneration_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_prefill\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3251\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3252\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3253\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/mistral.py\u001b[0m in \u001b[0;36mMistralForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpast_key_values\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         outputs = LlamaModel_fast_forward_inference(\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mLlamaModel_fast_forward_inference\u001b[0;34m(self, input_ids, past_key_values, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m ):\n\u001b[0;32m--> 936\u001b[0;31m     \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m     \u001b[0mbsz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0mhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1927\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1928\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1929\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MistralForCausalLM' object has no attribute 'max_seq_length'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPQxYSZ2ovmh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}